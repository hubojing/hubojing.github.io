<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>论文笔记 on 靖待</title>
        <link>https://hubojing.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</link>
        <description>Recent content in 论文笔记 on 靖待</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>靖待</copyright>
        <lastBuildDate>Tue, 26 Nov 2019 14:08:38 +0000</lastBuildDate><atom:link href="https://hubojing.github.io/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>注意力机制</title>
        <link>https://hubojing.github.io/ytpny8ez/</link>
        <pubDate>Tue, 26 Nov 2019 14:08:38 +0000</pubDate>
        
        <guid>https://hubojing.github.io/ytpny8ez/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;http://img0.imgtn.bdimg.com/it/u=2317694558,3959665778&amp;fm=26&amp;gp=0.jpg&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;没写完&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;概念&#34;&gt;概念
&lt;/h1&gt;&lt;p&gt;从众多信息中选择出对当前任务目标更关键的信息。&lt;/p&gt;
&lt;h1 id=&#34;起源&#34;&gt;起源
&lt;/h1&gt;&lt;p&gt;图像领域到自然语言处理领域&lt;/p&gt;
&lt;h1 id=&#34;encoder-decoder框架&#34;&gt;Encoder-Decoder框架
&lt;/h1&gt;&lt;p&gt;目前大多数注意力模型附着于Encoder-Decoder框架。
一般而言，文本处理和语音识别的Encoder部分通常采用RNN模型，图像处理的Encoder一般采用CNN模型。
对比：分心模型
Attention函数的本质可以被描述为一个查询（query）到一系列（键key-值value）对的映射。
在计算attention时主要分为三步，第一步是将query和每个key进行相似度计算得到权重，常用的相似度函数有点积，拼接，感知机等；然后第二步一般是使用一个softmax函数对这些权重进行归一化；最后将权重和相应的键值value进行加权求和得到最后的attention。目前在NLP研究中，key和value常常都是同一个，即key=value。&lt;/p&gt;
&lt;h1 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/hpulfc/article/details/80448570&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/hpulfc/article/details/80448570&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/robert-dlut/p/8638283.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/robert-dlut/p/8638283.html&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
