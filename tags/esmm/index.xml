<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>ESMM on 靖待</title>
        <link>https://hubojing.github.io/tags/esmm/</link>
        <description>Recent content in ESMM on 靖待</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>靖待</copyright>
        <lastBuildDate>Tue, 27 Apr 2021 10:23:10 +0000</lastBuildDate><atom:link href="https://hubojing.github.io/tags/esmm/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>【Paper】Entire Space Multi-Task Model-An Effective Approach for Estimating Post-Click Conversion Rate</title>
        <link>https://hubojing.github.io/hpxssgui/</link>
        <pubDate>Tue, 27 Apr 2021 10:23:10 +0000</pubDate>
        
        <guid>https://hubojing.github.io/hpxssgui/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\ESMM-f2.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;多任务学习之ESMM&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;2018年 阿里巴巴&lt;/p&gt;
&lt;h1 id=&#34;摘要-abstract&#34;&gt;摘要 ABSTRACT
&lt;/h1&gt;&lt;p&gt;传统的CVR建模应用流行的深度学习方法，并实现最先进的性能。遇到的问题：传统的CVR模型用点击曝光的样本进行训练，同时用所有曝光的样本对整个空间进行推断。这导致样本选择偏差（sample selection bias）问题。另外还有数据稀疏的问题。本文提出ESMM(Entire Space Multi-task Model)，通过用户行为序列模式对CVR建模，比如，曝光(impression)&amp;ndash;&amp;gt;点击(click)&amp;ndash;&amp;gt;转换(conversion)。该模型直接在整个空间建模CVR，并使用了一种特征表示转移学习策略。数据集采用淘宝推荐系统，显示ESMM效果显著。本文还发布了第一个包含点击和转化标签用于CVR建模的时序样本数据集。&lt;/p&gt;
&lt;p&gt;关键词：CVR(post-click conversion rate), 多任务学习(multi-task learning), 样本选择偏差(sample selection bias), 数据稀疏(data sparsity), 全空间建模(entire-space modeling)&lt;/p&gt;
&lt;h1 id=&#34;介绍-introduction&#34;&gt;介绍 INTRODUCTION
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cESMM-f1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ESMM&#34;
	
	
&gt;
1）传统的CVR模型在由impression组成的数据集上训练，同时利用所有impression的样本在整个空间上进行推断。该问题（SSB）会影响训练模型的泛化性能。
2）数据稀疏问题。在实践中，为训练CVR模型而收集的数据通常比CTR任务少得多。训练数据的稀疏性使得CVR模型拟合相当困难。&lt;/p&gt;
&lt;p&gt;以前的研究试图解决这些问题。在[5]中，建立了不同特征的分层估计量，并结合逻辑回归模型来解决直接序列问题。然而，它依赖于先验知识来构建层次结构，这在拥有数千万用户和项目的推荐系统中很难应用。过采样方法[11]复制了罕见的类别样本，这有助于减轻数据的稀疏性，但对采样率敏感。全部缺失为阴性(AMAN)应用随机抽样策略选择未点击的impression作为负样本[6]。通过引入未观察到的例子，它可以在一定程度上消除SSB问题，但会导致始终被低估的预测。无偏方法[10]通过剔除抽样从观测值中拟合真实的潜在分布，解决了CTR建模中的SSB问题。然而，当用拒绝概率划分来加权样本时，可能会遇到数值不稳定性。总之，无论是SSB还是DS问题都没有在CVR建模的场景中得到了很好的解决，上述方法都没有利用序列动作信息。&lt;/p&gt;
&lt;p&gt;pCVR = p(conversion|click, impression)&lt;/p&gt;
&lt;p&gt;ESMM可以同时解决SSB和DS问题。它引入了CTR和CTCVR的两个辅助任务。ESMM没有直接用曝光的样本来训练CVR模型，而是把pCVR作为一个中间变量，乘以pCTR等于pCTCVR。PCTCVR和pCTR都是在整个空间上用所有曝光的样本来估计的，因此导出的pCVR也适用于整个空间。这表明SSB问题已经消除。此外，CVR网络特征表示的参数与CTR网络共享。后者是用更丰富的样本训练的。这种参数迁移学习有助于显著缓解DS问题。&lt;/p&gt;
&lt;p&gt;对于这项工作，我们从淘宝的推荐系统中收集流量日志。整个数据集由89亿个样本组成，并带有点击和转换的序列标签。ESMM的表现始终优于其它模型，这证明了所提出方法的有效性。&lt;/p&gt;
&lt;p&gt;数据集开源：https://tianchi.aliyun.com/datalab/dataSet.html?dataId=408&lt;/p&gt;
&lt;h1 id=&#34;提出的方法-the-proposed-approach&#34;&gt;提出的方法 THE PROPOSED APPROACH
&lt;/h1&gt;&lt;h2 id=&#34;注释-notation&#34;&gt;注释 Notation
&lt;/h2&gt;&lt;p&gt;$S = {(x_i, y_i -&amp;gt; z_i)}|^N_{i=1}$，x代表已观察曝光的特征向量，它通常是一个有多域(field)的高维稀疏向量，比如用户域，物品域等。y和z是二分标签，y = 1或者z = 1代表各自被点击或转化事件发生。y-&amp;gt;z代表点击和转化标签的序列依赖，即转化事件发生时总会有前序点击。
pCVR = p(z = 1|y = 1, x)
pCTR = p(y = 1|x)
pCTCVR = p(y = 1, z = 1|x)
p(y = 1, z = 1|x) = p(y = 1|x) × p(z = 1|y = 1, x)
&amp;mdash;&amp;ndash;pCTCVR&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;pCTR&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;pCVR&amp;mdash;&amp;mdash;&amp;ndash;&lt;/p&gt;
&lt;h2 id=&#34;cvr建模和挑战-cvr-modeling-and-challenges&#34;&gt;CVR建模和挑战 CVR Modeling and Challenges
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cESMM-f2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ESMM架构&#34;
	
	
&gt;
图2左边的DNN CVR建模作为基线模型，传统的CVR模型直接建模p(z = 1|y = 1, x)，使用点击的曝光样本训练模型。比如，$S_c = {(x_j, z_j)|y_j = 1}|^M_{j=1}$，M是所有曝光样本数。$S_c$是S的子集。在$S_c$中，被点击但没有被转化的样本作为负样本，被转化也被点击的样本作为正样本。
&lt;strong&gt;Sample selection bias(SSB)&lt;/strong&gt;
通过引入一个辅助特征向量$x_c$，传统CVR做了一个近似：$p(z = 1|y = 1, x) ≈ q(z = 1|x_c)$。
推理阶段，p(z = 1|y = 1, x)在整个X空间将近似为q(z = 1|x)。
传统的CVR训练数据是曝光和点击的数据，然而预测时又要在整个样本空间。点击事件只是整个曝光样本空间的一个子集，在子集中提取的特征在完整集中使用是有偏的，且数据分布也不一致，违背了机器学习算法有效训练的前提（iid），减弱模型的泛化能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data sparsity (DS)&lt;/strong&gt;
一般CVR比关联的CTR任务少1-3个数量级，CTR任务是在全印象的S的数据集上训练的。表1显示了我们的实验数据集的统计数据，其中CVR任务的样本数量仅为CTR任务的4%。
值得一提的是，CVR建模还存在其他挑战，例如延迟反馈。本文不涉及。&lt;/p&gt;
&lt;h2 id=&#34;多任务全空间模型-entire-space-multi-task-model&#34;&gt;多任务全空间模型 Entire Space Multi-Task Model
&lt;/h2&gt;&lt;p&gt;在整个空间建模。&lt;br&gt;
$p(z = 1|y = 1, x) = \frac{p(y = 1, z = 1|x)}{p(y = 1|x)}$&lt;/p&gt;
&lt;p&gt;这里p(y = 1，z = 1|x)和p(y = 1|x)是在具有所有曝光的S的数据集上建模的。&lt;/p&gt;
&lt;p&gt;损失函数：$L(θ_{cvr}, θ_{ctr}) = \sum_{i=1}^N{l(y_i,f(x_i; θ_{ctr}))} + \sum_{i=1}^N{l(y_i &amp;amp; z_i,f(x_i; θ_{ctr}) × f(x_i;θ_{cvr}))}$
l(·)是交叉熵损失函数。&lt;/p&gt;
&lt;p&gt;特征表征转移。&lt;br&gt;
嵌入层将大规模稀疏输入映射到低维表示向量中。它贡献了深层网络的大部分参数，而深层网络的学习需要大量的训练样本。在ESMM，CVR网络的嵌入式词典与CTR的嵌入式词典是共享的。它遵循特征表征迁移学习范式。CTR任务的全曝光训练样本相对比CVR任务丰富得多。这种参数共享机制使ESMM的CVR网络能够借鉴未点击的曝光，为缓解数据稀疏问题提供了很大的帮助。
请注意，ESMM的子网络可以用一些最近开发的模型来代替，这可能会获得更好的性能。由于篇幅有限，我们省略了它，而把重点放在解决CVR建模在实际实践中遇到的挑战上。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
