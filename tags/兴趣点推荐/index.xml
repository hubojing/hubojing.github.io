<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>兴趣点推荐 on 靖待</title>
        <link>https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/</link>
        <description>Recent content in 兴趣点推荐 on 靖待</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>靖待</copyright>
        <lastBuildDate>Sun, 14 Aug 2022 22:34:04 +0000</lastBuildDate><atom:link href="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>兴趣点推荐（POI Recommendation）论文泛读</title>
        <link>https://hubojing.github.io/adedun3u/</link>
        <pubDate>Sun, 14 Aug 2022 22:34:04 +0000</pubDate>
        
        <guid>https://hubojing.github.io/adedun3u/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/沉醉于知识的芬芳.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;hierarchical-multi-task-graph-recurrent-network-for-next-poi-recommendation&#34;&gt;Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation
&lt;/h1&gt;&lt;p&gt;分层多任务图循环网络用于下一个兴趣点推荐
阅读时间：2022-08-11&lt;/p&gt;
&lt;h2 id=&#34;论文概况&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;SIGIR2022
Nicholas Lim, Bryan Hooi, See-Kiong Ng,Yong Liang Goh, Renrong Weng, Rui Tan
&lt;a class=&#34;link&#34; href=&#34;https://bhooi.github.io/papers/hmt_sigir22.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;解决问题：数据稀疏（用户-兴趣点矩阵稀疏）
提出HMT-GRN算法，该方法通过在多任务设置中学习不同的低稀疏用户区域矩阵来缓解数据稀疏问题，GRN模块同时对顺序依赖关系和全局时空POI-POI关系进行建模，然后对不同的区域和兴趣点分布采用分层束搜索（HBS），随着空间粒度增加来分层减少搜索空间并且预测下一个兴趣点。本文HBS通过减少搜索空间来提高效率，与穷举法相比速度提升5~7倍。本文还提出了一种新颖的选择层来预测下一个兴趣点用户是否曾经访问过，在个性化和探索之间取得平衡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/HMT-GRN.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;HMT-GRN&#34;
	
	
&gt;
个人备注：把bean search运用在POI推荐中；对于已访问过的POI设置了一个选择概率。&lt;/p&gt;</description>
        </item>
        <item>
        <title>TEMN</title>
        <link>https://hubojing.github.io/wpzth4rk/</link>
        <pubDate>Sun, 03 Jul 2022 13:03:28 +0000</pubDate>
        
        <guid>https://hubojing.github.io/wpzth4rk/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/TEMN架构图.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;陆续上架前几个月写的库存&lt;/strong&gt;
　　&lt;strong&gt;主题增强记忆网络个性化兴趣点推荐&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Topic-Enhanced Memory Networks for Personalised Point-of-Interest Recommendation
　　主题增强记忆网络个性化兴趣点推荐
　　KDD 2019
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1905.13127.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/XiaoZHOUCAM/TEMN&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　关键词：推荐系统；神经网络；主题建模&lt;/p&gt;
&lt;h1 id=&#34;问题提出&#34;&gt;问题提出
&lt;/h1&gt;&lt;p&gt;　　现有问题：数据稀疏；现有算法使用一个单一向量刻画用户偏好限制了表达和可解释性。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;　　Topic-Enhanced Memory Network (TEMN)
　　TEMN是一个统一的混合模型，利用TLDA和外部记忆网络以及神经注意机制来捕捉用户的全局和细粒度偏好。
&lt;img src=&#34;https://hubojing.github.io/images/TEMN%e6%9e%b6%e6%9e%84%e5%9b%be.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;TEMN&#34;
	
	
&gt;
　　三部分组成：记忆网络，TLDA和地理建模部分。
　　前两部分相互联系，用于建模从基于领域的记忆网络中学到的非线性交互（通过历史记录）以及从主题模型中学到的全局偏好。&lt;/p&gt;
&lt;p&gt;　　每一部分分别对应不同的损失函数，进行联合训练。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;h2 id=&#34;数据集&#34;&gt;数据集
&lt;/h2&gt;&lt;p&gt;　　微信朋友圈签到数据集（未开源）
&lt;img src=&#34;https://hubojing.github.io/images/TEMN%e6%95%b0%e6%8d%ae%e9%9b%86.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;MF&lt;/li&gt;
&lt;li&gt;BPR&lt;/li&gt;
&lt;li&gt;LDA&lt;/li&gt;
&lt;li&gt;CML&lt;/li&gt;
&lt;li&gt;LRML&lt;/li&gt;
&lt;li&gt;TEMN(GPR) 保留了记忆模块，将TLDA替换为LDA，去掉了地理模块。&lt;/li&gt;
&lt;li&gt;LORE&lt;/li&gt;
&lt;li&gt;ST-RNN&lt;/li&gt;
&lt;li&gt;TEMN(SPR) 完整TEMN模型使用微信（SPR）数据&lt;/li&gt;
&lt;li&gt;GeoMF&lt;/li&gt;
&lt;li&gt;TLDA&lt;/li&gt;
&lt;li&gt;TEMN(CPR) 完整TEMN模型使用微信（GPR）数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性能&#34;&gt;性能
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/TEMN%e6%80%a7%e8%83%bd.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;提出一种融合基于领域和全局的用户偏好的端到端深度学习框架。&lt;/li&gt;
&lt;li&gt;在兴趣点推荐中设计了能融合多种上下文信息的灵活架构，并使之能在多种推荐场景应用。&lt;/li&gt;
&lt;li&gt;提出一种结合监督和非监督学习的混合模型，并利用了记忆网络和主题模型。通过相互学习机制，模型还能得出用户在受记忆网络影响的主题上的概率分布。&lt;/li&gt;
&lt;li&gt;在微信数据集上进行模型验证，超过基线模型。&lt;/li&gt;
&lt;li&gt;通过在TEMN中引入神经注意机制和主题模型，POI推荐的可解释性得到了显著提高。&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>LSTPM</title>
        <link>https://hubojing.github.io/mnykvgbq/</link>
        <pubDate>Fri, 25 Feb 2022 15:59:46 +0000</pubDate>
        
        <guid>https://hubojing.github.io/mnykvgbq/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/LSTPM架构.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation&lt;/strong&gt;
　　下一步去哪儿：用户长短期偏好建模用于兴趣点推荐&lt;/p&gt;
&lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation
　　下一步去哪儿：用户长短期偏好建模用于兴趣点推荐
　　AAAI 2020
　　&lt;a class=&#34;link&#34; href=&#34;https://ojs.aaai.org/index.php/AAAI/article/view/5353&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
　　&lt;a class=&#34;link&#34; href=&#34;https://github.com/NLPWM-WHU/LSTPM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;问题提出&#34;&gt;问题提出
&lt;/h1&gt;&lt;p&gt;　　现有的基于RNN的方法在对用户的短期偏好建模时，要么忽略了用户的长期偏好，要么忽略了最近访问的兴趣点之间的地理关系，从而使得推荐结果不可靠。（所有基于RNN/LSTM的短期偏好建模方法都存在不能对两个非连续兴趣点之间的关系建模的缺点。）
　　为此，提出LSTPM（Long- and Short-Term Preference Modeling）架构。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e6%9e%b6%e6%9e%84.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　它包含三个部分：长期偏好建模、短期偏好建模和预测模块。&lt;/p&gt;
&lt;h2 id=&#34;长期偏好建模&#34;&gt;长期偏好建模
&lt;/h2&gt;&lt;p&gt;　　核心：使用非局部神经操作（nonlocal neural operation）建模长期偏好。
　　以前的做法是直接用LSTM建模签到序列，但是对时间戳的认识不够深。比如人们会在中午时间去餐馆，在晚上去酒吧。所以本文提出了融合时间戳去捕捉时间敏感的属性。论文将一周分成48个段slot（24个工作日段和24个周末段）。计算每两个时间段之间用户签到的兴趣点集合相似性。重合的兴趣点越多，相似性越高。
　　所以历史签到轨迹就可以用这些时间段的兴趣点来表示，从而可以给这些时间段加权重。时间越近影响越大。
　　同时，地理方面计算了各轨迹的中心，计算中心与最近轨迹相似度，得出距离加权公式。&lt;/p&gt;
$$y_i = \frac{1}{C(x)}\sum{_{\forall j}f(x_i, x_j)g(x_j)}$$&lt;p&gt;
　　&lt;code&gt;f&lt;/code&gt;用来度量输出位置和周围其他位置的尺度（例如相似度），&lt;code&gt;g&lt;/code&gt;是在位置j对于输入信号的表示（如卷积操作）。对于non-local behaiver来说，上式中的&lt;code&gt;j&lt;/code&gt;是取遍所有可能的邻居，而对于local操作，如3*3的卷积来说，&lt;code&gt;j&lt;/code&gt;只是取了周围8个像素点。
　　所以这里借鉴这个思想，将每个轨迹S都和历史轨迹和当前轨迹进行了分数计算，并除以标准化因素（全部特征求和）。&lt;/p&gt;
&lt;h2 id=&#34;短期偏好建模&#34;&gt;短期偏好建模
&lt;/h2&gt;&lt;p&gt;　　核心：使用联合方式的地理扩张LSTM建模短期偏好。
　　RNN本身只能用于序列建模，所以有人提出了跳步RNN。但是跳步RNN总是事先定义好和固定好的。所以提出geo-dilated LSTM根据地理和时间因素，来自动决定使用哪些相关输入。
&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e6%9e%b6%e6%9e%842.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;geo-dilated LSTM&#34;
	
	
&gt;
　　直观地，我们的地理扩张LSTM首先从当前轨迹中挑选poi作为输入，其具有由地理相关性确定的不同跳跃长度，然后通过扩展LSTM方案学习短期用户偏好。具体的算法论文给出了伪代码。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;关键理解&lt;/strong&gt;：那它究竟是怎么自动确定跳跃长度的呢？
　　如上图所示，标准的LSTM序列是从l1-&amp;gt;l2-&amp;gt;l3-&amp;gt;l4-&amp;gt;l5。但是加入地理距离后发现，对于l3的前面两个兴趣点l1和l2来说，l1到l3的距离比l1到l2的距离要近，所以留下{l1, l2}路径。依次类推，留下{l1, l2}{l2, l5}路径，也就是两跳。所以，将LSTM设计为两跳。&lt;/p&gt;
&lt;p&gt;　　最后的表示，是标准LSTM和geo-dilated LSTM的平均向量。&lt;/p&gt;
&lt;h2 id=&#34;预测&#34;&gt;预测
&lt;/h2&gt;&lt;p&gt;　　将长短期偏好联结起来，设置一个W全部兴趣点的可训练投影矩阵参数。预测的是下一个时间段t内目标用户最可能访问的兴趣点。损失函数是负对数似然函数。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;h2 id=&#34;数据集&#34;&gt;数据集
&lt;/h2&gt;&lt;p&gt;　　Foursqure, Gowalla&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM_datasets.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;LSTM&lt;/li&gt;
&lt;li&gt;Time-LSTM&lt;/li&gt;
&lt;li&gt;ST-RNN&lt;/li&gt;
&lt;li&gt;TMCA&lt;/li&gt;
&lt;li&gt;CARA&lt;/li&gt;
&lt;li&gt;DCRF&lt;/li&gt;
&lt;li&gt;DeepMove&lt;/li&gt;
&lt;li&gt;STGN&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;评价指标&#34;&gt;评价指标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;召回率Recall&lt;/li&gt;
&lt;li&gt;NDCG&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性能&#34;&gt;性能
&lt;/h2&gt;&lt;h3 id=&#34;基线对比&#34;&gt;基线对比
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e6%80%a7%e8%83%bd.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消融实验&#34;&gt;消融实验
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e8%87%aa%e8%ba%ab%e5%af%b9%e6%af%94.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;消融实验&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;参数分析&#34;&gt;参数分析
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e5%8f%82%e6%95%b0%e5%88%86%e6%9e%90.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;参数分析&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;跳数自动化&#34;&gt;跳数自动化
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM_LSTM%e5%af%b9%e6%af%94.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;LSTM对比&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;提出LSTPM框架解决上述存在的问题。&lt;/li&gt;
&lt;li&gt;LSTPM受非局部操作（nonlocal operations）和dilated RNNs的启发，在构建长期偏好时，设计了非局部操作网络结构来探索历史和最近轨迹的时空联系。在克服RNN在短期用户偏好建模的限制时，提出geo-dilated RNN来全面探索非连续兴趣点间的地理联系。&lt;/li&gt;
&lt;li&gt;在真实世界数据集上效果超过SOTA模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/py184473894/article/details/85322937&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/py184473894/article/details/85322937&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/85776086&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/85776086&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>ASGNN</title>
        <link>https://hubojing.github.io/gwmprssu/</link>
        <pubDate>Sat, 29 Jan 2022 14:27:42 +0000</pubDate>
        
        <guid>https://hubojing.github.io/gwmprssu/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-1.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;Attentive sequential model based on graph neuralnetwork for next poi recommendation&lt;/strong&gt;
　　基于图神经网络的注意力序列模型用于下一个兴趣点推荐&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Attentive sequential model based on graph neuralnetwork for next poi recommendation
　　基于图神经网络的注意力序列模型用于下一个兴趣点推荐
　　WWW21
&lt;a class=&#34;link&#34; href=&#34;https://link.springer.com/content/pdf/10.1007/s11280-021-00961-9.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
　　关键词：推荐系统、序列推荐、兴趣点推荐、图神经网络、注意力机制&lt;/p&gt;
&lt;h1 id=&#34;现有问题&#34;&gt;现有问题
&lt;/h1&gt;&lt;p&gt;　　传统推荐方法忽略了用户短时偏好的动态变化。另外，许多现有方法不能完全探索兴趣点签到序列中复杂的联系和转变形式。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;　　提出ASGNN。
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　ASGNN包括四部分：兴趣点签到序列图构建、特征表示学习、长短时偏好获取、兴趣点推荐&lt;/p&gt;
&lt;h2 id=&#34;兴趣点签到序列图构建&#34;&gt;兴趣点签到序列图构建
&lt;/h2&gt;&lt;p&gt;　　G(V, E), V = (U, L)，U是用户集，L是兴趣点集。E包括用户-兴趣点边和兴趣点-兴趣点边。
　　图中边的权重代表用户在兴趣点的签到次数。&lt;/p&gt;
&lt;h2 id=&#34;特征表示学习&#34;&gt;特征表示学习
&lt;/h2&gt;&lt;p&gt;　　图构建好后，使用GNN学习到用户和兴趣点的低维表示。这避免了马尔科夫决策过程需要的大量状态。
　　为了提高效率更新节点，使用了GGNN。
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;矩阵表示&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;长短时偏好获取&#34;&gt;长短时偏好获取
&lt;/h2&gt;&lt;p&gt;　　设计了两层注意力机制分别捕获长短时用户偏好。&lt;/p&gt;
&lt;h2 id=&#34;兴趣点推荐&#34;&gt;兴趣点推荐
&lt;/h2&gt;&lt;p&gt;　　上一步得到的个性化用户偏好参数和兴趣点特征点乘，得到每个兴趣点分数，通过softmax标准化输出概率值。
　　训练的损失函数为交叉熵函数。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;p&gt;　　围绕下列问题展开：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ASGNN在序列兴趣点推荐任务上性能如何（基线对比）&lt;/li&gt;
&lt;li&gt;ASGNN的关键组件效果如何（组件实验）&lt;/li&gt;
&lt;li&gt;ASGNN的嵌入维度对推荐的影响（维度分析）&lt;/li&gt;
&lt;li&gt;ASGNN和基线在不同稀疏性的数据集上的性能如何（数据稀疏性影响）&lt;/li&gt;
&lt;li&gt;ASGNN学习兴趣点嵌入是否有效（可视化说明）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据集&#34;&gt;数据集
&lt;/h2&gt;&lt;p&gt;　　Gowalla, FourSquare, Brightkite
&lt;a class=&#34;link&#34; href=&#34;https://snap.stanford.edu/data/loc-gowalla.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://snap.stanford.edu/data/loc-gowalla.html&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://sites.google.com/site/yangdingqi/home/foursquare-dataset&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://sites.google.com/site/yangdingqi/home/foursquare-dataset&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://snap.stanford.edu/data/loc-brightkite.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://snap.stanford.edu/data/loc-brightkite.html&lt;/a&gt;
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;POP&lt;/li&gt;
&lt;li&gt;BPR&lt;/li&gt;
&lt;li&gt;FPMC&lt;/li&gt;
&lt;li&gt;HRM&lt;/li&gt;
&lt;li&gt;CPAM&lt;/li&gt;
&lt;li&gt;SHAN&lt;/li&gt;
&lt;li&gt;SRGNN&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;评测指标&#34;&gt;评测指标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;召回率Recall&lt;/li&gt;
&lt;li&gt;MRR&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;基线对比&#34;&gt;基线对比
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;组件实验&#34;&gt;组件实验
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;组件分析&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;维度分析&#34;&gt;维度分析
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;维度分析&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据稀疏性影响&#34;&gt;数据稀疏性影响
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;不同数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;可视化说明&#34;&gt;可视化说明
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;可视化&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;提出ASGNN，它将用户签到行为视为图，并使用GNN局部方式学习用户行为模式和他们的偏好用于下一个兴趣点推荐。&lt;/li&gt;
&lt;li&gt;设计了一个个性化层级注意力机制捕捉用户长短时偏好，并将它们适应于序列推荐。&lt;/li&gt;
&lt;li&gt;实验结果显示ASGNN超过基线和部分SOTA模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/HduDBSI/ASGNN&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/HduDBSI/ASGNN&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>STAN</title>
        <link>https://hubojing.github.io/fhfxfwzp/</link>
        <pubDate>Mon, 24 Jan 2022 11:20:37 +0000</pubDate>
        
        <guid>https://hubojing.github.io/fhfxfwzp/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\STAN-2.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;STAN: Spatio-Temporal Attention Network for Next Location Recommendation&lt;/strong&gt;
　　STAN：基于时空注意力网络的下一个兴趣点推荐&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　STAN: Spatio-Temporal Attention Network for Next Location Recommendation
　　STAN：基于时空注意力网络的下一个兴趣点推荐
　　WWW 21
　　&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2102.04095.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;现有问题&#34;&gt;现有问题
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;引入&#34;
	
	
&gt;
　　0、1、2分别代表家、工作地、商场，3、4、5、6分别代表餐馆。虽然3、4、5、6时间和空间都不连续，但它们是有关联的。现有文献很少关注这种非相邻位置和非连续签到的情况。&lt;/p&gt;
&lt;h1 id=&#34;说明和定义&#34;&gt;说明和定义
&lt;/h1&gt;&lt;p&gt;　　用户U=${u_1, u_2, &amp;hellip;, u_U}$
　　兴趣点L=${l_1, l_2, &amp;hellip;, l_L}$
　　时间T=${t_1, t_2, &amp;hellip;, t_T}$&lt;/p&gt;
&lt;p&gt;　　用户轨迹$tra(u_i) = (r_1, r_2, &amp;hellip;, r_{m_i})$&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　STAN包括多模态嵌入模块、一个自注意力聚合层、一个注意力匹配层、一个平衡采样器。&lt;/p&gt;
&lt;h2 id=&#34;多模态嵌入模块&#34;&gt;多模态嵌入模块
&lt;/h2&gt;&lt;p&gt;　　该模块分为两部分：轨迹嵌入层和时空嵌入层。&lt;/p&gt;
&lt;h3 id=&#34;用户轨迹嵌入层&#34;&gt;用户轨迹嵌入层
&lt;/h3&gt;&lt;p&gt;　　使用了用户、地理位置、时间，嵌入向量记为$e^u$、$e^l$、$e^t$。时间戳被分为7*24=168个维度。所以，$e^u$、$e^l$、$e^t$的维度是U，L和168。
　　输出$e^r = e^u + e^l + e^t$&lt;/p&gt;
&lt;h3 id=&#34;时空嵌入层&#34;&gt;时空嵌入层
&lt;/h3&gt;&lt;p&gt;　　创造了两种矩阵，轨迹时空关系矩阵$△^{t, s}$和候选关系矩阵$N^{t, s}$。前者将两个轨迹间的时间差和地理距离作为关联信息，后者将轨迹中的兴趣点与候选集中可能的预测兴趣点采用同样的信息关联起来。使用线性插值方法。
　　这一层将这两种矩阵进行映射和求和，得到最终的嵌入表示E(△)和E(N)。&lt;/p&gt;
&lt;h2 id=&#34;自注意力聚合层&#34;&gt;自注意力聚合层
&lt;/h2&gt;&lt;p&gt;　　这一层是用来考虑轨迹中有不同距离和时间间隔的两次兴趣点签到的关联程度的。自注意力层可以捕捉长时依赖并为轨迹中的兴趣点分配不同的权重。将轨迹E(u)和时空关系矩阵E(△)通过自注意力聚合层，计算得到新的序列S表示。&lt;/p&gt;
&lt;h2 id=&#34;注意力匹配层&#34;&gt;注意力匹配层
&lt;/h2&gt;&lt;p&gt;　　这一层的作用是根据用户轨迹的最新表示在L中召回最合适的兴趣点候选。
　　A(u) = Matching(E(l), S(u), E(N))，得到的是概率。
　　$Matching(Q, K, N) = Sum(softmax(\frac{QK^T+N}{\sqrt{d}}))$
　　这个公式减少了其它自注意力模型中的PIF信息。&lt;/p&gt;
&lt;h2 id=&#34;平衡采样器&#34;&gt;平衡采样器
&lt;/h2&gt;&lt;p&gt;　　因为正负样本不均衡，优化交叉熵损失不再有用。本文修改了交叉熵损失公式中负样本数量，对于每个正样本$a_k$，需要同时计算L-1个负样本，这称为作为平衡采样器。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据&#34;
	
	
&gt;
　　数据集：Gowalla, SIN, TKY, NYC.
　　输入：$(u_i, l_k, t_k)$, $(l_k, lon_k, lat_k)$
　　输出：候选兴趣点概率值&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;STRNN&lt;/li&gt;
&lt;li&gt;DeepMove&lt;/li&gt;
&lt;li&gt;STGN&lt;/li&gt;
&lt;li&gt;ARNN&lt;/li&gt;
&lt;li&gt;LSTPM&lt;/li&gt;
&lt;li&gt;TiSARec&lt;/li&gt;
&lt;li&gt;GeoSAN&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性能&#34;&gt;性能
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;提出STAN，一种时空双向注意力模型，全面考虑了聚合相关联位置的时空效应。第一个将非相邻位置和非相邻签到时间的兴趣点的时空联系应用在兴趣点推荐中。&lt;/li&gt;
&lt;li&gt;使用简单的线性插值技术替代GPS网格进行空间离散化，它能恢复空间距离和反映时空偏好，而不仅仅是聚合邻居。&lt;/li&gt;
&lt;li&gt;提出了一种双向注意力架构用于PIF（personalized item frequency），第一层聚合了轨迹信息中相关的兴趣点用于更新表示，那么第二层就可以给全部的签到信息匹配目标。&lt;/li&gt;
&lt;li&gt;在四个真实世界数据集上性能比SOTA模型超过10%。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/yingtaoluo/Spatial-Temporal-Attention-Network-for-POI-Recommendation&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/yingtaoluo/Spatial-Temporal-Attention-Network-for-POI-Recommendation&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>CHAML</title>
        <link>https://hubojing.github.io/pd2tgrcn/</link>
        <pubDate>Sat, 22 Jan 2022 18:02:37 +0000</pubDate>
        
        <guid>https://hubojing.github.io/pd2tgrcn/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\CHAML-2.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;Curriculum Meta-Learning for Next POI Recommendation&lt;/strong&gt;
　　基于课程元学习的下一个兴趣点推荐&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Curriculum Meta-Learning for Next POI Recommendation
　　基于课程元学习的下一个兴趣点推荐
　　KDD 21
　　&lt;a class=&#34;link&#34; href=&#34;https://dl.acm.org/doi/abs/10.1145/3447548.3467132&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;现有问题&#34;&gt;现有问题
&lt;/h1&gt;&lt;p&gt;　　在下一个兴趣点推荐的研究中，在有限的用户-兴趣点交互数据下，在冷启动城市中提供满意的推荐是重要问题，这需要许多其它城市丰富数据下隐含的知识进行迁移。现有文献没有考虑到城市转移的问题或者不能同时处理数据稀疏和用户在多个城市的模式多样性的问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cCHAML-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;问题描述&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;　　问题描述如图所示。
　　该问题关键是提出一个合适的迁移算法，但难点有二：
　　1. 不同城市的数据太少
　　2. 用户在不同城市下有不同的多样性表达
　　现有算法不能同时解决这两个问题。传统的预训练和微调技术不能解决问题2，跨域推荐不能解决问题1。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;　　提出 Curriculum Hardness Aware Meta-Learning (CHAML) 框架。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cCHAML-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　架构分为两部分，一部分是基础推荐器，另一部分是MAML扩展。后者用于将元学习引入到POI推荐中。
　　两种采用策略组件，一种是硬意识元学习(hardness aware meta-learning)，另一种是城市级别采样课程(city-level sampling curriculum)。这用于细致思考采样多样性问题。
　　一些概念：
　　Curriculum Learning，主张让模型先从容易的样本开始学习，并逐渐进阶到复杂的样本和知识。
　　meta-learning，又叫learning to learn，即学习如何学习，元学习围绕任务（task）展开。元学习是要去学习任务中的特征表示，从而在新的任务上泛化。&lt;/p&gt;
&lt;h2 id=&#34;基础推荐器&#34;&gt;基础推荐器
&lt;/h2&gt;&lt;p&gt;　　使用DIN作为基础推荐器，由三部分组成，嵌入模块（Embedding module）、注意力模块（Attention module）和输出模块（Output module）。&lt;/p&gt;
&lt;h2 id=&#34;元学习&#34;&gt;元学习
&lt;/h2&gt;&lt;p&gt;　　使用MAML策略。
　　MAML论文：Model-agnostic meta-learning for fast adaptation of deep networks&lt;/p&gt;
&lt;p&gt;　　每轮MAML包括两步骤：局部更新和全局更新。见图中左上部分。
　　每一次元学习任务都有支持训练集$D^{spt}$用于训练，query训练集$D^{qry}$用于测试。
　　元学习目标就是学习一个选学习器F，F可以预测推荐器f中的参数$\theta$，使损失函数最小化。&lt;/p&gt;
&lt;h2 id=&#34;硬意识元学习-hardness-aware-meta-learning&#34;&gt;硬意识元学习 Hardness Aware Meta-Learning
&lt;/h2&gt;&lt;p&gt;　　这里的&amp;quot;hardness&amp;quot;是模型在query样本上的现有性能自判的。
　　分为两个阶段，hard_city阶段和hard_user阶段。两个任务交替循环。对应图右上。&lt;/p&gt;
&lt;h2 id=&#34;城市级别采样课程-city-level-sampling-curriculum&#34;&gt;城市级别采样课程 City-level Sampling Curriculum
&lt;/h2&gt;&lt;p&gt;　　见图下方。
　　分为两阶段，一是困难度测量，使用诸如AUC指标来衡量。二是调度器用于城市pool，定义了一个函数g。课程学习使模型有更大的概率在优化过程中选择容易的梯度步骤。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;p&gt;　　数据集：百度地图MapSmall、MapLarge（未开源）
　　输入：POI ID, POI category, time, user-POI dist
　　输出：POI预测分数$y^{hat}_i$&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;p&gt;　　针对POI推荐：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NeuMF&lt;/li&gt;
&lt;li&gt;HGN&lt;/li&gt;
&lt;li&gt;ATST-LSTM&lt;/li&gt;
&lt;li&gt;PLSPL&lt;/li&gt;
&lt;li&gt;iMTL&lt;/li&gt;
&lt;li&gt;DIN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　针对迁移策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No transfer&lt;/li&gt;
&lt;li&gt;Pretrain and Fine-Tune(FT)&lt;/li&gt;
&lt;li&gt;MAML&lt;/li&gt;
&lt;li&gt;$s^2$Meta&lt;/li&gt;
&lt;li&gt;HAML&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;第一个探索城市迁移的下一个兴趣点推荐，并将元学习用于该问题。&lt;/li&gt;
&lt;li&gt;提出CHAML框架，通过使用用户和城市级别的硬采样挖掘以及城市级别的课程学习（curriculum learning）增强元学习器，达到同时解决数据稀疏和冷启动城市的样本多样性的问题。&lt;/li&gt;
&lt;li&gt;在两个真实世界地图查找数据集中性能超越SOTA方法。
该框架已在百度地图上进行过A/B测试。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/PaddlePaddle/Research/tree/master/ST_DM/KDD2021-CHAML&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PaddlePaddle/Research/tree/master/ST_DM/KDD2021-CHAML&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/victorsoda/chaml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/victorsoda/chaml&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
