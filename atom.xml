<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>靖待的技术博客</title>
  
  <subtitle>小清新IT旅程 | 为中华之崛起而读书</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hubojing.github.io/"/>
  <updated>2022-09-12T06:58:39.220Z</updated>
  <id>https://hubojing.github.io/</id>
  
  <author>
    <name>靖待</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Waline评论服务端转移至Deta</title>
    <link href="https://hubojing.github.io/2022/09/12/Waline%E8%AF%84%E8%AE%BA%E6%9C%8D%E5%8A%A1%E7%AB%AF%E8%BD%AC%E7%A7%BB%E8%87%B3Deta/"/>
    <id>https://hubojing.github.io/2022/09/12/Waline评论服务端转移至Deta/</id>
    <published>2022-09-12T03:24:26.000Z</published>
    <updated>2022-09-12T06:58:39.220Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" width="300" height="180" style="float:right;"><br><br><br>　　<strong>和评论系统battle的第N年</strong><br>　　<strong>折腾不息</strong><br><br><br> </div><a id="more"></a><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>前阵子评论系统又挂了，原因是*.vercel.app域名被污染。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>法一：服务端换个域名<br>法二：换个服务端部署</p><p>我选法二。</p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><p>DETA官网：<a href="https://www.deta.sh/" target="_blank" rel="noopener">https://www.deta.sh/</a></p><blockquote><p>Deta is free for ever.</p></blockquote><p>这句话很不错有木有~</p><ol><li>注册</li><li>根据注册后的引导新建一个默认的project</li><li>点击 <a href="https://web.deta.sh/deploy?path=https://github.com/walinejs/deta-starter" target="_blank" rel="noopener">https://web.deta.sh/deploy?path=https://github.com/walinejs/deta-starter</a> 将Waline快速部署到deta平台</li><li>将部署url写入前端脚本的 serverURL 配置中，此时更新就可看到评论</li><li><p>将项目放到本地管理</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mac or Linux</span></span><br><span class="line">curl -fsSL https://get.deta.dev/cli.sh | sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Windows for powershell</span></span><br><span class="line">iwr https://get.deta.dev/cli.ps1 -useb | iex</span><br></pre></td></tr></table></figure></li><li><p>cmd<code>deta login</code>登录</p></li><li>复制并执行页面中的<code>deta clone</code>命令，将项目下载到本地</li><li><code>deta deploy</code>实现部署</li><li>本地项目新增<code>.env</code>文件，将需要修改的环境变量使用<code>VAR_NAME=VALUE</code>的形式一行一个写在文件中</li><li>使用<code>deta update -e .env</code>进行环境变量更新</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://waline.js.org/guide/server/deta.html" target="_blank" rel="noopener">Waline手册-Deta部署</a></li><li><a href="https://docs.deta.sh/docs/cli/install/" target="_blank" rel="noopener">Deta CLI</a></li><li><a href="https://docs.deta.sh/docs/micros/env_vars/#setting-environment-variables" target="_blank" rel="noopener">Deta环境变量配置</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;和评论系统battle的第N年&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;折腾不息&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="博客" scheme="https://hubojing.github.io/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="博客" scheme="https://hubojing.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="Waline" scheme="https://hubojing.github.io/tags/Waline/"/>
    
      <category term="Deta" scheme="https://hubojing.github.io/tags/Deta/"/>
    
  </entry>
  
  <entry>
    <title>关系抽取（RE）论文泛读</title>
    <link href="https://hubojing.github.io/2022/08/16/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%EF%BC%88RE%EF%BC%89%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/"/>
    <id>https://hubojing.github.io/2022/08/16/关系抽取（RE）论文泛读/</id>
    <published>2022-08-16T11:37:35.000Z</published>
    <updated>2022-08-16T12:22:37.247Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/沉醉于知识的芬芳.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>论文泛读不定期更新。</strong><br><br><br> </div><a id="more"></a><h1 id="Document-Level-Relation-Extraction-with-Adaptive-Focal-Loss-and-Knowledge-Distillation"><a href="#Document-Level-Relation-Extraction-with-Adaptive-Focal-Loss-and-Knowledge-Distillation" class="headerlink" title="Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation"></a>Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation</h1><p>具有自适应焦点损失和知识蒸馏的文档级关系抽取<br>阅读时间：2022-08-15</p><h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2022<br>阿里达摩院<br>Qingyu Tan, Ruidan He, Lidong Bing, Hwee Tou Ng<br><a href="https://arxiv.org/pdf/2203.10900" target="_blank" rel="noopener">PDF</a><br><a href="https://github.com/tonytan48/KD-DocRE" target="_blank" rel="noopener">CODE</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>文档级关系抽取要同时从多个句子中提取关系。本文提出DocRE算法，一个用于文档级别的关系抽取半监督算法，它有三个新组件。第一，用轴向注意力模块学习实体对之间的依赖关系。第二，提出了一个自适应的焦点损失来解决DocRE中类的不平衡问题。最后，利用知识蒸馏来克服人工标注数据与远程监督数据之间的差异。<br>现有问题：现存的方法关注实体对的句法特征，而忽略了实体对之间的交互作用；目前还没有工作可以直接的解决类的不平衡问题。现存的工作仅仅关注阈值学习来平衡正例和负例，但正例内部的类不平衡问题并没有得到解决；关于将远程监督数据应用于DocRE任务的研究很少。<br>贡献点：轴向注意力（提升two-hop关系的推理能力）、自适应焦点损失（解决标签分配不平衡的问题，长尾类在总的损失中占比较多）、知识蒸馏（克服标注数据和远程监督数据之间的差异）<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/KD-DocRE.png" alt="KD-DocRE" title="">                </div>                <div class="image-caption">KD-DocRE</div>            </figure></p><h1 id="Packed-Levitated-Marker-for-Entity-and-Relation-Extraction"><a href="#Packed-Levitated-Marker-for-Entity-and-Relation-Extraction" class="headerlink" title="Packed Levitated Marker for Entity and Relation Extraction"></a>Packed Levitated Marker for Entity and Relation Extraction</h1><p>打包悬浮标记用于实体和关系抽取<br>阅读时间：2022-08-15</p><h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><p>ACL 2022<br>Deming Ye, Yankai Lin, Peng Li, Maosong Sun<br>清华大学与腾讯微信模式识别中心合作<br><a href="https://aclanthology.org/2022.acl-long.337/" target="_blank" rel="noopener">PDF</a><br><a href="https://github.com/thunlp/PL-Marker" target="_blank" rel="noopener">CODE</a></p><h2 id="笔记-1"><a href="#笔记-1" class="headerlink" title="笔记"></a>笔记</h2><p>最近的命名实体识别和关系抽取工作专注于研究如何从预训练模型中获得更好的span表示。然而，许多工作忽略了span之间的相互关系。本文提出了一种基于悬浮标记的span表示方法，在编码过程中通过特定策略打包标记来考虑span之间的相互关系。对于命名实体识别任务，提出了一种面向邻居span的打包策略，以更好地建模实体边界信息。对于关系抽取任务，设计了一种面向头实体的打包策略，将每个头实体以及可能的尾实体打包，以共同建模同头实体的span对。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/PL-Marker.png" alt="PL-Marker" title="">                </div>                <div class="image-caption">PL-Marker</div>            </figure></p><h1 id="Consistent-Representation-Learning-for-Continual-Relation-Extraction"><a href="#Consistent-Representation-Learning-for-Continual-Relation-Extraction" class="headerlink" title="Consistent Representation Learning for Continual Relation Extraction"></a>Consistent Representation Learning for Continual Relation Extraction</h1><p>一致表示学习用于连续关系抽取<br>阅读时间：2022-08-12</p><h2 id="论文概况-1"><a href="#论文概况-1" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2022<br>Kang Zhao, Hua Xu, Jiangong Yang, Kai Gao<br><a href="https://arxiv.org/pdf/2203.02721" target="_blank" rel="noopener">PDF</a><br><a href="https://github.com/thuiar/CRL" target="_blank" rel="noopener">CODE</a></p><h2 id="笔记-2"><a href="#笔记-2" class="headerlink" title="笔记"></a>笔记</h2><p>通过对比学习和回放记忆时的知识蒸馏，提出一种新颖的一致性表示学习方法。使用基于记忆库的监督对比学习来训练每一个新的任务，以使模型高效学习特征表示。为了防止对老任务的遗忘，构造了记忆样本的连续回放，同时让模型保留在知识蒸馏中历史任务之间的关系。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/CRL.png" alt="CRL" title="">                </div>                <div class="image-caption">CRL</div>            </figure></p><h1 id="Pre-training-to-Match-for-Unified-Low-shot-Relation-Extraction"><a href="#Pre-training-to-Match-for-Unified-Low-shot-Relation-Extraction" class="headerlink" title="Pre-training to Match for Unified Low-shot Relation Extraction"></a>Pre-training to Match for Unified Low-shot Relation Extraction</h1><p>预训练用于匹配统一少样本关系抽取<br>阅读时间：2022-08-12</p><h2 id="论文概况-2"><a href="#论文概况-2" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2022<br>Fangchao Liu, Hongyu Lin, Xianpei Han, Boxi Cao, Le Sun<br><a href="https://arxiv.org/pdf/2203.12274" target="_blank" rel="noopener">PDF</a><br><a href="https://github.com/fc-liu/MCMN" target="_blank" rel="noopener">CODE</a></p><h2 id="笔记-3"><a href="#笔记-3" class="headerlink" title="笔记"></a>笔记</h2><p>低样本关系抽取旨在少样本甚至零样本场景下的关系抽取。由于低样本关系抽取所包含任务形式多样，传统方法难以统一处理。本文针对这一问题，提出了一种统一的低样本匹配网络：（1）基于语义提示（prompt）范式，构造了从关系描述到句子实例的匹配网络模型；（2）针对匹配网络模型学习，设计了三元组-复述的预训练方法，以增强模型对关系描述与实例之间语义匹配的泛化性。在零样本、小样本以及带负例的小样本关系抽取评测基准上的实验结果表明，该方法能有效提升低样本场景下关系抽取的性能，并且具备了较好的任务自适应能力。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/MCMN.png" alt="MCMN" title="">                </div>                <div class="image-caption">MCMN</div>            </figure></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/沉醉于知识的芬芳.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="关系抽取" scheme="https://hubojing.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/"/>
    
      <category term="RE" scheme="https://hubojing.github.io/tags/RE/"/>
    
  </entry>
  
  <entry>
    <title>兴趣点推荐（POI Recommendation）论文泛读</title>
    <link href="https://hubojing.github.io/2022/08/14/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90%EF%BC%88POI%20Recommendation%EF%BC%89%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/"/>
    <id>https://hubojing.github.io/2022/08/14/兴趣点推荐（POI Recommendation）论文泛读/</id>
    <published>2022-08-14T14:34:04.000Z</published>
    <updated>2022-08-14T16:16:24.228Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/沉醉于知识的芬芳.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>论文泛读不定期更新。</strong><br><br><br> </div><a id="more"></a><h1 id="Hierarchical-Multi-Task-Graph-Recurrent-Network-for-Next-POI-Recommendation"><a href="#Hierarchical-Multi-Task-Graph-Recurrent-Network-for-Next-POI-Recommendation" class="headerlink" title="Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation"></a>Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation</h1><p>分层多任务图循环网络用于下一个兴趣点推荐<br>阅读时间：2022-08-11</p><h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>SIGIR2022<br>Nicholas Lim, Bryan Hooi, See-Kiong Ng,Yong Liang Goh, Renrong Weng, Rui Tan<br><a href="https://bhooi.github.io/papers/hmt_sigir22.pdf" target="_blank" rel="noopener">PDF</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>解决问题：数据稀疏（用户-兴趣点矩阵稀疏）<br>提出HMT-GRN算法，该方法通过在多任务设置中学习不同的低稀疏用户区域矩阵来缓解数据稀疏问题，GRN模块同时对顺序依赖关系和全局时空POI-POI关系进行建模，然后对不同的区域和兴趣点分布采用分层束搜索（HBS），随着空间粒度增加来分层减少搜索空间并且预测下一个兴趣点。本文HBS通过减少搜索空间来提高效率，与穷举法相比速度提升5~7倍。本文还提出了一种新颖的选择层来预测下一个兴趣点用户是否曾经访问过，在个性化和探索之间取得平衡。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/HMT-GRN.png" alt="HMT-GRN" title="">                </div>                <div class="image-caption">HMT-GRN</div>            </figure><p>个人备注：把bean search运用在POI推荐中；对于已访问过的POI设置了一个选择概率。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/沉醉于知识的芬芳.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="POI" scheme="https://hubojing.github.io/tags/POI/"/>
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>实体链接（EL）论文泛读</title>
    <link href="https://hubojing.github.io/2022/08/14/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5%EF%BC%88EL%EF%BC%89%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/"/>
    <id>https://hubojing.github.io/2022/08/14/实体链接（EL）论文泛读/</id>
    <published>2022-08-14T08:26:09.000Z</published>
    <updated>2022-08-14T09:12:54.752Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/沉醉于知识的芬芳.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>论文泛读不定期更新。</strong><br><br><br> </div><a id="more"></a><h1 id="Entity-linking-meets-deep-learning-Techniques-and-solutions"><a href="#Entity-linking-meets-deep-learning-Techniques-and-solutions" class="headerlink" title="Entity linking meets deep learning: Techniques and solutions"></a>Entity linking meets deep learning: Techniques and solutions</h1><p>实体链接遇到深度学习：技术和解决方法<br>阅读时间：2022-08-11</p><h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>2021年 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING<br>CCF-A<br>Wei Shen, Yuhan Li, Yinan Liu, Jiawei Han,Fellow, IEEE, Jianyong Wang,Fellow, IEEE, Xiaojie Yuan<br><a href="https://arxiv.org/pdf/2109.12520" target="_blank" rel="noopener">PDF</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>从三个方面展开：嵌入（Embedding）、特征（Feature）、算法（Algorithm）<br>Embedding包括字（word）嵌入、Mention嵌入、实体（entity）嵌入、对齐（aligenment）嵌入。<br>特征包括先验流行度、表面形式相似度、类型相似度、上下文相似度、主题连贯性。<br>算法包括MLP、基于图的算法、强化学习。<br>给出了十种广泛使用的实体链接数据集。<br>未来方向：多源异质文本数据、NER和EL联合、更高级的语言模型、EL模型鲁棒性</p><h1 id="Multilingual-Autoregressive-Entity-Linking"><a href="#Multilingual-Autoregressive-Entity-Linking" class="headerlink" title="Multilingual Autoregressive Entity Linking"></a>Multilingual Autoregressive Entity Linking</h1><p>多语言自回归实体链接<br>阅读时间：2022-08-11</p><h2 id="论文概况-1"><a href="#论文概况-1" class="headerlink" title="论文概况"></a>论文概况</h2><p>2022年3月 Transactions of the Association for Computational Linguistics SCI Q1<br>Nicola De Cao, Ledell Wu, Kashyap Popat, Mikel Artetxe,Naman Goyal, Mikhail Plekhanov, Luke Zettlemoyer,Nicola Cancedda, Sebastian Riedel1,6, Fabio Petroni<br>Facebook AI<br><a href="https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00460/2004070/tacl_a_00460.pdf" target="_blank" rel="noopener">PDF</a><br><a href="https://github.com/facebookresearch/GENRE" target="_blank" rel="noopener">CODE</a></p><h2 id="笔记-1"><a href="#笔记-1" class="headerlink" title="笔记"></a>笔记</h2><p>提出mGENRE系统，它是一个用于多语言实体链接问题的序列到序列的系统，用于解析特定语言mention到多语言知识库。对于特定语言的mention，mGENRE以自回归的方式从左到右逐个（left-to-right, token-by-token）标记预测目标实体的名称。自回归公式有效地交叉编码关于字符串和实体名称，用来捕获比标准点积更多的交互。它还可以在大知识库中进行快速搜索，即使对于没出现在mention表中和不用大规模向量索引的mention也是如此。虽然先前的MEL工作对每个实体使用单一表示，但我们匹配尽可能多的多语言的实体名称，这允许利用源输入和目标名称之间的语言连接。此外，在完全没有训练数据的语言的零样本设置中，mGENRE将目标语言视为在预测时被边缘化的潜在变量。这使平均准确度提高了50%以上。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/mGENRE.png" alt="mGENRE" title="">                </div>                <div class="image-caption">mGENRE</div>            </figure></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/沉醉于知识的芬芳.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="实体链接" scheme="https://hubojing.github.io/tags/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5/"/>
    
  </entry>
  
  <entry>
    <title>BERT</title>
    <link href="https://hubojing.github.io/2022/08/09/BERT/"/>
    <id>https://hubojing.github.io/2022/08/09/BERT/</id>
    <published>2022-08-09T12:59:07.000Z</published>
    <updated>2022-08-09T15:22:39.168Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/BERT架构图.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>笔记</strong><br><br><br> </div><a id="more"></a><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>2019年 谷歌 Jacob Devlin<br>NAACL-HLT会议-NLP顶会<br><a href="https://arxiv.org/abs/1810.04805" target="_blank" rel="noopener">PDF</a><br><a href="GitHub - google-research/bert: TensorFlow code and pre-trained models for BERT">CODE</a></p><h1 id="摘要重点"><a href="#摘要重点" class="headerlink" title="摘要重点"></a>摘要重点</h1><p>　　BERT(Bidirectional Encoder Rpresentation from Transformers)<br>　　BERT 旨在通过联合调节所有层的左右上下文，从未标记的文本中预训练深度双向表示。因此，预训练的 BERT 模型可以通过一个额外的输出层进行微调，从而为各种任务（例如问答和语言推理）创建最先进的模型，而无需大量特定任务架构修改。</p><h1 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h1><p>　　在下游任务中有两种方法使用预训练语言表示模型，一种是基于特征（feature-based）方法，一种是微调（fine-tuning）。本文认为现有技术限制了预训练表示的能力，尤其是微调方法。主要限制是标准语言模型是单向的，这限制了预训练可以使用的架构。例如，在 OpenAI GPT 中，作者使用从左到右的架构，其中每个标记只能关注Transformer的自注意力层中的先前标记。 这样的限制对于句子级任务来说是次优的，并且在将基于微调的方法应用于令牌级任务（例如问答）时可能非常有害，在这些任务中，从两个方向整合上下文至关重要。</p><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ul><li>我们解释了语言表示中双向预训练的重要性。不像之前的模型在预训练中使用双向语言模型，BERT使用掩码语言模型（masked language model）来预训练深度双向表示。也和以前使用从左到右和从右到左LM独立训练再浅层连结的方法不同。</li><li>预训练表示减少了许多特定任务的繁重工程架构。BERT是第一个基于表示模型微调并在一系列句子级别和token级别任务中实现SOTA性能的。</li><li>BERT在11个NLP任务中实现SOTA性能，代码开源。</li></ul><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>基于特征的无监督方法（如ELMo）、微调无监督方法（如OpenAI GPT）</p><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p>　　两阶段：预训练+微调。<br>　　预训练阶段，模型在不同的预训练任务中使用未标注数据训练。<br>　　微调阶段，首先使用预训练参数初始化，所有的参数使用下游任务中的标注数据进行微调。即使每一个下游任务使用相同的预训练参数初始化，它们还是有单独的微调模型。如图为一个问答示例。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/BERT架构图.png" alt="BERT" title="">                </div>                <div class="image-caption">BERT</div>            </figure><br>　　记层数（Transformer块）为L，隐藏层为H，自注意力头数量为A。实验有两种模型规模：一种是$BERT_{BASE}$（L=12，H=768，A=12，总参数为110M）；另一种是$BERT_{LARGE}$（L=24，H=1024，A=16，总参数为340M）。<br>　　为压缩目的，$BERT_{BASE}$选择了和Open AI一样的模型规模。但是BERT Transformer使用了双向自注意力，GPT Transformer使用的是受限的自注意力，它的每个token只能获取它左边的上下文。<br>　　每一个token都以[CLS]开头。句子对会一起打包到一个序列中，分割句子使用两种方式。一是使用token[SEP]，二是在每个token中加入一个学习过的embedding表示它属于句子A还是句子B。如图1所示，输入embedding记为E，最后隐藏向量的[CLS]记为C，第i个输入token的最后的隐藏向量记为$T_i$。<br>对于给定的标记，其输入表示是通过对相应的标记、段和位置嵌入求和来构建的。这种结构的可视化可以在图2中看到。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/BERT输入表示.png" alt="BERT输入表示" title="">                </div>                <div class="image-caption">BERT输入表示</div>            </figure></p><h2 id="预训练BERT"><a href="#预训练BERT" class="headerlink" title="预训练BERT"></a>预训练BERT</h2><h3 id="任务1：Masked-LM"><a href="#任务1：Masked-LM" class="headerlink" title="任务1：Masked LM"></a>任务1：Masked LM</h3><p>　　随机掩盖掉部分输入的tokens，然后预测这些被掩盖的tokens。这个过程记为“masked LM”(MLM)，类似于文学里的完形填空。与掩码标记对应的最终隐藏向量被送到词汇表上的softmax输出，就像在标准 LM 中一样。本文选择15%的tokens进行掩盖。由于[MASK] token在微调阶段不存在，所以预训练阶段和微调阶段不匹配。为了减轻影响，当选中第i个token时，按三条规则进行掩码：<br>（1） 80%时间使用[MASK] token<br>（2）10%时间选择随机token<br>（3）10%时间token不变<br>然后，使用交叉熵损失和$T_i$预测原始token。</p><h3 id="任务2：下一个句子预测（NSP）"><a href="#任务2：下一个句子预测（NSP）" class="headerlink" title="任务2：下一个句子预测（NSP）"></a>任务2：下一个句子预测（NSP）</h3><p>　　问答QA和自然语言推理（NLI）都是基于对两个句子关系的理解做的，而语言模型不能直接捕捉它。为了训练一个能理解句子关系的模型，我们预先训练一个二值化的下一个句子预测任务，该任务可以从任何单语语料库中轻松生成。在之前的工作中，只有句子嵌入被转移到下游任务， BERT 转移所有参数来初始化最终任务模型参数。</p><h2 id="微调BERT"><a href="#微调BERT" class="headerlink" title="微调BERT"></a>微调BERT</h2><p>　　微调很简单，因为Transformer中的自注意力机制允许 BERT 通过交换适当的输入和输出来对许多下游任务进行建模——无论它们涉及单个文本还是文本对。对于涉及文本对的应用程序，一种常见的模式是在应用双向交叉注意力之前独立编码文本对。BERT使用自我注意力机制来统一这两个阶段，因为使用自我注意对连接的文本对进行编码有效地包括了两个句子之间的双向交叉注意力。<br>　　对于每个任务，我们只需将任务特定的输入和输出插入BERT，端到端微调所有参数。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/BERT架构图.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;笔记&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="BERT" scheme="https://hubojing.github.io/tags/BERT/"/>
    
      <category term="NLP" scheme="https://hubojing.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>samba映射</title>
    <link href="https://hubojing.github.io/2022/07/31/samba%E6%98%A0%E5%B0%84/"/>
    <id>https://hubojing.github.io/2022/07/31/samba映射/</id>
    <published>2022-07-31T10:02:47.000Z</published>
    <updated>2022-07-31T10:43:45.737Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" width="300" height="180" style="float:right;"><br><br><br>　　<strong>更方便地使用服务器。</strong><br><br><br> </div><a id="more"></a><h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>　　将服务器资源可通过windows进行管理，很方便。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>　　在ubuntu服务器上<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get install samba</span><br><span class="line">samba --version</span><br></pre></td></tr></table></figure></p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/samba/smb.conf</span><br></pre></td></tr></table></figure><p>　　在文件末尾追加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">security = share</span><br><span class="line"></span><br><span class="line">[share]</span><br><span class="line">path = /home/想映射的文件夹/</span><br><span class="line">available = yes</span><br><span class="line">browsealbe = yes</span><br><span class="line">public = yes</span><br><span class="line">guest ok = yes</span><br><span class="line">writable = yes</span><br><span class="line">create mask = 0664</span><br><span class="line">directory mask = 0664</span><br><span class="line">force user =root</span><br><span class="line">valid users = 用户名</span><br></pre></td></tr></table></figure></p><p>　　配置samba密码：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo touch /etc/samba/smbpasswd</span><br><span class="line">sudo smbpasswd -a 用户名</span><br></pre></td></tr></table></figure></p><p>　　之后输入密码。<br>　　配置samba服务：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/samba restart</span><br><span class="line">sudo service smbd restart</span><br></pre></td></tr></table></figure></p><h1 id="windows映射操作"><a href="#windows映射操作" class="headerlink" title="windows映射操作"></a>windows映射操作</h1><p>　　此电脑-计算机-映射网络驱动器<br>　　填写”\服务器ip\文件夹名称”，勾选使用其他凭据连接，输入用户名和密码。</p><p>　　完成。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;更方便地使用服务器。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="互联网" scheme="https://hubojing.github.io/categories/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
    
      <category term="samba" scheme="https://hubojing.github.io/tags/samba/"/>
    
  </entry>
  
  <entry>
    <title>JingSLink</title>
    <link href="https://hubojing.github.io/2022/07/03/JingSLink/"/>
    <id>https://hubojing.github.io/2022/07/03/JingSLink/</id>
    <published>2022-07-03T13:26:39.000Z</published>
    <updated>2022-07-04T06:39:33.468Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" width="300" height="180" style="float:right;"><br><br>　　<strong>简单开发一个截图保存并返回链接的小工具JingSLink</strong><br>　　<strong>JingPic迎来重构版JingSLink</strong><br>　　<strong>自用简陋小工具系列</strong><br><br><br> </div><a id="more"></a><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>　　写markdown文章时，贴图这件事儿真的很麻烦。我需要把图片手动保存到对应文件夹，再手动在文章里引入图片链接。所以很多时候我能不配图就不配图。多年前为了方便插入图床链接，用MFC做了个自用小工具<a href="https://github.com/hubojing/JingPic" target="_blank" rel="noopener">JingPic</a>。但是它是基于保存了的图片进行的操作，将图片转移到需要的位置。后期也没有维护，操作上依然不够简洁。比如我更喜欢直接截图能自动保存到指定位置，这样就减少一步自己保存的操作。</p><p>　　自己定制还是最爽的，我想要什么功能我自己开发好了。而且这个小工具开发起来也很简单，几十行很快就写完了。</p><p>　　首先，要起个名字，以前的叫JingPic，这个重构版就叫JingSLink（Jinger Screenshot for Link）吧。</p><h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ul><li>能够截图</li><li>截图能保存到指定文件夹中</li><li>截图完成后，自动将图片相对路径复制到剪贴板</li><li>有exe可执行文件</li></ul><h1 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h1><p>　　语言：Python<br>　　用到的库：tkinter, PIL, keyboard, pyperclip</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>　　一开始我是想自己实现截图操作的，后来一想，我平日用QQ截图最多，它功能齐全，那我直接调用它的截图不就好了。<br>　　所以，大体实现思路如下：</p><ul><li>监听键盘，捕捉QQ截图快捷键ctrl+alt+a，并设置一个结束键ctrl。</li><li>使用PIL库的ImageGrab读取截图。</li><li>弹出一个输入框，输入图片名称。<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/JingSLink.png" alt="输入框" title="">                </div>                <div class="image-caption">输入框</div>            </figure></li><li>拼凑出图片完整链接，将图片保存到该地址。</li><li>拼凑出hexo博文中所需的图片插入相对地址，复制到剪贴板。<br>　　当然，为了不每次都打开pycharm编译器，得导出一个exe文件。</li></ul><p>　　打包exe：<br>　　安装pyinstaller。<br>　　在pycharm中，<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pyinstaller -F main.py</span><br><span class="line">pyinstaller -F -w main.py<span class="comment">#（-w是取消dos窗口）</span></span><br><span class="line">pyinstaller -F -w --icon=ico main.py</span><br><span class="line"><span class="comment"># (ico为图标的文件名，与dist目录为同目录)</span></span><br></pre></td></tr></table></figure></p><p>　　最后生成的exe文件在dist文件夹下。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/hubojing/JingSLink" target="_blank" rel="noopener">https://github.com/hubojing/JingSLink</a></p><h1 id="后期优化"><a href="#后期优化" class="headerlink" title="后期优化"></a>后期优化</h1><p>　　如有必要：</p><ul><li>一些异常情况的提示</li><li>右下角有最小化托盘，右键有设置和退出菜单</li><li>可扩展性：可以更改文件夹路径</li><li>可扩展性：可以更改图片路径格式（绝对路径/相对路径）</li><li>换pyqt框架</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://tkdocs.com/tutorial/index.html" target="_blank" rel="noopener">http://tkdocs.com/tutorial/index.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;简单开发一个截图保存并返回链接的小工具JingSLink&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;JingPic迎来重构版JingSLink&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;自用简陋小工具系列&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="软件开发" scheme="https://hubojing.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="截图" scheme="https://hubojing.github.io/tags/%E6%88%AA%E5%9B%BE/"/>
    
      <category term="链接" scheme="https://hubojing.github.io/tags/%E9%93%BE%E6%8E%A5/"/>
    
      <category term="markdown" scheme="https://hubojing.github.io/tags/markdown/"/>
    
      <category term="软件开发" scheme="https://hubojing.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>TEMN</title>
    <link href="https://hubojing.github.io/2022/07/03/Paper_TEMN/"/>
    <id>https://hubojing.github.io/2022/07/03/Paper_TEMN/</id>
    <published>2022-07-03T05:03:28.000Z</published>
    <updated>2022-07-04T09:37:11.387Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/TEMN架构图.png" width="300" height="180" style="float:right;"><br><br>　　<strong>陆续上架前几个月写的库存</strong><br>　　<strong>主题增强记忆网络个性化兴趣点推荐</strong><br><br><br> </div><a id="more"></a><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>　　Topic-Enhanced Memory Networks for Personalised Point-of-Interest Recommendation<br>　　主题增强记忆网络个性化兴趣点推荐<br>　　KDD 2019<br><a href="https://arxiv.org/pdf/1905.13127.pdf" target="_blank" rel="noopener">PDF</a><br><a href="https://github.com/XiaoZHOUCAM/TEMN" target="_blank" rel="noopener">CODE</a></p><p>　　关键词：推荐系统；神经网络；主题建模</p><h1 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h1><p>　　现有问题：数据稀疏；现有算法使用一个单一向量刻画用户偏好限制了表达和可解释性。</p><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>　　Topic-Enhanced Memory Network (TEMN)<br>　　TEMN是一个统一的混合模型，利用TLDA和外部记忆网络以及神经注意机制来捕捉用户的全局和细粒度偏好。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/TEMN架构图.png" alt="TEMN" title="">                </div>                <div class="image-caption">TEMN</div>            </figure><br>　　三部分组成：记忆网络，TLDA和地理建模部分。<br>　　前两部分相互联系，用于建模从基于领域的记忆网络中学到的非线性交互（通过历史记录）以及从主题模型中学到的全局偏好。</p><p>　　每一部分分别对应不同的损失函数，进行联合训练。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>　　微信朋友圈签到数据集（未开源）<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/TEMN数据集.png" alt="数据集" title="">                </div>                <div class="image-caption">数据集</div>            </figure></p><h2 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h2><ul><li>MF</li><li>BPR</li><li>LDA</li><li>CML</li><li>LRML</li><li>TEMN(GPR) 保留了记忆模块，将TLDA替换为LDA，去掉了地理模块。</li><li>LORE</li><li>ST-RNN</li><li>TEMN(SPR) 完整TEMN模型使用微信（SPR）数据</li><li>GeoMF</li><li>TLDA</li><li>TEMN(CPR) 完整TEMN模型使用微信（GPR）数据<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/TEMN性能.png" alt="性能" title="">                </div>                <div class="image-caption">性能</div>            </figure></li></ul><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ul><li>提出一种融合基于领域和全局的用户偏好的端到端深度学习框架。</li><li>在兴趣点推荐中设计了能融合多种上下文信息的灵活架构，并使之能在多种推荐场景应用。</li><li>提出一种结合监督和非监督学习的混合模型，并利用了记忆网络和主题模型。通过相互学习机制，模型还能得出用户在受记忆网络影响的主题上的概率分布。</li><li>在微信数据集上进行模型验证，超过基线模型。</li><li>通过在TEMN中引入神经注意机制和主题模型，POI推荐的可解释性得到了显著提高。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/TEMN架构图.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;陆续上架前几个月写的库存&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;主题增强记忆网络个性化兴趣点推荐&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="推荐算法" scheme="https://hubojing.github.io/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>Office三件套笔记</title>
    <link href="https://hubojing.github.io/2022/07/02/office%E4%B8%89%E4%BB%B6%E5%A5%97%E7%AC%94%E8%AE%B0/"/>
    <id>https://hubojing.github.io/2022/07/02/office三件套笔记/</id>
    <published>2022-07-02T01:42:53.000Z</published>
    <updated>2022-07-03T14:53:23.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" width="300" height="180" style="float:right;"><br><br>　　<strong>陆续上架前几个月写的库存</strong><br><br>　　<strong>没想到有一天还会写这篇笔记</strong><br>　　<strong>记录一些稍高阶的玩法</strong><br>　　<strong>写论文后遗症</strong><br> </div><a id="more"></a><h1 id="Word"><a href="#Word" class="headerlink" title="Word"></a>Word</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>样式修改：<br>引用-目录-自定义目录-修改（选项旁边），为不同级别目录进行格式自定义。</p><h2 id="域代码"><a href="#域代码" class="headerlink" title="域代码"></a>域代码</h2><p>快捷键： Alt+F9。</p><p>别在百度里搜陈年包浆老帖了，官方文档不香吗<br><a href="https://support.microsoft.com/zh-cn/office/word-%E4%B8%AD%E7%9A%84%E5%9F%9F%E4%BB%A3%E7%A0%81%E5%88%97%E8%A1%A8-1ad6d91a-55a7-4a8d-b535-cf7888659a51" target="_blank" rel="noopener">官方文档</a></p><h3 id="图注"><a href="#图注" class="headerlink" title="图注"></a>图注</h3><p>Seq（序列）域<br>图注序号标注 域代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图&#123;SEQ 图 \r 1&#125;</span><br></pre></td></tr></table></figure></p><p>即 “图1”</p><h2 id="交叉引用"><a href="#交叉引用" class="headerlink" title="交叉引用"></a>交叉引用</h2><p>交叉引用后要添加或者删除怎么更新：</p><ol><li>在要插入的前一行最后的<strong>换行符前</strong>回车，添加文献</li><li>ctrl+A，右键“更新域”。</li></ol><p>多引用（形如格式[2, 5]）<br>原域代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;REF_Ref56957053 \r \h  *MERGRFORMAT &#125;&#123;REF_Ref56957053 \r \h *MERGRFORMAT &#125;</span><br></pre></td></tr></table></figure></p><p>修改域代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;REF_Ref56957053 \r \h  \#&quot;[0&quot;  \*MERGRFORMAT &#125;&#123;REF_Ref56957053 \r \h  \#&quot;0]&quot;  \*MERGRFORMAT &#125;</span><br></pre></td></tr></table></figure></p><p>手动加中间的逗号。</p><h1 id="Excel"><a href="#Excel" class="headerlink" title="Excel"></a>Excel</h1><ul><li>excel 如何合并相同项并累加<br><a href="https://zhidao.baidu.com/question/75402048.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/75402048.html</a></li><li>如何把2个excel的数据表连起来<br><a href="https://zhidao.baidu.com/question/577259682.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/577259682.html</a></li></ul><h1 id="PPT"><a href="#PPT" class="headerlink" title="PPT"></a>PPT</h1><p>待续..</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;陆续上架前几个月写的库存&lt;/strong&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;没想到有一天还会写这篇笔记&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;记录一些稍高阶的玩法&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;写论文后遗症&lt;/strong&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
    
      <category term="office" scheme="https://hubojing.github.io/tags/office/"/>
    
      <category term="word" scheme="https://hubojing.github.io/tags/word/"/>
    
      <category term="excel" scheme="https://hubojing.github.io/tags/excel/"/>
    
      <category term="ppt" scheme="https://hubojing.github.io/tags/ppt/"/>
    
  </entry>
  
  <entry>
    <title>毕业</title>
    <link href="https://hubojing.github.io/2022/06/29/%E6%AF%95%E4%B8%9A/"/>
    <id>https://hubojing.github.io/2022/06/29/毕业/</id>
    <published>2022-06-29T02:29:24.000Z</published>
    <updated>2022-08-14T16:23:53.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" width="300" height="180" style="float:right;"><br><br><br>　　<strong>一篇六月底就写好、八月中才发布的毕业总结。</strong><br><br><br> </div><a id="more"></a><p>　　技术博客只谈学习和技术。每次我在这里写这种总结文的时候，必须时刻提醒自己这句话，否则我的思路一旦打开，就不知道飞到哪里去了。</p><p>　　对比本科结束时写的<a href="https://hubojing.github.io/2017/03/06/%E5%8F%8D%E7%9C%81/">总结</a>，首先得给自己这三年打个分。<br>　　<br>　　从学习的角度来说，给个65分吧。(其它方面可能要远高于本科时期)</p><p>　　相比于本科时期自己200%投入到学习中的那种专注和疯狂，读研期间的我看起来要“正常”许多。那时候需要用忙碌和疲惫来使自己放松（这句话也许听起来十分奇怪），而读研后的我尝试着逐步和自己和解了。</p><h1 id="最大收获"><a href="#最大收获" class="headerlink" title="最大收获"></a>最大收获</h1><p>　　如果说本科期间我的最大收获是学会了自学的话，读研期间的最大收获有二：学会了读书、科研入了门。<br>　　本科时，每个学期都会给自己强行列个读书方向，比如这学期重点是推理方面、日本作家系列，下学期重点是历史方面、国内作家系列，再下个学期看点俄国文学、美国文学之类的。书是看了一些，但是往往得到最多的是完成任务的快感，并没有真正得到读书的快乐。<br>　　读研时，再没有给自己布置强制性的读书任务。而是在微信读书上凭着兴趣，任意读之。慢慢地，我竟喜欢上了这种读书的感觉，只要是在空隙时间，我都会打开看看书。就这样，我读完了一本又一本书，读完书后的感受各不相同，也许会受主人公的命运而牵绊，也许会通过书籍体验了不同的人生而倍感快乐。我也遇到了一本改变我三观的重要书籍：三体。<br>　　读三体完全是因为看新闻说这本书要被改编成影视了，为了防止影视先入为主的剧情，我决定在影视剧开播前把原著给看完了。三体的三大本着实很厚，但是30个小时读下来也一点不亏。从大的角度上，我对整个人类的观点产生了巨大变化，从个人方面，也改变了我对生活的态度。<br>　　罗马假日里说，要么读书，要么旅行，身体和心灵总有一个要在路上。(You can either travel or read, but either your body or soul must be on the way.)<br>　　我比较宅，对旅游无感，所幸还可以通过读书来认识世界。三年读了几十本书，虽然不多，但是每本都留下了一些笔记和感悟，很多书里的语句也在影响和改变我的行为和看法。当然也有不少技术书，大都是电子版（省钱哈哈哈），希望自己对技术的追求永不停止吧。</p><p>　　学术方面，现在回想起来本科毕业时自己的科研底子很薄弱，是一个科研小白，和现在的学弟学妹们的基础比不了。本科时的学习基本上也都是自己的单打独斗，总体上是一段孤独的旅程。读研给了我一个接触学术和前沿的机会，而三年后的我能够在科研方面入了门，离不开我导的指引、组内的讨论、实习实践和网上大神们的知识共享。</p><h1 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h1><p>　　（更新插一句）这篇文章其它部分六月底就写好了，唯独技术这一节我总觉得写地短了浅了点，拖到如今才完善这一段。<br>　　从通信转到软工，我终于算个科班出身啦哈哈哈。为了缩小和大家的差距，三年里蹭了些课、看了些书、刷了些题，但总归还是觉得自己水平不咋地。但是一想到自己未来还有一辈子可以去学这些东西就令人神往。<br>　　本科关注开发技术，读研关注算法技术。读研之前，在方向的求索问题上，我走了不少弯路，进行过很多简单的尝试。那段时间我依然存在着新手都有的困惑，纠结于编程语言的选择。虽然干着C++开发的活，但因为市场上C++求职岗位比Java岗位数量少，而担忧起C++的未来发展。现在回头来想，还是杞人忧天了些，C++随着AI浪潮的崛起，反而迎来了新的上升期。而我现在也不再纠结于编码语言本身，摆正了对它的看法，终于明白了“编程语言只是工具”这句话的含义。读研之后，由于学术培养，我开始了算法研究之路。科研初期也是跌跌撞撞的，由于比很多同学起步晚，只有自己多看多学才能弥补差距。一开始阅读英文文献也很不习惯很慢，但好在考研期间坚持了几年的英语电台每日一句录制，英语的基础还没有荒废，随着习惯逐渐养成，基本摆脱了中文翻译的操作（其实主要是懒得打开翻译器……所以懒有时候也有帮助哈哈哈哈）。在方向的选择上，研一上学期在看了不多的文献后，大致了解了数据挖掘的基础情况，结合我们组内的具体科研状况、对当时就业市场的观察（CV卷得惨绝人寰、NLP落地尚不明朗、搜广推相对靠近业务且竞争小于前两者，当然，2022年的搜广推已经不是这样了！）以及个人兴趣推动（非常好奇网易云私人FM推荐是如何做的），我鼓足勇气和导师提出了推荐算法方向，没想到的是，我导当场就同意了。结合我们组的特点，我做的是兴趣点推荐算法。想想读研以前，我深感自己没有一个特定的领域导致无法深耕，而现在，我终于拥有了一个自己的研究方向，终于可以在知乎上写上“xxx方向”了哈哈哈。<br>　　兴趣点推荐方向本身，隶属于推荐算法大家庭，所以，为了更好地学习推荐算法，我也不断学习机器学习（包括深度学习）的基础知识，积极了解前沿学术和工业界动态。在这里还有个小插曲，当年入学前，有好几个已经读研的同学们纷纷给我提醒：慎入深度学习深坑！（后来我知道了他们都是搞CV的，求职的时候被卷死……后来怒转开发）但是在我心中已经有了这种印象——远离深度学习，否则会变得不幸，哈哈哈哈哈。幸好我当时拉跨的AI基础让我觉得推荐算法和深度学习这个词看起来很远，所以选了推荐算法时还在沾沾自喜我应该没有入坑吧？属实是TOO YOUNG TOO NAIVE，直到后来阅读每一篇顶会论文都是深度学习时，我才明白天下就是深度学习的天下啊……其实现在的我回看这个观点，我不会认为对，但也并没有全错。深度学习本身只是一种方法，它只有结合到某种场景、某个业务或者某个领域才会产生价值。<br>　　推荐算法目前来说依然是个不错的方向，至少现在它是一个能够落地、有实际应用的方向。但随着互联网增速放缓进入存量时代，搜广推是否仍和之前一样蕴含巨大价值也许值得讨论。在我秋招的那段日子里，我看到过一句话：“这个世界上最聪明的一些头脑，都在哄骗他人去点击广告。（大意如此）”那天这句话对我还是有不小的触动，也许我们做的这些算法是否已经足够甚至过量了呢？信息茧房的危害正在蚕食互联网中的我们，同质化的算法打着个性化的招牌过分挖掘用户隐私的同时，也使人们沉迷在算法里，渐渐抹杀掉很多的创造力。比如网易云，当初是因为喜欢它去研究推荐算法，可是有一天开始，它的私人FM让我觉得不准了，远远不如18年那会儿了，但去搜它官方公开的技术模型，反而迭代地更加复杂，更加高深了。这件事让我常常想，我们的推荐算法会不会早就“过拟合”了？不过，技术本身是不应该附带偏见的，对推荐算法本身我始终以纯粹的技术观点去分析和学习。<br>　　秋招拿的一些offer大都是推荐算法方面的，但是最后我选择了NLP算法。除了一些现实因素的考虑（离家较近）外，选择NLP也是选择了更多的挑战，而我比较享受未知。当然，和推荐算法关联最大的就是NLP算法，两者关联紧密，而NLP算法的应用场景会更大更多，未来总归是NLP的天下（虽然现在是CV的）。所以，打好NLP算法的基础十分重要。我总觉得机器人时代离我们不远了。认知智能在我们这一代一定会实现。另一方面，我选择的领域，让我感觉很有社会价值和意义，这和我建立博客以来就写在副标题上的“为中华之崛起而读书”似乎又贴近了一步。<br>　　即将步入工作岗位，希望在工作中能更好地打磨自己的技术水平，提高编码效率。</p><h1 id="自律"><a href="#自律" class="headerlink" title="自律"></a>自律</h1><p>　　关于自律这件事，远远比不上当年了。即使挂着“自律使人自由”的标语催促着自己上进，也无法再像原来一样。同样都是我，现在的我卷不过以前的我（哈哈哈哈人老了）。我为此不断地想这到底是为什么。是我现在的学习态度不够端正了吗？应该不是。是我变得更加懒惰了吗？好像也不是。后来我可能知道了答案：自律只是一种实现目标的手段，当缺乏必须高度自律才能做到的目标时，自律本身失去了意义。这可能也和我的学习方法改变有关。</p><p>　　三年里，我尝试了一些新的学习方法。以前我按照要趁早的学习模式，干什么都会在一开始就行动。但是久而久之，我不仅有了些强迫症（比如会反复检查作业、格式、要求之类），这无意义地耗费了大量宝贵的时间，心情也不悦（明知没必要但依然会反复检查），而且由于完成的时间很充沛，慢慢地形成了拖延症，而我在很长的时间里将这归结于我是一个慢性子。所以，我开始尝试要求自己不要一开始就行动，而是要在最短的时间内以最高的效率去学习（俗称DDL学习法，滑稽.jpg）。我知道这样是有风险的，毕竟学渣基本上都是DDL学习法的忠实拥护者。但是幸好，我带着意识地去主动尝试，目的是追求高效率，而不是拖到最后不得不做的被动，两者的自我驱动是不一样的。比如，以前上学七点一刻到校，我总是六点就被闹钟叫醒。可是同学们大都六点半才起。这是我第一次意识到自己效率低下或者说为了保证不迟到过于苛刻了。而这损失的半小时睡眠可能使白天的工作效率更低了。读研时，我经常要求自己不要在规定时间提前太多，我要看看我是否拥有这种弹性。事实证明，这些提前的时间就是没必要的，在现有时间内，我也能有条不紊地完成计划。DDL很好地克制住了我反复检查的毛病，而这多出来的时间，应该去做其它更有意义的事情。当然，这个度是难以把握的，一不小心就堕入学渣之境。我现在更加认可两种方法的结合，根据任务的紧急程度和优先级来合理使用这些方法。<br>　　自律应该是自然而然的，当心中有执念时，会主动地做到。如果自律成为一种负担，也许已经是本末倒置了，倒不妨想想自己到底要干什么。</p><p>　　（更新插一句）比如，明天又是周一了，为了早上精力充沛地去上班，我现在就关掉电脑去睡觉了！上班让我作息自律了哈哈哈哈哈哈。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;一篇六月底就写好、八月中才发布的毕业总结。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="杂谈" scheme="https://hubojing.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="毕业" scheme="https://hubojing.github.io/tags/%E6%AF%95%E4%B8%9A/"/>
    
      <category term="总结" scheme="https://hubojing.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>《推荐系统：原理与实践》笔记</title>
    <link href="https://hubojing.github.io/2022/06/15/%E3%80%8A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5%E3%80%8B%E7%AC%94%E8%AE%B0/"/>
    <id>https://hubojing.github.io/2022/06/15/《推荐系统：原理与实践》笔记/</id>
    <published>2022-06-15T02:41:55.000Z</published>
    <updated>2022-06-15T09:06:01.591Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\假装有图片.jpg" width="300" height="180" style="float:right;"><br><br><br>　　<strong>砖头书笔记（自用）</strong><br><br><br> </div><a id="more"></a><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>　　有几本砖头书在图书馆里我不断续借，网上又没有PDF，现在要毕业了，只有勉强把它看完了……</p><h1 id="高级论问题和应用"><a href="#高级论问题和应用" class="headerlink" title="高级论问题和应用"></a>高级论问题和应用</h1><ul><li>推荐系统中的冷启动问题<br>太常见不说了。</li><li>抗攻击推荐系统<br>只要指恶意评论。</li><li>组推荐系统<br>针对一组用户推荐，而不是单一用户。</li><li>多标准推荐系统<br>如，用户可以给予情节、音乐、特效等对电影进行评分。在多标准推荐系统中，用户可能根本没有给出整体评分。</li><li>推荐系统中的主动学习<br>鼓励用户输入评分以完善系统的机制。例如，用户可能会为某些物品评分获得奖励。因此，必须明智地选择由特定用户进行评分的物品。如，某用户已评价大量动作片，那么要求该用户去评价另一部动作电影对预测其他的动作电影评分帮助不大，并且对预测属于无关种类的电影评分的帮助甚至更少。另一方面，要求用户评价不太热门种类的电影将对预测这种类型的电影评分有显著帮助。当然，如果用户被要求评价无关的电影，他不一定能够提供反馈，因为他可能根本没有看过那部电影。<strong>（此处举例我存疑）</strong>因此，在推荐系统的主动学习问题中有许多在其他问题领域（如分类问题）没有遇到的有趣权衡问题。</li><li>推荐系统中的隐私问题</li><li>保护隐私的推荐算法。</li><li>应用领域</li></ul><h1 id="推荐系统评估"><a href="#推荐系统评估" class="headerlink" title="推荐系统评估"></a>推荐系统评估</h1><h2 id="评估设计的总体目标"><a href="#评估设计的总体目标" class="headerlink" title="评估设计的总体目标"></a>评估设计的总体目标</h2><ul><li>精确性</li><li>覆盖率</li><li>置信度和信任度</li><li>新颖度</li><li>惊喜度</li><li>多样性</li><li>健壮性和稳定性</li><li>可扩展性<h2 id="离线评估的精确性指标"><a href="#离线评估的精确性指标" class="headerlink" title="离线评估的精确性指标"></a>离线评估的精确性指标</h2><h3 id="独立预测评分的精确性"><a href="#独立预测评分的精确性" class="headerlink" title="独立预测评分的精确性"></a>独立预测评分的精确性</h3>　　RMSE, MAE<br>　　RMSE计算时用的是误差的平方，所以它更加显著地被大的误差值或者异常值所影响。一些被预测失败的评分会显著地破坏RMSE方法。在各种评分的预测健壮性非常重要的应用中，RMSE可能是一个更加合适的方法。另一方面，当评估的异常值有限时，MAE能更好地反映精确性。RMSE主要的问题是它不是平均误差的真实反映，而且它又是会导致有误导的结果。<h3 id="通过相关性评估排名"><a href="#通过相关性评估排名" class="headerlink" title="通过相关性评估排名"></a>通过相关性评估排名</h3></li><li>Spearman等级相关系数</li><li>肯德尔等级相关系数<h3 id="通过效用评估排名"><a href="#通过效用评估排名" class="headerlink" title="通过效用评估排名"></a>通过效用评估排名</h3>　　基于效用方法的总体目标就是给出用户可能找到推荐系统排名的有用程度的简单量化。这种方法下隐含的一个重要准则就是相对于物品的总量而言，推荐列表是简短的。因此一个具体评分的效用大部分情况下应该基于在推荐列表中相关性高的物品。这种情况下，RMSE指标有一个缺点，因为它对低排名物品和那些高排名物品赋予了同样的权重。</li></ul><p>　　NDCG, ARHR（平均逆命中率）<br>　　ARHR也被称作是平均倒数排名（MRR）</p><h3 id="通过ROC曲线评估排名"><a href="#通过ROC曲线评估排名" class="headerlink" title="通过ROC曲线评估排名"></a>通过ROC曲线评估排名</h3><h1 id="抵抗攻击的推荐系统"><a href="#抵抗攻击的推荐系统" class="headerlink" title="抵抗攻击的推荐系统"></a>抵抗攻击的推荐系统</h1><h2 id="攻击类型"><a href="#攻击类型" class="headerlink" title="攻击类型"></a>攻击类型</h2><ul><li>随机攻击</li><li>均值攻击</li><li>bandwagon攻击</li><li>流行攻击</li><li>爱/憎攻击</li><li>反向bandwagon攻击</li><li>探测攻击</li><li>分段攻击<h2 id="健壮推荐设计策略"><a href="#健壮推荐设计策略" class="headerlink" title="健壮推荐设计策略"></a>健壮推荐设计策略</h2></li><li>用CAPTCHA防止自动攻击</li><li>使用社会信任</li><li>设计健壮的推荐算法</li></ul><h1 id="排名学习"><a href="#排名学习" class="headerlink" title="排名学习"></a>排名学习</h1><p>　　pointwise<br>　　pairwise: BPR, Eigen Rank, pLPA, CR<br>　　listwise: NDCG, MRR</p><h1 id="多臂赌博机算法"><a href="#多臂赌博机算法" class="headerlink" title="多臂赌博机算法"></a>多臂赌博机算法</h1><h1 id="组推荐系统"><a href="#组推荐系统" class="headerlink" title="组推荐系统"></a>组推荐系统</h1><ul><li>协同和基于内容的系统</li><li>基于知识的系统<h1 id="多标准推荐系统"><a href="#多标准推荐系统" class="headerlink" title="多标准推荐系统"></a>多标准推荐系统</h1></li><li>基于近邻的方法</li><li>基于集成的方法</li><li>无整体评分的多标准系统<h1 id="推荐系统中的主动学习"><a href="#推荐系统中的主动学习" class="headerlink" title="推荐系统中的主动学习"></a>推荐系统中的主动学习</h1></li><li>基于异质性的模型</li><li>基于性能的模型<h1 id="推荐系统中的隐私"><a href="#推荐系统中的隐私" class="headerlink" title="推荐系统中的隐私"></a>推荐系统中的隐私</h1></li><li>基于冷凝的隐私</li><li>高维数据的挑战</li></ul><h1 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h1><ul><li>门户内容个性化</li><li>计算广告与推荐系统</li><li>互惠推荐系统<br>　　基本思想是当考虑多个具有不对称兴趣的利益相关人的推荐的效用时，推荐的任务会发生改变。如在线约会的互惠推荐系统。</li></ul><ol><li>用户意识到交易的成功取决于另一方的许可。另一方是互惠环境中的“物品”。</li><li>用户和物品在系统中可能只出现一次，在一次成功的事物后它们可能永远不会重现。冷启动问题在互惠场景中更加显著。<br>　　方法：</li><li>利用混合方法<br>在这些方法中，两个传统的推荐方法被构造出来，分别对应着两个互惠方的喜好。然后，这两个互惠方的预测被组合起来。</li><li>利用链路预测方法<br>当冷启动问题不是很严重或者可以用来自类似用户和物品的数据来增加评分数据时，可以在系统中采用链路预测方法。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;\images\假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;砖头书笔记（自用）&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="推荐系统" scheme="https://hubojing.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="推荐算法" scheme="https://hubojing.github.io/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>2022年最新教程！Hexo + GitLab搭建个人博客详细教程</title>
    <link href="https://hubojing.github.io/2022/06/08/Hexo+GitLab%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%9C%80%E6%96%B0%E6%95%99%E7%A8%8B/"/>
    <id>https://hubojing.github.io/2022/06/08/Hexo+GitLab搭建个人博客最新教程/</id>
    <published>2022-06-08T02:19:16.000Z</published>
    <updated>2022-06-11T11:19:36.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\Hexo+Gitlab.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>不是标题党，我自己刚写的，保证最新。（2022年6月）</strong><br><br><br> </div><a id="more"></a><h1 id="前言（可不看）"><a href="#前言（可不看）" class="headerlink" title="前言（可不看）"></a>前言（可不看）</h1><p>　　以前生活博客放在Gitee上，每次命令部署后还得登录网页管理端手动更新一下Page服务才能完成一次部署，着实很麻烦。<del>懒人要贯彻到底，</del>为追求效率，弃之转GitLab。<br>　　幸好生活博客都是我<del>静悄悄</del>自娱自乐写写东西，没推广，百度也搜不到，基本没人看，损失的点击数不心疼哈哈哈。</p><p>　　但是，全网我竟然搜不到一篇像样的GitLab搭建博客教程（很多都是三四年前的，过时了，都不教GitLab的runners如何自建的。），反观Github搭建博客教程可是满天飞！</p><p>　　是<strong>GitLab</strong>，不是<strong>GitHub</strong>，看错请在下方评论哈哈哈。</p><p>　　不能忍，我只好自己写了。（草稿箱里这几个月堆积的其它文章都还没发……属实是和博客纠纠缠缠多少年）</p><h1 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h1><p>　　前置条件：安装Node.js和Git。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br><span class="line">hexo init blog</span><br><span class="line"><span class="built_in">cd</span> blog</span><br><span class="line">npm install</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure></p><p>　　本地能运行<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> ，ok。</p><h1 id="GitLab"><a href="#GitLab" class="headerlink" title="GitLab"></a>GitLab</h1><p><a href="https://hexo.io/docs/gitlab-pages" target="_blank" rel="noopener">官网指引</a><br>　　<strong>看英文版！</strong><br>　　<strong>看英文版！</strong><br>　　<strong>看英文版！</strong><br>　　重要的事情说三遍！我中途看了一下中文版，被坑了好几次。那个中文网的配置文件不对，部署疯狂报错！！！（中英文文档版本竟然不一致，我也是醉了…）</p><ol><li>GitLab账户注册。</li><li>创建一个username.github.io的项目，或者把已有项目更名为此，可以选择Private。</li><li>Settings &gt; CI/CD &gt; Runners &gt; Enable，开启Runners。</li></ol><p>　　重点来了！！！</p><blockquote><p>Pipeline failing? To keep GitLab spam and abuse free we ask that you verify your identity.Until then, shared runners will be unavailable. Validate your account or use your own runners.</p></blockquote><p>　　GitLab要求上传身份证（经评论区指正，是信用卡号）才给用shared runners。Validate是不可能validate的。现有的教程到这里都是直接用共享runners，我猜前几年可能GitLab无需验证这一步吧。</p><p>　　既然还有自建Runners这种方法当然要试一试了。</p><h2 id="GitLab自建Runners"><a href="#GitLab自建Runners" class="headerlink" title="GitLab自建Runners"></a>GitLab自建Runners</h2><p>　　首先，这个东西是干什么用的呢？Github部署博客时，是在本地<code>hexo g</code>生成好静态页面，然后把静态页面<code>hexo d</code>部署上去。而GitLab不同，它要把所有源文件push到项目中，当push后，GitLab会自动调用一个叫runners的玩意儿帮项目自动生成页面并部署。它本身是个优化的东西，叫CI/CD，也就是持续集成、持续交付和持续部署，用它可以很好地实现自动化开发。</p><p>　　介绍完毕，开始安装。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><a href="https://docs.gitlab.com/runner/install/" target="_blank" rel="noopener">https://docs.gitlab.com/runner/install/</a></p><p>　　以windows为例。<br><a href="https://docs.gitlab.com/runner/install/windows.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/install/windows.html</a></p><ol><li>创建一个文件夹，如E:\GitLab-Runner。</li><li>下载二进制文件。</li><li>限制文件夹写权限。(我没特地设置)</li><li>打开cmd。</li><li>注册一个runner。<br>　　怎么注册呢？这里也是一个坑巨多的地方。想建博客的小伙伴们就别想那么多了，跟着我一步步走就完事了。</li></ol><h3 id="注册Runner"><a href="#注册Runner" class="headerlink" title="注册Runner"></a>注册Runner</h3><p><a href="https://docs.gitlab.com/runner/register/index.html" target="_blank" rel="noopener">https://docs.gitlab.com/runner/register/index.html</a></p><ol><li><p>在刚才下载好文件的文件夹中打开cmd运行</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\gitlab-runner.exe register</span><br></pre></td></tr></table></figure></li><li><p>输入URL。这个URL在哪找呢？Settings-CI/CD Settings-Runners-Specific runners，里面就有URL。一般是<a href="https://gitlab.com/" target="_blank" rel="noopener">https://gitlab.com/</a> 。</p></li><li>输入token。</li><li>输入描述。可不写。</li><li>输入tag。最好不写。否则还得后面还得去设置untag。</li><li>输入备注。可不写。</li><li>输入runner执行器。我写的shell。结束注册。如果是docker，后面还要输入默认image。</li></ol><p>　　怎么验证我的runner是好的呢？<br>　　Settings-Runners-Specific runners下方出现刚才建立的Runner，并且前面有个绿色的圆圈。如果是感叹号，证明上面的过程出现问题。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ol><li>使用<code>node --version</code>检查Node.js版本，记录下来（比如v16.y.z）。</li><li><p>在项目中增加<code>.gitlab-ci.yml</code>文件，其中将<code>16</code>替换为自己Node.js的版本：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="attr">node:16-alpine</span></span><br><span class="line"><span class="attr">cache:</span></span><br><span class="line"><span class="attr">  paths:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">node_modules/</span></span><br><span class="line"></span><br><span class="line"><span class="attr">before_script:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">npm</span> <span class="string">install</span> <span class="string">hexo-cli</span> <span class="bullet">-g</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">npm</span> <span class="string">install</span></span><br><span class="line"></span><br><span class="line"><span class="attr">pages:</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">npm</span> <span class="string">run</span> <span class="string">build</span></span><br><span class="line"><span class="attr">  artifacts:</span></span><br><span class="line"><span class="attr">    paths:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">public</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">    - if:</span> <span class="string">$CI_COMMIT_BRANCH</span> <span class="string">==</span> <span class="string">$CI_DEFAULT_BRANCH</span></span><br></pre></td></tr></table></figure></li><li><p>将hexo文件夹push到GitLab。一旦push完成，GitLab自动部署开始。</p></li><li>当GitLib CI成功部署，username.gitlab.io就能运行了。</li><li>（可选）如果希望检查生成的站点资产(html、css、js等)，可看<a href="https://docs.gitlab.com/ee/ci/pipelines/job_artifacts.html" target="_blank" rel="noopener">https://docs.gitlab.com/ee/ci/pipelines/job_artifacts.html</a> 。</li></ol><p>　　注意，网站看起来似乎能运行了，结果把GitLab账号退出后再点击网站就看不到了，而是转到GitLab要登录。这是因为项目本身是Private的，需要把Page页的权限设置为Public！<br>　　Settings-&gt;General-&gt;Visibility, project features, permissions，仓库权限保持private，下面的Pages选项改为Everyone。</p><h1 id="一些报错解决方法"><a href="#一些报错解决方法" class="headerlink" title="一些报错解决方法"></a>一些报错解决方法</h1><ol><li>GitLab push报错。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> existing_repo</span><br><span class="line">git init</span><br><span class="line">git remote add origin https://gitlab.com/username/username.gitlab.io.git</span><br><span class="line">git branch -M main</span><br><span class="line">git push -uf origin main</span><br></pre></td></tr></table></figure></li></ol><p>　　报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">! [remote rejected] main -&gt; main (pre-receive hook declined)</span><br></pre></td></tr></table></figure></p><p>　　这是因为main分支默认是protected，需要在Settings-Repository-Protected branch，修改权限。</p><ol><li>部署时runner报错。<blockquote><p>ERROR: Job failed (system failure): prepare environment: failed to start process: exec: “pwsh”: executable file not found in %PATH%.</p></blockquote></li></ol><p>　　转到GitLab运行程序的安装目录，如E:\GitLab-Runner。记事本打开config.toml文件，并用powershell替换pwsh，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[runners]]</span><br><span class="line">  shell = &quot;pwsh&quot;</span><br></pre></td></tr></table></figure></p><p>改为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell = &quot;powershell&quot;</span><br></pre></td></tr></table></figure></p><h1 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h1><p>　　换到GitLab部署后，总体效率是不错，一次push就完事儿，还把源文件备份的工作一道给解决了，而不是像Github部署那样，项目内只存页面。而且page打开速度似乎也比Gitee快不少。缺点就是GitLab自动部署比自己手动<code>hexo d</code>的速度要慢。<br>　　把生活博客切换修好花了我大半天时间，踩了好多坑（之前没咋用过GitLab）。干脆把过程整理出来造福有需要的人吧。知识共享、开源精神yyds！<br>　　(难得我还为此博文专门做了一张封面图，虽然很丑)</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;\images\Hexo+Gitlab.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;不是标题党，我自己刚写的，保证最新。（2022年6月）&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
    
      <category term="博客" scheme="https://hubojing.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="GitLab" scheme="https://hubojing.github.io/tags/GitLab/"/>
    
  </entry>
  
  <entry>
    <title>关于TensorFlow和Pytorch的GPU版本配置问题</title>
    <link href="https://hubojing.github.io/2022/04/18/%E5%85%B3%E4%BA%8ETensorFlow%E5%92%8CPytorch%E7%9A%84GPU%E7%89%88%E6%9C%AC%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/"/>
    <id>https://hubojing.github.io/2022/04/18/关于TensorFlow和Pytorch的GPU版本配置问题/</id>
    <published>2022-04-18T14:13:41.000Z</published>
    <updated>2022-04-19T08:46:49.288Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\假装有图片.jpg" width="300" height="180" style="float:right;"><br><br><br>　　<strong>相关安装问题汇总</strong><br><br><br> </div><a id="more"></a><h1 id="关于版本是否适配"><a href="#关于版本是否适配" class="headerlink" title="关于版本是否适配"></a>关于版本是否适配</h1><p>python, cuda, cudnn, tf/torch版本需要适配！<br>组合不是任意的，建议先看好版本再去下载。</p><h1 id="下载链接"><a href="#下载链接" class="headerlink" title="下载链接"></a>下载链接</h1><p>显卡驱动下载<a href="https://www.nvidia.com/Download/index.aspx?lang=en-us" target="_blank" rel="noopener">https://www.nvidia.com/Download/index.aspx?lang=en-us</a></p><p>cuda版本下载<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-downloads</a><br>cuda历史版本下载<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a><br>cudnn版本下载<a href="https://developer.nvidia.com/rdp/cudnn-download" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-download</a><br>cudnn历史版本下载<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a></p><p>python+cuda+cudnn+tf版本适配查询<a href="https://www.tensorflow.org/install/source_windows" target="_blank" rel="noopener">https://www.tensorflow.org/install/source_windows</a><br>pytorch+cuda版本适配查询<a href="https://pytorch.org/get-started/previous-versions/" target="_blank" rel="noopener">https://pytorch.org/get-started/previous-versions/</a></p><p>pytorch下载<a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener">https://pytorch.org/get-started/locally/</a><br>pytorch历史版本<a href="https://pytorch.org/get-started/previous-versions/" target="_blank" rel="noopener">https://pytorch.org/get-started/previous-versions/</a></p><h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>分清本地环境和虚拟环境。<br>在cmd直接安装的是在本地环境里，若在虚拟环境中安装，需要在cmd中切换到虚拟环境。<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 创建新的conda环境</span><br><span class="line">conda create -n poiRec python=<span class="number">3</span>.<span class="number">7</span></span><br><span class="line"># 进入虚拟环境</span><br><span class="line">activate poiRec</span><br><span class="line"># 退出当前conda环境</span><br><span class="line">conda deactivate</span><br><span class="line">删除环境（先退出该环境）</span><br><span class="line">conda remove -n poiRec --all</span><br></pre></td></tr></table></figure></p><h1 id="conda一键配环境"><a href="#conda一键配环境" class="headerlink" title="conda一键配环境"></a>conda一键配环境</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># cuda 不写版本自动选择</span><br><span class="line">conda install cudatoolkit=10.0</span><br><span class="line"># cudnn 不写版本自动选择</span><br><span class="line">conda install cudnn=7.0.5</span><br><span class="line"># 安装tf</span><br><span class="line">conda install tensorflow-gpu==1.15.0</span><br><span class="line"># 安装pytorch 复制官方命令 注意版本适配</span><br><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch</span><br></pre></td></tr></table></figure><h1 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h1><p>查看CUDA版本<br>C:\Windows\System32&gt;nvidia-smi.exe<br>cmd中在C:\Windows\System32下<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure></p><h1 id="Tensorflow-gpu"><a href="#Tensorflow-gpu" class="headerlink" title="Tensorflow-gpu"></a>Tensorflow-gpu</h1><p>查看版本<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure></p><p>查看设备<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">gpus = tf.config.experimental.list_physical_devices(device_type=<span class="string">'GPU'</span>)</span><br><span class="line">cpus = tf.config.experimental.list_physical_devices(device_type=<span class="string">'CPU'</span>)</span><br><span class="line">print(gpus)</span><br><span class="line">print(cpus)</span><br></pre></td></tr></table></figure></p><p>查看是否有GPU<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line">gpu_device_name = tf.test.gpu_device_name()</span><br><span class="line">print(gpu_device_name)</span><br></pre></td></tr></table></figure></p><p>查看GPU是否可用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.test.is_gpu_available()</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.python.client import device_lib</span><br><span class="line"> </span><br><span class="line"># 列出所有的本地机器设备</span><br><span class="line">local_device_protos = device_lib.list_local_devices()</span><br><span class="line">print(local_device_protos)</span><br><span class="line"> </span><br><span class="line"># 只打印GPU设备</span><br><span class="line">[print(x) for x in local_device_protos if x.device_type == &apos;GPU&apos;]</span><br></pre></td></tr></table></figure><p>查看GPU是否可用的第二种方法<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定在cpu上运行</span></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    cpu_a = tf.random.normal([<span class="number">10000</span>, <span class="number">1000</span>])</span><br><span class="line">    cpu_b = tf.random.normal([<span class="number">1000</span>, <span class="number">2000</span>])</span><br><span class="line">    cpu_c = tf.matmul(cpu_a, cpu_b)</span><br><span class="line">print(<span class="string">"cpu_a:"</span>, cpu_a.device)</span><br><span class="line">print(<span class="string">"cpu_b:"</span>, cpu_b.device)</span><br><span class="line">print(<span class="string">"cpu_c:"</span>, cpu_c.device)</span><br><span class="line"><span class="comment"># 查看gpu是否可用</span></span><br><span class="line">print(tf.config.list_physical_devices(<span class="string">'GPU'</span>))</span><br><span class="line"><span class="comment"># 指定在gpu上运行</span></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br><span class="line">    gpu_a = tf.random.normal([<span class="number">10000</span>, <span class="number">1000</span>])</span><br><span class="line">    gpu_b = tf.random.normal([<span class="number">1000</span>, <span class="number">2000</span>])</span><br><span class="line">    gpu_c = tf.matmul(gpu_a, gpu_b)</span><br><span class="line">print(<span class="string">"gpu_a:"</span>, gpu_a.device)</span><br><span class="line">print(<span class="string">"gpu_b:"</span>, gpu_b.device)</span><br><span class="line">print(<span class="string">"gpu_c:"</span>, gpu_c.device)</span><br></pre></td></tr></table></figure></p><p>比较CPU和GPU运行时间<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpu_run</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">        cpu_a = tf.random.normal([<span class="number">10000</span>, <span class="number">1000</span>])</span><br><span class="line">        cpu_b = tf.random.normal([<span class="number">1000</span>, <span class="number">2000</span>])</span><br><span class="line">        c = tf.matmul(cpu_a, cpu_b)</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gpu_run</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br><span class="line">        gpu_a = tf.random.normal([<span class="number">10000</span>, <span class="number">1000</span>])</span><br><span class="line">        gpu_b = tf.random.normal([<span class="number">1000</span>, <span class="number">2000</span>])</span><br><span class="line">        c = tf.matmul(gpu_a, gpu_b)</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cpu_time = timeit.timeit(cpu_run, number=<span class="number">10</span>)</span><br><span class="line">gpu_time = timeit.timeit(gpu_run, number=<span class="number">10</span>)</span><br><span class="line">print(<span class="string">"cpu:"</span>, cpu_time, <span class="string">"  gpu:"</span>, gpu_time)</span><br></pre></td></tr></table></figure></p><h1 id="Pytorch-gpu"><a href="#Pytorch-gpu" class="headerlink" title="Pytorch-gpu"></a>Pytorch-gpu</h1><p>查看版本<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">print(torch.__version__) <span class="comment">#查看pytorch版本</span></span><br><span class="line">print(torch.cuda_version) <span class="comment">#查看cuda版本</span></span><br><span class="line">print(torch.cuda.is_available()) <span class="comment">#查看cuda是否可用</span></span><br></pre></td></tr></table></figure></p><p>装pytorch+CUDA<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch==<span class="number">1.8</span><span class="number">.1</span>+cu101 torchvision==<span class="number">0.9</span><span class="number">.1</span>+cu101  -f https://download.py torch.org/whl/cu101/torch_stable.html</span><br></pre></td></tr></table></figure></p><p>安装特定版本<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch==<span class="number">1.1</span><span class="number">.0</span> -f https://download.pytorch.org/whl/torch_stable.html</span><br></pre></td></tr></table></figure></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证GPU是否能用</span></span><br><span class="line">print(<span class="string">"torch.cuda.is_available():"</span>, torch.cuda.is_available())</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;\images\假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;相关安装问题汇总&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="数据挖掘" scheme="https://hubojing.github.io/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="TensorFlow" scheme="https://hubojing.github.io/tags/TensorFlow/"/>
    
      <category term="Pytorch" scheme="https://hubojing.github.io/tags/Pytorch/"/>
    
      <category term="GPU" scheme="https://hubojing.github.io/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>技术博客访问量超过十万</title>
    <link href="https://hubojing.github.io/2022/04/13/%E5%8D%9A%E5%AE%A2%E8%AE%BF%E9%97%AE%E9%87%8F%E8%B6%85%E8%BF%87%E5%8D%81%E4%B8%87/"/>
    <id>https://hubojing.github.io/2022/04/13/博客访问量超过十万/</id>
    <published>2022-04-13T06:30:18.000Z</published>
    <updated>2022-04-13T09:27:05.196Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/博客十万访问量.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>随手写之，有感而发。</strong><br><br><br> </div><a id="more"></a><p>　　这两天，我突然发现这个技术博客总访问量超过十万了。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/博客十万访问量.png" alt="记录" title="">                </div>                <div class="image-caption">记录</div>            </figure><br>　　这个统计值不一定非常准确，它只记录了现在的域名的访问量，以前的域名访问量都丢失了。不过无所谓啦，记录这个访问量本来也就图一乐。</p><p>　　昨天访问友链的时候，不少技术博主都断更很久了。然而我私信一些博主问他们以后是否继续写博时，他们都不约而同的说，会的。我想，这是一个写博爱好者放不下的兴趣爱好吧。</p><p>　　访问量十万，用了七年。数据本身其实我并不在意，<del>只是借着这个数字又可以水一篇博文(滑稽.jpg)。</del>只是这个小小的博客也伴随我走过了七年的青春时光，可以说是我的朋友。</p><p>　　友链说，“一看你的博文都已经一百四五十篇了，我这输出太寒碜了&gt;_&lt;”，我这才自己数了数，还真有这么多。虽然这些文章多半没什么质量和价值，往往是一些零碎的笔记，不过是我相信好记性不如烂笔头而敲键盘又比用笔写字快的一种娱乐方式。我不爱说自己写文章是在“输出”，因为这个词给人一种写文章的人好像刻意要教给他人什么东西一样似的。我仅仅是用来“记录”，这个词似乎更合适一些。在许多时候，往往是我认为自己状态很颓废时，就会要求自己写点技术文章。其它时候大多是有感而发、灵感乍现，或者说，单纯是写出来让自己快乐，并不打算教给任何人什么东西<del>，而且自己写的什么玩意儿心中有数（滑稽.jpg）</del>。当然，如果碰巧有读者点开了某篇我的文章，并且觉得对自己有些帮助，那给我带来的就是双倍的快乐。</p><p>　　现在好多技术博主转型，也许去写公众号，也许去开课，也许去平台写文章，也许去直播写代码等等。或为名，或为利，或为能力提升。我写博呢，曾经是为了玩，现在主要也是为了玩哈哈哈哈。当然，要是玩的时候顺带着让我变强了就更好了<del>（不要秃）</del>！写博客这个事情变得越来越小众，不过还是留下了一些人。我总是会隔一段时间去逛逛，耐心的看看有些朋友在博客上写下的长篇大论，即使下面没有任何的评论，但是大家依然乐此不彼的更新着。只有在这种时候，似乎还能感受到一种互联网上的“慢”，一种即使没有观众也能自娱自乐的闲适。</p><p>　　我的博客是比较幸运的，偶尔能得到一些网友的关注，这些让我觉得我的博客始终活着。感谢一直关注我、随机关注我、默默关注我、误入点击的广大网友们。十万的点击量可能算不了什么，现在一篇公众号爆款文章的点击量随随便便就是十万，不过对于一个默默无闻的小博主来说依然是值得开心的事情，我喜欢这种慢悠悠到来的感觉。（不过要是写一个记录点击量贡献最大之人的功能，我猜结果肯定是我自己……）</p><p>　　最后，显然这篇文章不是在我的计划内，但是我实在压不住我这敲键盘的手上来就是一阵码字，索性就放任它了。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/博客十万访问量.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;随手写之，有感而发。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="杂谈" scheme="https://hubojing.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="博客" scheme="https://hubojing.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>LSTPM</title>
    <link href="https://hubojing.github.io/2022/02/25/Paper_LSTPM/"/>
    <id>https://hubojing.github.io/2022/02/25/Paper_LSTPM/</id>
    <published>2022-02-25T07:59:46.000Z</published>
    <updated>2022-02-25T13:55:09.816Z</updated>
    
    <content type="html"><![CDATA[<p><div align="left"><br><img src="/images/LSTPM架构.png" width="300" height="180" style="float:right;"></div></p><p>　　<strong>Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation</strong><br>　　下一步去哪儿：用户长短期偏好建模用于兴趣点推荐</p><p><br><a id="more"></a></p><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>　　Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation<br>　　下一步去哪儿：用户长短期偏好建模用于兴趣点推荐<br>　　AAAI 2020<br>　　<a href="https://ojs.aaai.org/index.php/AAAI/article/view/5353" target="_blank" rel="noopener">PDF</a><br>　　<a href="https://github.com/NLPWM-WHU/LSTPM" target="_blank" rel="noopener">CODE</a></p><h1 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h1><p>　　现有的基于RNN的方法在对用户的短期偏好建模时，要么忽略了用户的长期偏好，要么忽略了最近访问的兴趣点之间的地理关系，从而使得推荐结果不可靠。（所有基于RNN/LSTM的短期偏好建模方法都存在不能对两个非连续兴趣点之间的关系建模的缺点。）<br>　　为此，提出LSTPM（Long- and Short-Term Preference Modeling）架构。</p><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/LSTPM架构.png" alt="架构" title="">                </div>                <div class="image-caption">架构</div>            </figure><p>　　它包含三个部分：长期偏好建模、短期偏好建模和预测模块。</p><h2 id="长期偏好建模"><a href="#长期偏好建模" class="headerlink" title="长期偏好建模"></a>长期偏好建模</h2><p>　　核心：使用非局部神经操作（nonlocal neural operation）建模长期偏好。<br>　　以前的做法是直接用LSTM建模签到序列，但是对时间戳的认识不够深。比如人们会在中午时间去餐馆，在晚上去酒吧。所以本文提出了融合时间戳去捕捉时间敏感的属性。论文将一周分成48个段slot（24个工作日段和24个周末段）。计算每两个时间段之间用户签到的兴趣点集合相似性。重合的兴趣点越多，相似性越高。<br>　　所以历史签到轨迹就可以用这些时间段的兴趣点来表示，从而可以给这些时间段加权重。时间越近影响越大。<br>　　同时，地理方面计算了各轨迹的中心，计算中心与最近轨迹相似度，得出距离加权公式。</p><p>　　<strong>关键理解</strong>：非局部神经操作是什么意思呢？<br>　　这个基本想法来自计算机视觉任务，论文<a href="https://arxiv.org/pdf/1711.07971v1.pdf" target="_blank" rel="noopener">Non-local Neural Networks</a>它主张在输入信号的每一个位置的表示都通过全部位置的特征加权求和来对非局部的、长范围的依赖进行建模。<br>$$y_i = \frac{1}{C(x)}\sum{_{\forall j}f(x_i, x_j)g(x_j)}$$<br>　　<code>f</code>用来度量输出位置和周围其他位置的尺度（例如相似度），<code>g</code>是在位置j对于输入信号的表示（如卷积操作）。对于non-local behaiver来说，上式中的<code>j</code>是取遍所有可能的邻居，而对于local操作，如3*3的卷积来说，<code>j</code>只是取了周围8个像素点。<br>　　所以这里借鉴这个思想，将每个轨迹S都和历史轨迹和当前轨迹进行了分数计算，并除以标准化因素（全部特征求和）。</p><h2 id="短期偏好建模"><a href="#短期偏好建模" class="headerlink" title="短期偏好建模"></a>短期偏好建模</h2><p>　　核心：使用联合方式的地理扩张LSTM建模短期偏好。<br>　　RNN本身只能用于序列建模，所以有人提出了跳步RNN。但是跳步RNN总是事先定义好和固定好的。所以提出geo-dilated LSTM根据地理和时间因素，来自动决定使用哪些相关输入。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/LSTPM架构2.png" alt="geo-dilated LSTM" title="">                </div>                <div class="image-caption">geo-dilated LSTM</div>            </figure><br>　　直观地，我们的地理扩张LSTM首先从当前轨迹中挑选poi作为输入，其具有由地理相关性确定的不同跳跃长度，然后通过扩展LSTM方案学习短期用户偏好。具体的算法论文给出了伪代码。</p><p>　　<strong>关键理解</strong>：那它究竟是怎么自动确定跳跃长度的呢？<br>　　如上图所示，标准的LSTM序列是从l1-&gt;l2-&gt;l3-&gt;l4-&gt;l5。但是加入地理距离后发现，对于l3的前面两个兴趣点l1和l2来说，l1到l3的距离比l1到l2的距离要近，所以留下{l1, l2}路径。依次类推，留下{l1, l2}{l2, l5}路径，也就是两跳。所以，将LSTM设计为两跳。</p><p>　　最后的表示，是标准LSTM和geo-dilated LSTM的平均向量。</p><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>　　将长短期偏好联结起来，设置一个W全部兴趣点的可训练投影矩阵参数。预测的是下一个时间段t内目标用户最可能访问的兴趣点。损失函数是负对数似然函数。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>　　Foursqure, Gowalla</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/LSTPM_datasets.png" alt="数据集" title="">                </div>                <div class="image-caption">数据集</div>            </figure><h2 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h2><ul><li>LSTM</li><li>Time-LSTM</li><li>ST-RNN</li><li>TMCA</li><li>CARA</li><li>DCRF</li><li>DeepMove</li><li>STGN<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2></li><li>召回率Recall</li><li>NDCG</li></ul><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><h3 id="基线对比"><a href="#基线对比" class="headerlink" title="基线对比"></a>基线对比</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/LSTPM性能.png" alt="性能" title="">                </div>                <div class="image-caption">性能</div>            </figure><h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/LSTPM自身对比.png" alt="消融实验" title="">                </div>                <div class="image-caption">消融实验</div>            </figure><h3 id="参数分析"><a href="#参数分析" class="headerlink" title="参数分析"></a>参数分析</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/LSTPM参数分析.png" alt="参数分析" title="">                </div>                <div class="image-caption">参数分析</div>            </figure><h3 id="跳数自动化"><a href="#跳数自动化" class="headerlink" title="跳数自动化"></a>跳数自动化</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/LSTPM_LSTM对比.png" alt="LSTM对比" title="">                </div>                <div class="image-caption">LSTM对比</div>            </figure><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ol><li>提出LSTPM框架解决上述存在的问题。</li><li>LSTPM受非局部操作（nonlocal operations）和dilated RNNs的启发，在构建长期偏好时，设计了非局部操作网络结构来探索历史和最近轨迹的时空联系。在克服RNN在短期用户偏好建模的限制时，提出geo-dilated RNN来全面探索非连续兴趣点间的地理联系。</li><li>在真实世界数据集上效果超过SOTA模型。</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/py184473894/article/details/85322937" target="_blank" rel="noopener">https://blog.csdn.net/py184473894/article/details/85322937</a><br><a href="https://zhuanlan.zhihu.com/p/85776086" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/85776086</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/LSTPM架构.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation&lt;/strong&gt;&lt;br&gt;　　下一步去哪儿：用户长短期偏好建模用于兴趣点推荐&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
      <category term="LSTPM" scheme="https://hubojing.github.io/tags/LSTPM/"/>
    
      <category term="Non-local Neural Networks" scheme="https://hubojing.github.io/tags/Non-local-Neural-Networks/"/>
    
  </entry>
  
  <entry>
    <title>ASGNN</title>
    <link href="https://hubojing.github.io/2022/01/29/Paper_ASGNN/"/>
    <id>https://hubojing.github.io/2022/01/29/Paper_ASGNN/</id>
    <published>2022-01-29T06:27:42.000Z</published>
    <updated>2022-02-09T09:22:32.359Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/ASGNN-1.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>Attentive sequential model based on graph neuralnetwork for next poi recommendation</strong><br>　　基于图神经网络的注意力序列模型用于下一个兴趣点推荐<br><br><br> </div><a id="more"></a><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>　　Attentive sequential model based on graph neuralnetwork for next poi recommendation<br>　　基于图神经网络的注意力序列模型用于下一个兴趣点推荐<br>　　WWW21<br><a href="https://link.springer.com/content/pdf/10.1007/s11280-021-00961-9.pdf" target="_blank" rel="noopener">PDF</a><br>　　关键词：推荐系统、序列推荐、兴趣点推荐、图神经网络、注意力机制</p><h1 id="现有问题"><a href="#现有问题" class="headerlink" title="现有问题"></a>现有问题</h1><p>　　传统推荐方法忽略了用户短时偏好的动态变化。另外，许多现有方法不能完全探索兴趣点签到序列中复杂的联系和转变形式。</p><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>　　提出ASGNN。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-1.png" alt="架构" title="">                </div>                <div class="image-caption">架构</div>            </figure><br>　　ASGNN包括四部分：兴趣点签到序列图构建、特征表示学习、长短时偏好获取、兴趣点推荐</p><h2 id="兴趣点签到序列图构建"><a href="#兴趣点签到序列图构建" class="headerlink" title="兴趣点签到序列图构建"></a>兴趣点签到序列图构建</h2><p>　　G(V, E), V = (U, L)，U是用户集，L是兴趣点集。E包括用户-兴趣点边和兴趣点-兴趣点边。<br>　　图中边的权重代表用户在兴趣点的签到次数。</p><h2 id="特征表示学习"><a href="#特征表示学习" class="headerlink" title="特征表示学习"></a>特征表示学习</h2><p>　　图构建好后，使用GNN学习到用户和兴趣点的低维表示。这避免了马尔科夫决策过程需要的大量状态。<br>　　为了提高效率更新节点，使用了GGNN。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-3.png" alt="矩阵表示" title="">                </div>                <div class="image-caption">矩阵表示</div>            </figure></p><h2 id="长短时偏好获取"><a href="#长短时偏好获取" class="headerlink" title="长短时偏好获取"></a>长短时偏好获取</h2><p>　　设计了两层注意力机制分别捕获长短时用户偏好。</p><h2 id="兴趣点推荐"><a href="#兴趣点推荐" class="headerlink" title="兴趣点推荐"></a>兴趣点推荐</h2><p>　　上一步得到的个性化用户偏好参数和兴趣点特征点乘，得到每个兴趣点分数，通过softmax标准化输出概率值。<br>　　训练的损失函数为交叉熵函数。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>　　围绕下列问题展开：</p><ul><li>ASGNN在序列兴趣点推荐任务上性能如何（基线对比）</li><li>ASGNN的关键组件效果如何（组件实验）</li><li>ASGNN的嵌入维度对推荐的影响（维度分析）</li><li>ASGNN和基线在不同稀疏性的数据集上的性能如何（数据稀疏性影响）</li><li>ASGNN学习兴趣点嵌入是否有效（可视化说明）</li></ul><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>　　Gowalla, FourSquare, Brightkite<br><a href="https://snap.stanford.edu/data/loc-gowalla.html" target="_blank" rel="noopener">https://snap.stanford.edu/data/loc-gowalla.html</a><br><a href="https://sites.google.com/site/yangdingqi/home/foursquare-dataset" target="_blank" rel="noopener">https://sites.google.com/site/yangdingqi/home/foursquare-dataset</a><br><a href="https://snap.stanford.edu/data/loc-brightkite.html" target="_blank" rel="noopener">https://snap.stanford.edu/data/loc-brightkite.html</a><br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-2.png" alt="数据集" title="">                </div>                <div class="image-caption">数据集</div>            </figure></p><h2 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h2><ul><li>POP</li><li>BPR</li><li>FPMC</li><li>HRM</li><li>CPAM</li><li>SHAN</li><li>SRGNN<h2 id="评测指标"><a href="#评测指标" class="headerlink" title="评测指标"></a>评测指标</h2></li><li>召回率Recall</li><li>MRR</li></ul><h2 id="基线对比"><a href="#基线对比" class="headerlink" title="基线对比"></a>基线对比</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-RQ1.png" alt="性能" title="">                </div>                <div class="image-caption">性能</div>            </figure><h2 id="组件实验"><a href="#组件实验" class="headerlink" title="组件实验"></a>组件实验</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-RQ2.png" alt="组件分析" title="">                </div>                <div class="image-caption">组件分析</div>            </figure><h2 id="维度分析"><a href="#维度分析" class="headerlink" title="维度分析"></a>维度分析</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-RQ3.png" alt="维度分析" title="">                </div>                <div class="image-caption">维度分析</div>            </figure><h2 id="数据稀疏性影响"><a href="#数据稀疏性影响" class="headerlink" title="数据稀疏性影响"></a>数据稀疏性影响</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-RQ4.png" alt="不同数据集" title="">                </div>                <div class="image-caption">不同数据集</div>            </figure><h2 id="可视化说明"><a href="#可视化说明" class="headerlink" title="可视化说明"></a>可视化说明</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/ASGNN-RQ5.png" alt="可视化" title="">                </div>                <div class="image-caption">可视化</div>            </figure><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ol><li>提出ASGNN，它将用户签到行为视为图，并使用GNN局部方式学习用户行为模式和他们的偏好用于下一个兴趣点推荐。</li><li>设计了一个个性化层级注意力机制捕捉用户长短时偏好，并将它们适应于序列推荐。</li><li>实验结果显示ASGNN超过基线和部分SOTA模型。</li></ol><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/HduDBSI/ASGNN" target="_blank" rel="noopener">https://github.com/HduDBSI/ASGNN</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/ASGNN-1.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;Attentive sequential model based on graph neuralnetwork for next poi recommendation&lt;/strong&gt;&lt;br&gt;　　基于图神经网络的注意力序列模型用于下一个兴趣点推荐&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="推荐算法" scheme="https://hubojing.github.io/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
      <category term="图神经网络" scheme="https://hubojing.github.io/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="注意力机制" scheme="https://hubojing.github.io/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    
      <category term="ASGNN" scheme="https://hubojing.github.io/tags/ASGNN/"/>
    
  </entry>
  
  <entry>
    <title>STAN</title>
    <link href="https://hubojing.github.io/2022/01/24/Paper_STAN/"/>
    <id>https://hubojing.github.io/2022/01/24/Paper_STAN/</id>
    <published>2022-01-24T03:20:37.000Z</published>
    <updated>2022-01-27T15:39:58.710Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\STAN-2.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>STAN: Spatio-Temporal Attention Network for Next Location Recommendation</strong><br>　　STAN：基于时空注意力网络的下一个兴趣点推荐<br><br><br> </div><a id="more"></a><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>　　STAN: Spatio-Temporal Attention Network for Next Location Recommendation<br>　　STAN：基于时空注意力网络的下一个兴趣点推荐<br>　　WWW 21<br>　　<a href="https://arxiv.org/pdf/2102.04095.pdf" target="_blank" rel="noopener">PDF</a></p><h1 id="现有问题"><a href="#现有问题" class="headerlink" title="现有问题"></a>现有问题</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="\images\STAN-1.png" alt="引入" title="">                </div>                <div class="image-caption">引入</div>            </figure><p>　　0、1、2分别代表家、工作地、商场，3、4、5、6分别代表餐馆。虽然3、4、5、6时间和空间都不连续，但它们是有关联的。现有文献很少关注这种非相邻位置和非连续签到的情况。</p><h1 id="说明和定义"><a href="#说明和定义" class="headerlink" title="说明和定义"></a>说明和定义</h1><p>　　用户U=${u_1, u_2, …, u_U}$<br>　　兴趣点L=${l_1, l_2, …, l_L}$<br>　　时间T=${t_1, t_2, …, t_T}$</p><p>　　用户轨迹$tra(u_i) = (r_1, r_2, …, r_{m_i})$</p><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="\images\STAN-2.png" alt="架构" title="">                </div>                <div class="image-caption">架构</div>            </figure><p>　　STAN包括多模态嵌入模块、一个自注意力聚合层、一个注意力匹配层、一个平衡采样器。</p><h2 id="多模态嵌入模块"><a href="#多模态嵌入模块" class="headerlink" title="多模态嵌入模块"></a>多模态嵌入模块</h2><p>　　该模块分为两部分：轨迹嵌入层和时空嵌入层。</p><h3 id="用户轨迹嵌入层"><a href="#用户轨迹嵌入层" class="headerlink" title="用户轨迹嵌入层"></a>用户轨迹嵌入层</h3><p>　　使用了用户、地理位置、时间，嵌入向量记为$e^u$、$e^l$、$e^t$。时间戳被分为7*24=168个维度。所以，$e^u$、$e^l$、$e^t$的维度是U，L和168。<br>　　输出$e^r = e^u + e^l + e^t$</p><h3 id="时空嵌入层"><a href="#时空嵌入层" class="headerlink" title="时空嵌入层"></a>时空嵌入层</h3><p>　　创造了两种矩阵，轨迹时空关系矩阵$△^{t, s}$和候选关系矩阵$N^{t, s}$。前者将两个轨迹间的时间差和地理距离作为关联信息，后者将轨迹中的兴趣点与候选集中可能的预测兴趣点采用同样的信息关联起来。使用线性插值方法。<br>　　这一层将这两种矩阵进行映射和求和，得到最终的嵌入表示E(△)和E(N)。</p><h2 id="自注意力聚合层"><a href="#自注意力聚合层" class="headerlink" title="自注意力聚合层"></a>自注意力聚合层</h2><p>　　这一层是用来考虑轨迹中有不同距离和时间间隔的两次兴趣点签到的关联程度的。自注意力层可以捕捉长时依赖并为轨迹中的兴趣点分配不同的权重。将轨迹E(u)和时空关系矩阵E(△)通过自注意力聚合层，计算得到新的序列S表示。</p><h2 id="注意力匹配层"><a href="#注意力匹配层" class="headerlink" title="注意力匹配层"></a>注意力匹配层</h2><p>　　这一层的作用是根据用户轨迹的最新表示在L中召回最合适的兴趣点候选。<br>　　A(u) = Matching(E(l), S(u), E(N))，得到的是概率。<br>　　$Matching(Q, K, N) = Sum(softmax(\frac{QK^T+N}{\sqrt{d}}))$<br>　　这个公式减少了其它自注意力模型中的PIF信息。</p><h2 id="平衡采样器"><a href="#平衡采样器" class="headerlink" title="平衡采样器"></a>平衡采样器</h2><p>　　因为正负样本不均衡，优化交叉熵损失不再有用。本文修改了交叉熵损失公式中负样本数量，对于每个正样本$a_k$，需要同时计算L-1个负样本，这称为作为平衡采样器。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="\images\STAN-3.png" alt="数据" title="">                </div>                <div class="image-caption">数据</div>            </figure><p>　　数据集：Gowalla, SIN, TKY, NYC.<br>　　输入：$(u_i, l_k, t_k)$, $(l_k, lon_k, lat_k)$<br>　　输出：候选兴趣点概率值</p><h2 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h2><ul><li>STRNN</li><li>DeepMove</li><li>STGN</li><li>ARNN</li><li>LSTPM</li><li>TiSARec</li><li>GeoSAN</li></ul><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="\images\STAN-4.png" alt="性能" title="">                </div>                <div class="image-caption">性能</div>            </figure><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ul><li>提出STAN，一种时空双向注意力模型，全面考虑了聚合相关联位置的时空效应。第一个将非相邻位置和非相邻签到时间的兴趣点的时空联系应用在兴趣点推荐中。</li><li>使用简单的线性插值技术替代GPS网格进行空间离散化，它能恢复空间距离和反映时空偏好，而不仅仅是聚合邻居。</li><li>提出了一种双向注意力架构用于PIF（personalized item frequency），第一层聚合了轨迹信息中相关的兴趣点用于更新表示，那么第二层就可以给全部的签到信息匹配目标。</li><li>在四个真实世界数据集上性能比SOTA模型超过10%。</li></ul><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/yingtaoluo/Spatial-Temporal-Attention-Network-for-POI-Recommendation" target="_blank" rel="noopener">https://github.com/yingtaoluo/Spatial-Temporal-Attention-Network-for-POI-Recommendation</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;\images\STAN-2.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;STAN: Spatio-Temporal Attention Network for Next Location Recommendation&lt;/strong&gt;&lt;br&gt;　　STAN：基于时空注意力网络的下一个兴趣点推荐&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="推荐算法" scheme="https://hubojing.github.io/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
      <category term="STAN" scheme="https://hubojing.github.io/tags/STAN/"/>
    
  </entry>
  
  <entry>
    <title>CHAML</title>
    <link href="https://hubojing.github.io/2022/01/22/Paper_CHAML/"/>
    <id>https://hubojing.github.io/2022/01/22/Paper_CHAML/</id>
    <published>2022-01-22T10:02:37.000Z</published>
    <updated>2022-01-23T15:37:57.794Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\CHAML-2.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>Curriculum Meta-Learning for Next POI Recommendation</strong><br>　　基于课程元学习的下一个兴趣点推荐<br><br><br> </div><a id="more"></a><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>　　Curriculum Meta-Learning for Next POI Recommendation<br>　　基于课程元学习的下一个兴趣点推荐<br>　　KDD 21<br>　　<a href="https://dl.acm.org/doi/abs/10.1145/3447548.3467132" target="_blank" rel="noopener">PDF</a></p><h1 id="现有问题"><a href="#现有问题" class="headerlink" title="现有问题"></a>现有问题</h1><p>　　在下一个兴趣点推荐的研究中，在有限的用户-兴趣点交互数据下，在冷启动城市中提供满意的推荐是重要问题，这需要许多其它城市丰富数据下隐含的知识进行迁移。现有文献没有考虑到城市转移的问题或者不能同时处理数据稀疏和用户在多个城市的模式多样性的问题。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="\images\CHAML-1.png" alt="问题描述" title="">                </div>                <div class="image-caption">问题描述</div>            </figure><p>　　问题描述如图所示。<br>　　该问题关键是提出一个合适的迁移算法，但难点有二：<br>　　1. 不同城市的数据太少<br>　　2. 用户在不同城市下有不同的多样性表达<br>　　现有算法不能同时解决这两个问题。传统的预训练和微调技术不能解决问题2，跨域推荐不能解决问题1。</p><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>　　提出 Curriculum Hardness Aware Meta-Learning (CHAML) 框架。<br><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="\images\CHAML-2.png" alt="架构" title="">                </div>                <div class="image-caption">架构</div>            </figure><br>　　架构分为两部分，一部分是基础推荐器，另一部分是MAML扩展。后者用于将元学习引入到POI推荐中。<br>　　两种采用策略组件，一种是硬意识元学习(hardness aware meta-learning)，另一种是城市级别采样课程(city-level sampling curriculum)。这用于细致思考采样多样性问题。<br>　　一些概念：<br>　　Curriculum Learning，主张让模型先从容易的样本开始学习，并逐渐进阶到复杂的样本和知识。<br>　　meta-learning，又叫learning to learn，即学习如何学习，元学习围绕任务（task）展开。元学习是要去学习任务中的特征表示，从而在新的任务上泛化。</p><h2 id="基础推荐器"><a href="#基础推荐器" class="headerlink" title="基础推荐器"></a>基础推荐器</h2><p>　　使用DIN作为基础推荐器，由三部分组成，嵌入模块（Embedding module）、注意力模块（Attention module）和输出模块（Output module）。</p><h2 id="元学习"><a href="#元学习" class="headerlink" title="元学习"></a>元学习</h2><p>　　使用MAML策略。<br>　　MAML论文：Model-agnostic meta-learning for fast adaptation of deep networks</p><p>　　每轮MAML包括两步骤：局部更新和全局更新。见图中左上部分。<br>　　每一次元学习任务都有支持训练集$D^{spt}$用于训练，query训练集$D^{qry}$用于测试。<br>　　元学习目标就是学习一个选学习器F，F可以预测推荐器f中的参数$\theta$，使损失函数最小化。</p><h2 id="硬意识元学习-Hardness-Aware-Meta-Learning"><a href="#硬意识元学习-Hardness-Aware-Meta-Learning" class="headerlink" title="硬意识元学习 Hardness Aware Meta-Learning"></a>硬意识元学习 Hardness Aware Meta-Learning</h2><p>　　这里的”hardness”是模型在query样本上的现有性能自判的。<br>　　分为两个阶段，hard_city阶段和hard_user阶段。两个任务交替循环。对应图右上。</p><h2 id="城市级别采样课程-City-level-Sampling-Curriculum"><a href="#城市级别采样课程-City-level-Sampling-Curriculum" class="headerlink" title="城市级别采样课程 City-level Sampling Curriculum"></a>城市级别采样课程 City-level Sampling Curriculum</h2><p>　　见图下方。<br>　　分为两阶段，一是困难度测量，使用诸如AUC指标来衡量。二是调度器用于城市pool，定义了一个函数g。课程学习使模型有更大的概率在优化过程中选择容易的梯度步骤。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>　　数据集：百度地图MapSmall、MapLarge（未开源）<br>　　输入：POI ID, POI category, time, user-POI dist<br>　　输出：POI预测分数$y^{hat}_i$</p><h2 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h2><p>　　针对POI推荐：</p><ul><li>NeuMF</li><li>HGN</li><li>ATST-LSTM</li><li>PLSPL</li><li>iMTL</li><li>DIN</li></ul><p>　　针对迁移策略：</p><ul><li>No transfer</li><li>Pretrain and Fine-Tune(FT)</li><li>MAML</li><li>$s^2$Meta</li><li>HAML</li></ul><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ol><li>第一个探索城市迁移的下一个兴趣点推荐，并将元学习用于该问题。</li><li>提出CHAML框架，通过使用用户和城市级别的硬采样挖掘以及城市级别的课程学习（curriculum learning）增强元学习器，达到同时解决数据稀疏和冷启动城市的样本多样性的问题。</li><li>在两个真实世界地图查找数据集中性能超越SOTA方法。<br>该框架已在百度地图上进行过A/B测试。</li></ol><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/PaddlePaddle/Research/tree/master/ST_DM/KDD2021-CHAML" target="_blank" rel="noopener">https://github.com/PaddlePaddle/Research/tree/master/ST_DM/KDD2021-CHAML</a><br><a href="https://github.com/victorsoda/chaml" target="_blank" rel="noopener">https://github.com/victorsoda/chaml</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;\images\CHAML-2.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;Curriculum Meta-Learning for Next POI Recommendation&lt;/strong&gt;&lt;br&gt;　　基于课程元学习的下一个兴趣点推荐&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="推荐算法" scheme="https://hubojing.github.io/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
      <category term="CHAML" scheme="https://hubojing.github.io/tags/CHAML/"/>
    
      <category term="元学习" scheme="https://hubojing.github.io/tags/%E5%85%83%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="课程学习" scheme="https://hubojing.github.io/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>博客更换为Waline评论系统</title>
    <link href="https://hubojing.github.io/2022/01/14/%E5%8D%9A%E5%AE%A2%E6%9B%B4%E6%8D%A2%E4%B8%BAWaline%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/"/>
    <id>https://hubojing.github.io/2022/01/14/博客更换为Waline评论系统/</id>
    <published>2022-01-14T13:18:13.000Z</published>
    <updated>2022-05-22T03:26:35.654Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\waline.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>数据安全挺重要的</strong><br>　　<strong>2022-05-22更新 解决评论模块无法访问的问题-CDN更换</strong><br><br> </div><a id="more"></a><h1 id="更换缘由"><a href="#更换缘由" class="headerlink" title="更换缘由"></a>更换缘由</h1><p>　　博客诞生以来，折腾最多的板块就是评论系统，多说–&gt;网易云跟帖–&gt;Disqus–&gt;Valine，一路换换换，经历了一些数据丢失，直到2018年3月更换到Valine评论系统后，至今平稳运行了快四年时间，除了偶尔有些广告以外，没有出过大问题。<br>　　但是从安装Valine起，我明了作为一款无后端的评论系统的安全性是很难保证的。由于那段时间折腾到心累，加上Valine是当时颜值最高且简洁的评论系统，同时觉得应该没有谁会去费精力黑一个没多少人看的小博客，所以就默默躺平了。中间也看到过有博主被攻击，不过总觉得自己应该不会这么倒霉吧，懒得管。没想到能撑四年也是不容易<del>（从侧面说明我的博客确实没人看，叹气.jpg）</del>。</p><p>　　今天更新博客时间线的时候看到博客上次大调整还是19年，究竟是我变懒了还是indigo主题确实满足了我大部分需求呢，肯定是后者哈哈。</p><p>　　为什么现在突然要换呢？主要是上次这篇博文<a href="https://hubojing.github.io/2021/12/07/%E8%A7%A3%E5%86%B3Valine%E8%AF%84%E8%AE%BA%E4%B8%8D%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98/">解决Valine评论不显示的问题</a>下面的评论让我再次想起Valine系统的这个隐患。</p><p>　　秉持着最小化修改的精神，我很快决定换成Waline系统。看这个名字吧，Valine和Waline，感觉上就相差肯定不多。Waline其实就是一个带后端的Valine，可以进行一些反垃圾和校验操作。其实早就看好了Waline，只是一直没有动力换它。现在是时候把它换了。也希望各位黑客大佬们手下留情，不要难为我这小小博客。</p><h1 id="更换步骤"><a href="#更换步骤" class="headerlink" title="更换步骤"></a>更换步骤</h1><p>　　以下步骤基于原有系统为Valine系统的简单迁移方法。</p><h2 id="Vercel-部署（服务端）"><a href="#Vercel-部署（服务端）" class="headerlink" title="Vercel 部署（服务端）"></a>Vercel 部署（服务端）</h2><p>　　免费的就是最好的！（本穷狗如是说）<br><a href="https://vercel.com/import/project?template=https://github.com/walinejs/waline/tree/main/example" target="_blank" rel="noopener">deploy</a></p><ul><li>点击上方跳转至Vercel部署。</li><li>未登录需要注册或登录，使用Github快捷登录。</li><li>输入名称创建项目，Vercel会根据Waline模板新建并初始化仓库。</li><li>几分钟后，满屏烟花部署成功。</li></ul><p>　　转到<code>Dashboard</code>-<code>Setting</code>-<code>Environment Variables</code>，进行环境变量配置。</p><h3 id="环境变量配置"><a href="#环境变量配置" class="headerlink" title="环境变量配置"></a>环境变量配置</h3><h4 id="必备"><a href="#必备" class="headerlink" title="必备"></a>必备</h4><p>　　新增/对应于</p><ul><li><code>LEAN_ID</code> —— LeanCloud中获得的<code>APP ID</code></li><li><code>LEAN_KEY</code> —— LeanCloud中获得的<code>APP KEY</code></li><li><code>LEAN_MASTER_KEY</code> —— LeanCloud中获得的<code>Master Key</code><br>　　以上默认LeanCloud国际版，如果是LeanCloud国内版，还要配置<code>LEAN_SERVER</code>环境变量，值为绑定好的域名。</li></ul><p>　　点击<code>Deployments</code>-<code>Redeploy</code>重新部署。当<code>STATUS</code>变为<code>Ready</code>后，点击<code>Visit</code>跳转的地址即为服务端地址。</p><h4 id="邮件提醒"><a href="#邮件提醒" class="headerlink" title="邮件提醒"></a>邮件提醒</h4><ul><li><p><code>SMTP_SERVICE</code>: SMTP 邮件发送服务提供商。<br><a href="https://github.com/nodemailer/nodemailer/blob/master/lib/well-known/services.json" target="_blank" rel="noopener">支持的服务提供商列表</a><br>(如果运营商不受支持，必须填写 <code>SMTP_HOST</code> 和 <code>SMTP_PORT</code>。<br><code>SMTP_HOST</code>: SMTP 服务器地址，一般可以在邮箱的设置中找到。<br><code>SMTP_PORT</code>: SMTP 服务器端口，一般可以在邮箱的设置中找到。)</p></li><li><p><code>SMTP_USER</code>: SMTP 邮件发送服务的用户名，一般为登录邮箱。</p></li><li><code>SMTP_PASS</code>: SMTP 邮件发送服务的密码，一般为邮箱登录密码，部分邮箱(例如 163)是单独的 SMTP 密码。</li><li><code>SITE_NAME</code>: 网站名称，用于在消息中显示。</li><li><code>SITE_URL</code>: 网站地址，用于在消息中显示。</li><li><code>AUTHOR_EMAIL</code>: 博主邮箱，用来接收新评论通知。如果是博主发布的评论则不进行提醒通知。</li></ul><p>选填:</p><ul><li><code>SENDER_NAME</code>: 自定义发送邮件的发件人</li><li><code>SENDER_EMAIL</code>: 自定义发送邮件的发件地址</li><li><code>MAIL_SUBJECT</code>: 自定义评论回复邮件标题</li><li><code>MAIL_TEMPLATE</code>: 自定义评论回复邮件内容</li><li><code>MAIL_SUBJECT_ADMIN</code>: 自定义新评论通知邮件标题</li><li><code>MAIL_TEMPLATE_ADMIN</code>: 自定义新评论通知邮件内容</li></ul><h2 id="HTML-引入-客户端"><a href="#HTML-引入-客户端" class="headerlink" title="HTML 引入 (客户端)"></a>HTML 引入 (客户端)</h2><p>在indigo主题中，需要修改\hexo\themes\indigo\layout_partial\plugins\valine.ejs文件。<br>去掉<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=<span class="string">"//code.bdstatic.com/npm/leancloud-storage@4.12.0/dist/av-min.js"</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;script src=<span class="string">"//unpkg.com/valine@latest/dist/Valine.min.js"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure></p><p>加上<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=<span class="string">"//cdn.jsdelivr.net/npm/@waline/client"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure></p><p>去掉<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> Valine(&#123;</span><br><span class="line">    el: <span class="string">'#comments'</span>,</span><br><span class="line">    notify: <span class="string">'&lt;%= theme.valine.notify %&gt;'</span> == <span class="string">'true'</span>,</span><br><span class="line">    verify: <span class="string">'&lt;%= theme.valine.verify %&gt;'</span> == <span class="string">'true'</span>,</span><br><span class="line">    appId: <span class="string">"&lt;%= theme.valine.appId %&gt;"</span>,</span><br><span class="line">    appKey: <span class="string">"&lt;%= theme.valine.appKey %&gt;"</span>,</span><br><span class="line">    avatar: <span class="string">"&lt;%= theme.valine.avatar %&gt;"</span>,</span><br><span class="line">    placeholder: <span class="string">"&lt;%= theme.valine.placeholder %&gt;"</span>,</span><br><span class="line">    guest_info: guest_info.length == <span class="number">0</span> ? GUEST_INFO : guest_info,</span><br><span class="line">    pageSize: <span class="string">"&lt;%= theme.valine.pageSize %&gt;"</span>,</span><br><span class="line">    serverURLs: <span class="string">'&lt;%= theme.valine.serverURLs %&gt;'</span>  <span class="comment">// 增加这一行！！！</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></p><p>更换为<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Waline(&#123;</span><br><span class="line">            el: <span class="string">'#comments'</span>,</span><br><span class="line">            serverURL: <span class="string">'此处为你的服务端地址'</span><span class="comment">//注意此处是serverURL，Valine里的是serverURLs</span></span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure></p><p>　　此时评论服务已能在博客成功运行。</p><h2 id="评论管理（管理端）"><a href="#评论管理（管理端）" class="headerlink" title="评论管理（管理端）"></a>评论管理（管理端）</h2><ul><li>部署完成后，在<code>&lt;serverURL&gt;/ui/register</code>进行注册。第一个注册的人被设定为管理员。</li><li>管理员可管理评论。</li><li>用户可通过评论框注册账号，登录后可跳转至自己的评论页。</li></ul><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><ul><li>如果无法发布评论，比如报错说格式不对（要求Number结果是String）之类的，建议查看LeanCloud数据中的单元格式是否正确。</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://waline.js.org/" target="_blank" rel="noopener">Waline官网</a></p><h1 id="2022-05-22更新-解决评论模块无法访问的问题-CDN更换"><a href="#2022-05-22更新-解决评论模块无法访问的问题-CDN更换" class="headerlink" title="2022-05-22更新 解决评论模块无法访问的问题-CDN更换"></a>2022-05-22更新 解决评论模块无法访问的问题-CDN更换</h1><h2 id="查找问题"><a href="#查找问题" class="headerlink" title="查找问题"></a>查找问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET https://cdn.jsde1ivr.net/npm/@waline/client</span><br><span class="line">net::ERR_CONNECTION_TIMED_OUT</span><br></pre></td></tr></table></figure><p>该CDN链接超时，需要更换。</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>将<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=<span class="string">"//cdn.jsdelivr.net/npm/@waline/client"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure></p><p>更换为<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;script src=<span class="string">"https://unpkg.com/@waline/client@v2/dist/waline.js"</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;link</span><br><span class="line">  rel=<span class="string">"stylesheet"</span></span><br><span class="line">  href=<span class="string">"https://unpkg.com/@waline/client@v2/dist/waline.css"</span></span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure></p><p>另外，waline版本更新后更改了方法入口，需要将<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Waline(&#123;</span><br><span class="line">            el: <span class="string">'#comments'</span>,</span><br><span class="line">            serverURL: <span class="string">'https://your-domain.vercel.app'</span>,</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure></p><p>更改为<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Waline.init(&#123;</span><br><span class="line">      el: <span class="string">'#comments'</span>,</span><br><span class="line">      serverURL: <span class="string">'https://your-domain.vercel.app'</span>,</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure></p><p>问题解决。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;\images\waline.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;数据安全挺重要的&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;2022-05-22更新 解决评论模块无法访问的问题-CDN更换&lt;/strong&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="博客" scheme="https://hubojing.github.io/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="Waline" scheme="https://hubojing.github.io/tags/Waline/"/>
    
      <category term="Valine" scheme="https://hubojing.github.io/tags/Valine/"/>
    
      <category term="评论" scheme="https://hubojing.github.io/tags/%E8%AF%84%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>2021年终总结</title>
    <link href="https://hubojing.github.io/2021/12/31/2021%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>https://hubojing.github.io/2021/12/31/2021年终总结/</id>
    <published>2021-12-31T05:00:59.000Z</published>
    <updated>2021-12-31T07:45:56.126Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\2022.png" width="300" height="180" style="float:right;"><br><br><br>　　<strong>白天写的年终总结！</strong><br><br><br> </div><a id="more"></a><h1 id="打分"><a href="#打分" class="headerlink" title="打分"></a>打分</h1><p>　　技术博客只谈技术。2021年给自己在技术方面打分：60分。</p><blockquote><p>自律使人自由 ——致自己2020~2021</p></blockquote><p>　　这句话大概要延续到2022年了……</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>　　去年的总结上写着“一晃，研究生生涯已经走完一半了。”<br>　　现在，我就要写上：<br>　　一晃，研究生生涯几乎快要走完了。<br>　　真快呀。</p><p>　　这一年里围绕的主要是两件事：</p><ol><li>科研</li><li>秋招</li></ol><p>　　科研带来的是日复一日读论文做实验的平静的心态，小论文被接收时也是一种平和的欣喜，作为对自己的一份鼓励。<br>　　秋招带来的是对未知的迷茫和跃跃欲试的憧憬，每天笔试面试虽辛苦疲累，但一想收到offer时的快乐，这些努力都很值得。<br>　　本来洋洋洒洒写了一大段，又觉得没有必要在技术博客里写长篇大论去叙述这些过程，也许我在总结生活的时候，可以再加上。每个走过这段路的人都有类似的体会，我在走前人走过的路，而后来的人又即将走我走过的路。<br>　　去年定的目标只是简单的一句进大厂。但是在几乎贯穿全年的找工作话题中，在说服自己和迷茫不断循环中，我发现我竟想不明白我到底要什么，致使我的想法有几次很大的转变。也许是我第一次真正地参与秋招，这着实是自己在选择今后的人生，我要为我的选择负责。要感谢所有发给我offer的公司，我非常幸运能被你们看中。我想，无论选择哪一个，也许我都会遐想另一条路会怎样，但总归人只能选择一条路。所幸这几个月的不断思考，或者说不得不思考，让我渐渐地得出了模糊的答案。</p><h1 id="关于技术"><a href="#关于技术" class="headerlink" title="关于技术"></a>关于技术</h1><p>　　读研后拥有了自己的研究方向，我很珍惜这种归属感，而不是和从前一样学得广而杂。这几年的科研做的都是推荐算法相关的研究，所以找工作多半也是这方面。倒是想提一提为什么我会选择推荐算法，说来有些搞笑，我曾经非常喜欢网易云音乐的私人FM功能，十分好奇为什么私人FM的推歌功能可以如此抓住人心。当我研一选择研究方向的时候，毫不犹豫地选择了推荐算法，只是希望有一天我能知道到底是什么算法能实现这个功能。现在我大概知道了是如何实现的，可是就和魔术一样，当你知道它是怎么变的后，就有些不过如此的感觉。<br>　　现在我除了推荐算法的研究外，也在往NLP算法拓展。或者说，推荐算法是NLP算法的一种应用算法也可以。NLP算法现在的研究依然充满了挑战，毕竟现在还处于感知智能，要升级到认知智能，还得靠NLP算法。（突然就高大上了起来哈哈）<br>　　当然，我对开发技术也始终保持乐趣，我总是希望自己能利用业余时间设计出好玩或者有用的软件。<br>　　学技术的路上，我感觉和玩游戏升级打怪差不多，并不感觉自己是在费劲地强迫学习，只是玩。其实秋招也给我这种感觉，虽然是找工作，也会有累和压力，但我后期笔试面试已经麻了<del>（逐 渐 变 态）</del>，只觉得自己是在玩，单纯获得一份人生经历罢了。</p><p>　　另外，这几年对技术博客疏于管理，回看自己写的文章也不多，水平也很菜，对于这一点我对自己很不满意。这种时候就挺想念本科时自己的学习状态。</p><h1 id="新的一年"><a href="#新的一年" class="headerlink" title="新的一年"></a>新的一年</h1><p>　　2022年应该是生活方式改变的一年，如果顺利的话我应该工作了。那么前半年和后半年的生活也许完全不同。</p><p>　　还剩下的最后一个学期，也许是我人生中最后的学生生活吧。<br>　　还有哪些事情需要做以至于以后想起学生时代的遗憾能够少一点呢？<br>　　我打算默默地写一个列表，然后用最后一个学期尽可能地去完成它。</p><p>　　当然，认真写毕业论文，这个是TOP1级别的。</p><p>　　后半年的工作，也许会有很多新的期待，但是现在的我无法预料。希望能够在工作中有所收获，技术和研究能力能得到提升。剩下的，享受未知吧。</p><p>　　最后，为了表明2022年不熬夜的决心，不像前几年凌晨写总结，这次我白天写好了！（倔强.jpg）</p><p>　　　　　　　　　　　　　　　　　　　　　　　　　　2021年12月31日下午  于实验室</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;\images\2022.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;白天写的年终总结！&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="杂谈" scheme="https://hubojing.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="年终总结" scheme="https://hubojing.github.io/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
</feed>
