<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>靖待的技术博客</title>
  
  <subtitle>小清新IT旅程 | 为中华之崛起而读书</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://hubojing.github.io/"/>
  <updated>2024-07-08T15:48:18.458Z</updated>
  <id>https://hubojing.github.io/</id>
  
  <author>
    <name>靖待</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【大模型系列】提示学习</title>
    <link href="https://hubojing.github.io//s3H6oP3Z/"/>
    <id>https://hubojing.github.io//s3H6oP3Z/</id>
    <published>2024-05-18T04:39:43.000Z</published>
    <updated>2024-07-08T15:48:18.458Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\大模型.png" class="lazyload" data-srcset="\images\大模型.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>大模型系列笔记之提示工程（基础、上下文学习、思维链）。</strong><br><br><br> </div><span id="more"></span><h1 id="基础提示"><a href="#基础提示" class="headerlink" title="基础提示"></a>基础提示</h1><h2 id="人工设计提示"><a href="#人工设计提示" class="headerlink" title="人工设计提示"></a>人工设计提示</h2><ul><li>任务描述</li><li>输入数据</li><li>上下文信息</li><li>提示策略<br>“你是这个任务的专家”<br>“让我们一步一步地思考”<br>“通过依次执行以下任务形成一段连贯的叙述：1. …；2. …；3. …”<br>对话式大模型，可以将提示拆分为多个子任务提示，以多轮对话的方法逐步输入给大模型。<br>提供少样本示例<br>使用特殊符号进行分割（###、三引号、XML标签等）<br>英文指令理解更好<h2 id="自动提示优化"><a href="#自动提示优化" class="headerlink" title="自动提示优化"></a>自动提示优化</h2><h3 id="离散提示优化"><a href="#离散提示优化" class="headerlink" title="离散提示优化"></a>离散提示优化</h3>离散提示通常是由一系列自然语言词元组成的完整句子表达（如“请根据提供的检索信息回答下列问题”）。在离散的词元空间中进行组合搜索，时间复杂度高且搜索结果可能不是最优。因此有以下的优化方法。</li><li>基于梯度的方法<br>通过梯度更新技术以最大化模型的似然分数来优化离散提示的搜索过程。将提示词初始化为一系列“[MASK]”标记，然后迭代地将提示中的词元替换为词典中的其它词元，通过词元替换产生的对数似然变化来近似估计梯度，进而为提示的每个位置贪心搜索出最佳的词元。由于对提示的每个位置都进行所有候选词元的替换和梯度评估，因此模型需要进行多次前向和后向计算，搜索过程效率较低。为此，可将离散词元转化为连续嵌入表示（软词元），使用梯度直接对连续嵌入参数进行优化，最后将每个连续嵌入映射为词典中最邻近的离散词元。</li><li>基于强化学习的方法<br>将预训练语言模型作为强化学习中的策略网络并依次生成提示中的词元。在提示生成结束之后，策略网络可以获得任务特定的奖励信号，该奖励信号可通过强化学习算法用于策略网络参数的训练。可设计不同类型的奖励信号，如真实便签与基于提示的预测标签是否一致、生成文本与给定条件的匹配程度。在测试阶段，基于训练好的策略网络，可采用贪心搜索策略来生成任务提示中的每个词元。</li><li>基于编辑的方法<br>特别适用于无法直接访问模型内部状态（如梯度）的情况，比如只能通过API调用的模型。这种方法需事先定义好编辑操作，然后迭代地修改提示，直到最大迭代轮次或者模型最佳性能。常用的提示编辑操作：修改任务描述、添加或删除上下文任务示例、调整输入到输出的标签映射器（二分类用‘postive/negtive’、‘正/负’）。</li><li><p>基于大语言模型的方法<br>该方法首先利用提示生成模型（用于生成指示指令的大语言模型）基于少量上下文示例生成一批候选的任务指令。随后，使用目标模型（用于下游测试的大语言模型）对这些候选指令在目标任务上的表现逐一评估。评估过程可采用模型困惑度或任务准确率作为衡量指令质量的指标。上述过程可通过基于蒙特卡洛搜索的多轮优化策略进行扩展。在每轮迭代中，根据模型表现对候选指令进行筛选得到高评分指令，并利用大语言模型生成与高评分指令相似的新指令，从而扩展候选指令集。迭代完成后，选择模型表现最佳的候选指令作为最终使用的提示。但是这种方法可能在提示搜索过程中陷入局部最优或者产生效果震荡，无法生成更好的提示。为解决该问题，可将所有改进的历史提示及其分数纳入提示优化过程，以指导大语言模型逐步生成更好的新提示。</p><h3 id="连续提示优化"><a href="#连续提示优化" class="headerlink" title="连续提示优化"></a>连续提示优化</h3><p>由一组连续空间中的嵌入向量组成，可根据下游任务的损失直接通过梯度更新进行优化。已有连续提示优化的工作主要是基于预训练语言模型开展，由于参数量巨大，受到的关注有限。已有研究通常依赖于有监督学习方法，数据稀缺时还可采用迁移学习来缓解。</p></li><li><p>监督学习方法<br>将连续提示向量视为可训练的模型参数，基于下游任务数据，通过最小化交叉熵损失来优化连续提示。Prefix-tuning在语言模型每个Transformer层预置一串前缀（即一组可训练的连续向量），而Prompt-tuning只会在输入层加入可训练的提示向量。通过固定语言模型的大规模参数而只微调这些连续的提示向量，可以有效节省训练所需要的参数量。然而这些提示优化方法通常与输入无关，缺乏对于输入语义的充分考虑。</p></li><li>迁移学习方法<br>为若干个具有代表性的源任务学习一个所有任务共享的连续提示，然后使用该提示初始化目标任务的提示，但它在解决目标任务的所有实例时都使用了相同提示，未必适合所有的任务实例。为此，可以为每个源任务独自学习任务特定的连续提示（而不是所有源任务共享），在解决目标任务的实例时，可以采用注意力机制等方式学习目标实例与每个源任务提示的相关性权重系数，对若干个源任务的提示向量进行加权组合，将组合后的新提示（为连续向量形式）用于帮助模型解决当前任务实例。<h1 id="上下文学习"><a href="#上下文学习" class="headerlink" title="上下文学习"></a>上下文学习</h1>GPT3提出In-context learning（ICL），由任务描述和（或）示例所组成的自然语言文本作为提示。<br>首先，通过自然语言描述任务，并从任务数据集中选择一些样本作为示例。其次，根据特定的模板，将这些示例按照特定顺序组合成提示内容。最后，将测试样本添加到提示后面，整体输入到大语言模型以生成输出。基于任务描述以及示例信息，大语言模型无需显式的梯度更新即可识别和执行新的任务。<h2 id="示例选择"><a href="#示例选择" class="headerlink" title="示例选择"></a>示例选择</h2></li><li>基于相关度排序的方法<br>KNN相似度检测算法，选出与目标任务实例相关的示例。具体来说，可以使用文本嵌入模型（如 BERT）将所有候选样本映射到低维嵌入空间中，然后根据这些候选样本与测试样本的嵌入语义相似度进行排序，并选择出最相关的 𝑘 个示例，最后将筛选出的示例作为上下文学习的示例集合。</li><li>基于集合多样性的方法<br>经典启发式MMR（Maximum Margin Ranking）算法、基于行列式点过程的DPP算法（Determinantal Point Process）</li><li>基于大语言模型的方法<br>将大语言模型作为评分器对候选样本进行评估，进而选择出优质的示例。一种最直接的评估方法是通过计算在加入当前示例后大语言模型性能的增益来评估示例的有效性，以此筛选出有效的示例。但是，这种方法需要大语言模型进行重复多次计算，才能选择出最优的示例集合。为了减少大语言模型评估的开销，还可以根据大语言模型的评分结果选择出少量的正负示例用于训练一个分类器，该分类器通过正负示例能够学习到如何准确地区分和筛选出高质量示例，从而更准确地来指导后续的示例选择过程。<br>总体来说，在上下文学习中进行示例选择时应确保所选示例包含丰富的任务信息且与测试样本保持高度的相关性。<h2 id="示例格式"><a href="#示例格式" class="headerlink" title="示例格式"></a>示例格式</h2></li><li>人工标注的格式</li><li>自动生成的格式<br>首先人工标注一部分的示例模板作为种子集合加入到大语言模型的输入中。然后，利用大语言模型强大的少样本学习能力，指导其为新任务生成相应的示例模版。最后，对这些生成的示例模版进行筛选与后处理，使之符合任务要求。<h2 id="示例顺序"><a href="#示例顺序" class="headerlink" title="示例顺序"></a>示例顺序</h2></li><li>产生候选示例顺序<br>大语言模型在做出预测时，倾向于依赖于提示末端的信息。常用的方式是根据示例与测试样本之间的语义相似度进行排序，然后将与测试样例相似度更高的示例放在更靠近测试样本的位置。</li><li>评估示例顺序质量<br>在测试集样本可获得的情况下，可以直接测试大语言模型基于该示例顺序的任务性能，以此作为当前示例顺序的评分。无法获得测试样本时，需要人工创建独立的验证集进行示例顺序的评估。另一种不依赖测试数据的评估方法是采用模型对于预测结果的不确定性作为评估指标。具体来说，可以计算基于该示例顺序大语言模型预测分布的熵值，选择熵值较低的示例顺序作为较为有效的顺序。熵值越低，意味着模型预测分布越不均匀，则模型预测的置信度更高。<h1 id="思维链提示"><a href="#思维链提示" class="headerlink" title="思维链提示"></a>思维链提示</h1>思维链提示作为上下文学习的一种扩展形式，将原始的&lt;输入，输出&gt;映射关系转换为&lt;输入，思维链，输出&gt;这一三元组形式。<br>“Let’s think step by step.”<br>“Take a deep breath and work on this problem step-by-step.” <h2 id="思维链示例设计"><a href="#思维链示例设计" class="headerlink" title="思维链示例设计"></a>思维链示例设计</h2>从输入侧对思维链示例进行增强。<ul><li>复杂化的思维链</li><li>推理步骤多、问题长</li><li>多样化的思维链<br>首先利用聚类算法（例如 𝑘-means 聚类）将训练集中的问题划分为 𝑘 个簇（𝑘 为所需的示例数量），簇内部的问题比较相似，而不同簇的问题差别较大。然后，预定义一系列启发式规则，从每个簇中选择距离质心最近且满足规则的问题作为该簇的代表性问题，将该问题输入给大语言模型并生成对应的思维链和答案作为示例。由于每个问题来自于不同的簇，从而保证了示例的多样性。实验发现，虽然大模型生成的思维链示例可能存在错误，但是当选择更加多样化的示例时，思维链示例中的错误对模型性能的影响会显著降低。<h2 id="思维链生成方法"><a href="#思维链生成方法" class="headerlink" title="思维链生成方法"></a>思维链生成方法</h2></li></ul></li><li>基于采样的方法<br>单一思维链推理容易出错，可采样多条推理路径来缓解。代表性方法：self-consistency。首先使用大语言模型生成多个推理路径和对应的答案，然后对于这些候选答案进行集成并获得最终输出。具体的集成方法可选择各条推理路径所得到答案中出现频率最高的那个答案作为最终输出，也可对所有答案进行某种形式的加权。<br>但问题太简单用思维链反而效果不好。例如，对于句子的情感分类任务，由于问题过于简单，加入思维链提示之后反而会使模型过度思考，从而得出错误的答案。</li><li><p>基于验证的方法<br>思维链提示所具有的顺序推理本质可能导致推理过程中出现错误传递或累积的现象。为了解决这一问题，可以使用专门训练的验证器或大语言模型自身来验证所生成的推理步骤的准确性。<br>例：DIVERSE 方法<br>针对整个推理路径的验证器通过如下方法训练得到：首先选择一个包含大量问题答案对的数据集，然后将问题输入给大语言模型，通过思维链提示的方法使其生成推理路径和最终答案。如果模型生成的答案和数据集标注的答案一致，则判为正例，否则判为负例。最后使用构造的&lt;问题，推理链，答案&gt;数据训练一个二分类器，从而可以对任意一个推理路径进行打分。训练针对中间步骤的验证器也可以采用类似的方案。然而，与整体推理路径的数据标注相比，构造面向中间步骤的正负例数据更加困难。这里可以采取一个简化处理：对于每一个训练集中的问题，我们采样多次得到多个推理路径，对于得出正确答案的推理路径，中间的每一个步骤我们都认为是正确的，作为正例；对于得出错误答案的推理路径，如果其中某个步骤和正例的推理路径相一致，也认为是正例，否则作为负例。通过这样构造出来的数据，用同样的方法训练一个二分类器，从而可以对模型输出的中间步骤进行打分。</p><h2 id="拓展的推理结构"><a href="#拓展的推理结构" class="headerlink" title="拓展的推理结构"></a>拓展的推理结构</h2><p>链式推理结构在处理较为复杂的任务时（例如需要进行前瞻和回溯探索）仍然存在一定的局限性。</p></li><li><p>树形推理结构<br>代表性工作：思维树（Tree of Thought, ToT）<br>它和思维链的区别在于：思维链从一个节点出发，只能生成一个节点，而思维树则可以生成多个节点。当某一个思考步骤无法得到正确答案时，可以回溯到它的父节点，选择另一个子节点继续推理。</p></li><li>图形推理结构<br>代表性工作：思维图（Graph of Thought, GoT）<br>思维图和思维树的区别在于，思维树的子节点只能进行前向搜索和回溯，而思维图的子节点可以和其他子节点进行汇聚，得到新的中间步骤，然后进行下一步的推理。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;&#92;images&#92;大模型.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;大模型系列笔记之提示工程（基础、上下文学习、思维链）。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="大模型" scheme="https://hubojing.github.io/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="大模型" scheme="https://hubojing.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="提示学习" scheme="https://hubojing.github.io/tags/%E6%8F%90%E7%A4%BA%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Hexo根据更新时间修改文章排序机制</title>
    <link href="https://hubojing.github.io/2024/04/12/Hexo%E6%A0%B9%E6%8D%AE%E6%9B%B4%E6%96%B0%E6%97%B6%E9%97%B4%E4%BF%AE%E6%94%B9%E6%96%87%E7%AB%A0%E6%8E%92%E5%BA%8F%E6%9C%BA%E5%88%B6/"/>
    <id>https://hubojing.github.io/2024/04/12/Hexo根据更新时间修改文章排序机制/</id>
    <published>2024-04-12T15:00:11.000Z</published>
    <updated>2024-04-12T15:09:54.959Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\blog.png" class="lazyload" data-srcset="\images\blog.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>改一行代码就行了。</strong><br><br><br> </div><span id="more"></span><h1 id="前言（可不看）"><a href="#前言（可不看）" class="headerlink" title="前言（可不看）"></a>前言（可不看）</h1><p>之前由于电脑不在身边，长期通过其它电脑写文章利用之前说过的github action推送博客更新。但是发现一个问题，它总是按照文章创建时间排序，而不是文章更新时间。<br>查过网上很多方法，法一：博客源目录配置文件新增<code>updated_option: mtime</code>，不行。<br>法二：利用插件，<br>新增<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index_generator:</span><br><span class="line">    per_page: 10</span><br><span class="line">    order_by: updated</span><br></pre></td></tr></table></figure><br>不行。<br>直到最近拿到了电脑，终于有了源文件可以修改了。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>hexo源目录下，\node_modules\hexo-generator-index\lib\generator.js<br>将<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#x27;use strict&#x27;;</span><br><span class="line"></span><br><span class="line">var pagination = require(&#x27;hexo-pagination&#x27;);</span><br><span class="line"></span><br><span class="line">module.exports = function(locals)&#123;</span><br><span class="line">  var config = this.config;</span><br><span class="line">  var posts = locals.posts.sort(&#x27;-updated&#x27;); //修改这里！ 原代码为var posts = locals.posts.sort(&#x27;-date&#x27;);</span><br><span class="line">  var paginationDir = config.pagination_dir || &#x27;page&#x27;;</span><br><span class="line"></span><br><span class="line">  return pagination(&#x27;&#x27;, posts, &#123;</span><br><span class="line">    perPage: config.index_generator.per_page,</span><br><span class="line">    layout: [&#x27;index&#x27;, &#x27;archive&#x27;],</span><br><span class="line">    format: paginationDir + &#x27;/%d/&#x27;,</span><br><span class="line">    data: &#123;</span><br><span class="line">      __index: true</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><br>就这么简单。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;&#92;images&#92;blog.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;改一行代码就行了。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="博客" scheme="https://hubojing.github.io/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="博客" scheme="https://hubojing.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="Hexo" scheme="https://hubojing.github.io/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>博客永久链接与计数</title>
    <link href="https://hubojing.github.io/2024/02/15/%E5%8D%9A%E5%AE%A2%E6%B0%B8%E4%B9%85%E9%93%BE%E6%8E%A5%E4%B8%8E%E8%AE%A1%E6%95%B0/"/>
    <id>https://hubojing.github.io/2024/02/15/博客永久链接与计数/</id>
    <published>2024-02-15T08:42:03.000Z</published>
    <updated>2024-04-09T15:01:28.097Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>折腾。。。</strong><br><br><br> </div><span id="more"></span><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>工欲善其事，必先利其器。<br>对自己的博客不好用不满意很久了，但是这几年太懒。想趁着放假弄一下吧，发现几年没动，版本升级后很多东西变了，折腾了一下午效果不太理想。先记录一下。</p><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ul><li>博客链接中有中文，转码后太长<br>解决方法：<strong>永久链接</strong></li></ul><ol><li>在front-matter中加permalink<br>这个应该是新特性，以前似乎没有，额，我说的以前大概是hexo 3.0，现在一看，7.0了……<br>但是我尝试了:hash，没奏效，不知道是不是因为我hexo3低了。</li><li>使用插件hexo-abbrlink<br>试了，会把所有的博文都变了，那么就又多一个问题，以前已经被搜索引擎收录的，就成了死链。</li></ol><ul><li><p>永久链接用什么形式<br>中文转拼音hexo-permalink-pinyin，不够优雅<br>uuid，32位太长<br>hexo-abbrlink生成的8位还挺好的</p></li><li><p>以前的链接处理<br>解决方法：</p></li></ul><ol><li>重定向<br>记录原有的链接，使用插件hexo-generator-alias，利用别名进行跳转。但是要记录原来的url，又要写脚本获取，麻烦。</li><li>以前的链接不动，只改新的<br>官方没给这种操作，搜到一个自己写js脚本的，尝试了，控制台是对的，本地渲染后不行。</li></ol><ul><li>修改链接后网页计数没了<br>因为用的是不蒜子，它根据url统计的，url一变，相当于归零。<br>解决方法：</li></ul><ol><li>写脚本在原有基础上魔改，手动初始化。</li><li>改用leancloud计数。</li></ol><p>以前我觉得能用就行，现在发现数据不放在自己手上真是麻烦啊，还是想办法改吧。<br>好久没看过前端代码，indigo主题又停更好多年了，ejs又没咋学过，硬是找了个加了lc计数功能的主题对着改了改，最终leancloud计数能成功，但是lc更新数据好慢啊……犹豫要不要换掉不蒜子了。</p><p>这几个问题，你中有我，我中有你，相互影响，醉了。<br>想到最后，差点想换个主题了。</p><h1 id="懒人最终处理方法"><a href="#懒人最终处理方法" class="headerlink" title="懒人最终处理方法"></a>懒人最终处理方法</h1><ul><li>lc计数我再观察一阵子</li><li>以前的链接暂时不动</li><li>新博文采用新的永久链接，暂时手动添加在front-matter中</li></ul><p>写了一个超简单的uuid生成器，后面看能不能搞成自己的博文管理器。</p><p>前端横竖还是应该至少学会一种技术栈，用熟一套框架，否则太影响发挥了。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://hexo.io/zh-cn/docs/permalinks">https://hexo.io/zh-cn/docs/permalinks</a></li><li><a href="https://zhuanlan.zhihu.com/p/353378112">https://zhuanlan.zhihu.com/p/353378112</a></li><li><a href="https://crescentmoon.info/2014/12/11/popular-widget/">https://crescentmoon.info/2014/12/11/popular-widget/</a></li><li><a href="https://polar-bear.eu.org/2023/06/29/hexo-generator-alias-wang-ye-chong-ding-xiang/index.html">https://polar-bear.eu.org/2023/06/29/hexo-generator-alias-wang-ye-chong-ding-xiang/index.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/386945980">https://zhuanlan.zhihu.com/p/386945980</a></li><li><a href="https://blog.dejavu.moe/posts/hexo-permalinks/">https://blog.dejavu.moe/posts/hexo-permalinks/</a></li><li><a href="https://www.jianshu.com/p/c7de2ae59975">https://www.jianshu.com/p/c7de2ae59975</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;折腾。。。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="博客" scheme="https://hubojing.github.io/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="博客" scheme="https://hubojing.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="Hexo" scheme="https://hubojing.github.io/tags/Hexo/"/>
    
      <category term="永久链接" scheme="https://hubojing.github.io/tags/%E6%B0%B8%E4%B9%85%E9%93%BE%E6%8E%A5/"/>
    
      <category term="计数" scheme="https://hubojing.github.io/tags/%E8%AE%A1%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>2023年终总结</title>
    <link href="https://hubojing.github.io/2023/12/31/2023%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>https://hubojing.github.io/2023/12/31/2023年终总结/</id>
    <published>2023-12-31T06:37:55.000Z</published>
    <updated>2023-12-31T09:39:12.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\年终总结.png" class="lazyload" data-srcset="\images\年终总结.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br> 　　<br>　　<strong>希望2024年能深耕技术。</strong><br><br><br><br> </div><span id="more"></span><p>　　2023年，技术方面，对自己不太满意。  </p><h1 id="今年总结"><a href="#今年总结" class="headerlink" title="今年总结"></a>今年总结</h1><p>　　先说说博客吧，毕竟博客是我技术向感受的输出窗口。今年发布的博文很少，尤其是4月以后到10月几乎停更。这有两大原因，一方面是生活上的，一方面是技术上的。<br>　　在生活中，今年总是会被外界看起来不大的事情所牵绊，陷入各种内耗中。2022年底阳康后，身体似乎比以前要虚很多。2023年发烧的次数似乎比前十年加起来都多，甚至出现了这辈子没体验过的40.4℃（幸好脑子影响不大…吧）。很多次都有想学的心，但是整体状态让我只想躺着休息。这就是心有余而力不足吗？可是我三十还没到呢，这不对。明年一定要改。   </p><p>　　技术博客只谈技术。<br>　　在技术上，去年底开始，大模型技术受到关注，今年三月火热程度仿佛新技术革命一般，我也兴致勃勃地去阅读chatGPT的论文，去理解什么是RLHF，什么是PPO，如何去模型分布式训练等。但是当我粗浅地了解这些东西后，我陷入了一种莫名的失落感。NLP算法似乎进入到了一种谁的数据多、谁的算力大，谁就能赢得更高的准确率和召回率，而那些细微的模型区别，在这些东西的掩盖下，似乎已经不那么重要。未来，可能只有极个别接触到模型的核心算法去做模型的事情，其他人沦为数据处理师或者模型应用师，比如最新的Prompt工程师。<br>　　这个词刚出来的时候，我是很不屑的。一个东西称为技术，应该是需要门槛的。但是Prompt这种玩意儿不需要会数据结构，也不需要会组成原理，甚至只要会打字（哦，语音输入也不是不行）就可以干的事情，也能算技术？这也能叫工程师？然而现实啪啪打脸，讲prompt优化的论文在各大顶会上如泉涌，一时间我真的分不清是因为这一块好灌水，还是因为prompt真的是技术。到现在，我还是有些不解，很多论文提出了各种玄学调prompt的方法，甚至还总结了很多经验，可是模型只要稍作修改，那些奇技淫巧很可能都失效了啊。这种感觉，就仿佛盲人摸象般，只知其然而不知其所以然。<br>　　总之，困惑不外有二。一是个人很难复现大模型能力，我也想改模型，也想训练调参，但是没有那么多卡，也没有几十个数据团队为我服务，现在几乎失去了个人单打独斗就能创造的机会，只能看看论文，找找开源代码玩参数很小的玩具；二是火热的prompt技术似乎也没什么技术含量。所以，四月后很长时间，我对大模型一直抱有抵触情绪，有时候恨不能刻意避开它。仿佛它并不是一种厉害的发明，更像是粗鲁的大力飞砖打败了细致的算法。那段时间，经常在知乎上看到这种论调：NLP已死。那我去年从搜广推转向NLP，岂不是49年入国军？<br>　　有时候也觉得自己很可笑，明明只是个刚入行的算法新手，竟然还挑剔起现在最火热的技术了，颇有点眼高手低。基础打扎实了吗就在这嚷嚷，我经常暗自嘲笑自己。然而我依然我行我素，我觉得扩散模型好玩、有用，多模态模型好玩、有用，大模型？啊nono。<br>　　这种困扰直到被人骂了才清醒许多。“既然你觉得prompt算不上技术，那以前微调那些，也并没有重训模型，只是在原模型上修修改改，要说技术含量，也算不了什么技术。那你干嘛还要学微调那些呢？技术都是慢慢发展起来的。”不知道为什么，就这几句话反而说动我了。是我应该去适应技术，而不是让世界迁就我。如果足够强大，提出更好的技术时，也许世界就会跟随我。（纯属白日做梦~哈哈）<br>　　所以，在很晚的11月，我又重新捡起大模型的论文看了起来。Better late than never嘛。</p><p>　　工作上，逐渐从新人成长为熟悉业务的老员工。可惜员工流动频繁，逐渐地，很少被指导技术了，自己一个人摸索总是不断走弯路。虽然一直明白，学技术要靠自己，可是还是偶尔做梦要是能跟着大佬学习多好。今年有了两个实习生，也是人生中第一次带人，自己非常理解如果有个经验稍多一点的人帮助白纸们规划或者点评一下，其实对他们来说也许可以省时省力一些。所以我尽量在他们困惑时帮一把，至少在这段实习中有些收获，虽然也很忐忑自己能力有限无法给予太多他们想学的东西，但是我已尽力啦，希望他们对我还算满意。</p><p>　　读书上，技术书籍今年读完了几本，还凑合。</p><h1 id="明年计划"><a href="#明年计划" class="headerlink" title="明年计划"></a>明年计划</h1><ul><li>跟着大模型的步伐，学！学就是了！</li><li>基础，打基础，NLP基础永不过时</li><li>搜广推算法持续关注</li><li>写几个自己感兴趣的小软件</li><li>了解机器人相关算法</li><li>强身健体，为祖国健康工作！</li></ul><p>　　希望明年能深耕技术。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;&#92;images&#92;年终总结.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt; 　　&lt;br&gt;　　&lt;strong&gt;希望2024年能深耕技术。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="杂谈" scheme="https://hubojing.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="年终总结" scheme="https://hubojing.github.io/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>大模型相关论文笔记</title>
    <link href="https://hubojing.github.io/2023/11/22/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>https://hubojing.github.io/2023/11/22/大模型相关论文笔记/</id>
    <published>2023-11-22T14:20:55.000Z</published>
    <updated>2024-01-26T14:55:12.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\paper.png" class="lazyload" data-srcset="\images\paper.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br> 　　<br>　　<strong>大模型相关论文阅读笔记。 </strong><br>　　<strong>倒序排列论文，最新阅读的在最上面。</strong><br>　　<strong>2024年1月26日更新</strong><br><br><br> </div><span id="more"></span><h1 id="Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks"><a href="#Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks" class="headerlink" title="Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"></a>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</h1><p>用于知识密集型NLP任务的检索增强生成<br>Facebook 2020<br><a href="https://arxiv.org/pdf/2005.11401v4.pdf">PDF</a><br><a href="https://github.com/huggingface/transformers/tree/main/examples/research_projects/rag">CODE</a><br>（论文代码链接已失效，以上是最新链接）</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>大模型有幻觉问题（hallucinations），检索增强生成(retrieval-augmented generation, RAG)可以解决它。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>输入为x，外部检索资源为z，生成目标序列y。<br>模型有两块：一个检索器$p_\eta(z|x)$，$\eta$为参数，给定一个查询q，根据文本返回top-K个分布；一个生成器$p_\theta(y_i|x,z,y_{1:i-1})$，参数为$\theta$，它基于过去i-1个tokens $y_{1:i-1}$、原始输入x和检索器信息z，产生一个当前的token。<br>为了端到端的训练检索器和生成器，我们将检索文档作为一个隐变量。我们提出了两个模型，他们以不同的方式边缘化隐变量，从而在文本上产生分布。在我们的方法里，第一步，RAG-Sequence，这个模型使用相同的文本预测每一个目标token；第二步，RAG-Token，基于不同的文件预测每一个目标token。</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul><li>RAG-Sequence模型<br>$$p_{RAG-Sequence}(y|x)≈\sum_{z∈top-k(p(·|x))}p_\eta(z|x)p_\theta(y|x,z)=\sum_{z∈top-k(p(·|x))}p_\eta(z|x)\prod^N_ip_\theta(y_i|x,z,y_{1:i-1})$$</li><li>RAG-Token模型<br>$$p_{RAG-Token}(y|x)≈\prod^N_i\sum_{z∈top-k(p(·|x))}p_\eta(z|x)p_\theta(y_i|x,z,y_{1:i-1})$$<h3 id="检索器：DPR"><a href="#检索器：DPR" class="headerlink" title="检索器：DPR"></a>检索器：DPR</h3>DPR(Dense Passage Retriever)，密集信息检索器<br>检索器$p_\eta(z|x)$基于DPR。DPR是一个双向编码器架构：<br>$$p_\eta(z|x)∝exp(d(z)^Tq(x)) ~~~ d(z)=BERT_d(z), q(x)=BERT_q(x)$$<br>其中，d(z)是使用BERT编码得到的密集表示，q(x)是问题通过BERT编码得到的表示。计算top-k($p_\eta(·|x)$)是一个MIPS(Maximum Inner Product Search)问题，可以在亚线性时间内解决。我们使用一个基于DPR的预训练双向编码器来初始化我们的检索器并建立索引，将其视为非参数记忆(non-parametric memory)。<h3 id="生成器：BART"><a href="#生成器：BART" class="headerlink" title="生成器：BART"></a>生成器：BART</h3>生成器可以使用任何编码器-解码器。我们使用的是BART-large。<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3>求最小似然log-likelihood、Adam<h3 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h3></li><li>RAG-Toke<br>$$p^{‘}_\theta(y_i|x,y_{1:i-1})=\sum_{z∈top-k(p(·|x))}p_\eta(z_i|x)p_\theta(y_i|x,z_i,y_{1:i-1})$$<br>将$p^{‘}_\theta(y_i|x,y_{1:i-1})$送入标准beam解码器中。</li><li>RAG-Sequence<br>Thorough Decoding<br>Fast Decoding</li></ul><h1 id="FLASHATTENTION-Fast-and-Memory-Efficient-Exact-Attention-with-IO-Awareness"><a href="#FLASHATTENTION-Fast-and-Memory-Efficient-Exact-Attention-with-IO-Awareness" class="headerlink" title="FLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-Awareness"></a>FLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-Awareness</h1><p>FlashAttention: 具有IO感知的快速和有效存储精确注意力<br>2022年6月24日<br><a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf">PDF</a><br><a href="https://github.com/Dao-AILab/flash-attention">CODE</a></p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>　　自注意力的时间和空间复杂度在序列长度上是二次关系，近似注意力机制尝试在模型质量和复杂度计算中折中来解决该问题，但是经常不能实现wall-clock加速。本文认为，需要一种规范，可以根据GPU读写水平使注意力IO感知。为此，本文提出FLASHATTENTION，一种IO感知的精确注意力机制，它使用tiling技术来减少GPU HBM（high bandwidth memory）和GPU芯片内SRAM的存储读写次数。FLASHATTENTION相比标准注意力机制要减少这方面开销。</p><h2 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h2><p><img src="\images\FlashAttention.png" class="lazyload" data-srcset="\images\FlashAttention.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="FlashAttention"><br>　　现代GPU的计算速度比存储速度快，在Transformer里的许多操作都受限于存储接入。现在的公共Python接口，比如PyTorch和Tensorflow对于内存接入没有精细化管理。本文提出FLASHATTENTION，一种计算注意力时减少内存接入操作的新注意力算法。它的目标是减少在HBM中读写的注意力矩阵。这需要<br>（1）在不访问整体输入的情况下计算softmax reduction；<br>（2）反向传播时不存大量中间过程的注意力矩阵。<br>　　本文提出两种方法解决上面的问题。<br>（1）我们重新构建了注意力计算模块，将输入分块，在输入块中形成多个通道，因此递增地执行softmax reduction（也就是tiling)；<br>（2）从前向传播到反向传播中快速重新计算片上注意力，我们存储了其中的softmax标准化因素，这比从HBM读取中间注意力矩阵的标准方法要快。<br>　　在CUDA使用FLASHATTENTION去实现精细化存储控制以及在GPU内核中融合所有的注意力操作。即使因为重计算会增加FLOP（Floating Point Operations），相对于标准注意力而言，我们的算法依然更快、需要更少的内存，在序列长度上是线性的，这是因为HBM的接入大量减少。<br>　　FLASHATTENTION在HBM上的复杂度是O(N^2d^2M^{-1})，其中d是头head的维度，M是SRAM的规模，标准注意力的复杂度是$Ω(Nd+N^2)$。<br>　　本文贡献点：</p><ul><li>更快的模型训练速度</li><li>更高的模型质量</li><li>比现有基线注意力都要快<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><h3 id="硬件性能"><a href="#硬件性能" class="headerlink" title="硬件性能"></a>硬件性能</h3>　　重点描述GPU。</li><li>GPU存储等级<br>　　HBM、SRAM</li><li>执行模型<br>　　GPU有很多线程去执行一个操作（称为核）。每个核从HBM登记加载输入，SRAM计算，再将输出写入HBM。</li><li>性能特点</li></ul><ol><li>计算密集型Compute-bound</li><li>存储密集型Memory-bound</li></ol><ul><li>内核融合<br>　　最常见的加速存储密集操作的就是内核融合。如果多个操作同时应用在相同的输入时，可以从HBM一次性加载输入。编译器会自动融合许多elementwise操作。然而，根据模型训练的上下文，中间过程的值为了反向传播仍然需要写入HBM，这降低了原生内核融合的效率。<h4 id="标准注意力"><a href="#标准注意力" class="headerlink" title="标准注意力"></a>标准注意力</h4>　　输入序列$Q,K,V∈\mathbb{R}^{N×d}$，其中N是序列长度，d是头head维度。我们想要计算注意力输出$O∈\mathbb{R}^{N×d}$。<br>$$S=QK^T∈\mathbb{R}^{N×N}, P=softmax(S)∈\mathbb{R}^{N×N}, O=PV∈\mathbb{R}^{N×d}$$<br>softmax按行(row-wise)使用。<br>　　标准注意力将S和P扔给HBM，这花费了$O(N^2)$存储。一般来说，N&gt;&gt;d，比如GPT2里N=1024，d=64。大部分操作是存储密集型（比如softmax），大量的存储读写造成wall-clock时间变慢。<br>　　其它操作更加加剧了这个问题，比如加在注意力矩阵的elementwise操作、加在S上的遮罩或者加在P上的dropout。为此，有很多融合几种elementwise操作的方法尝试，比如一些文献用softmax融合遮罩。<br><img src="\images\FlashAttention-StandardAttention伪代码.png" class="lazyload" data-srcset="\images\FlashAttention-StandardAttention伪代码.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="标准注意力伪代码"><h2 id="FLASHATTENTION"><a href="#FLASHATTENTION" class="headerlink" title="FLASHATTENTION"></a>FLASHATTENTION</h2>　　两种方法：tiling和recomputation<br>　　主要思路：将输入的Q、K、V分块，将它们从慢的HBM放到快的SRAM中，计算了注意力输出后再返回到各自块里。在每个快的输出相加之前，通过标准化进行缩放，最终得到结果。</li><li>Tiling</li><li>Recomputation<br>　　我们的目标之一是不要存储反向传播中间过程值$O(N^2)$。反向传播需要矩阵$S,P∈\mathbb{R}^{N×N}$来计算Q、K、V的梯度。<br><img src="\images\FlashAttention伪代码.png" class="lazyload" data-srcset="\images\FlashAttention伪代码.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="FlashAttention伪代码"></li></ul><h1 id="LORA-LOW-RANK-ADAPTATION-OF-LARGE-LANGUAGE-MODELS"><a href="#LORA-LOW-RANK-ADAPTATION-OF-LARGE-LANGUAGE-MODELS" class="headerlink" title="LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS"></a>LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS</h1><p>　　大模型的低秩适配器<br>　　微软 2021年<br>　　Low-Rank Adaptation, LORA<br><a href="https://arxiv.org/pdf/2106.09685.pdf">PDF</a><br><a href="https://github.com/microsoft/LoRA">CODE</a><br>　　冻结预训练模型的参数，在Transformer架构每一层注入一个可训练的低秩分解矩阵（rank decomposition matrices），大幅减少了下游任务的训练参数。<br>　　对比GPT-3 175B Adam微调，LoRA可以减少10000倍训练参数、3倍GPU存储。<br>　　对比RoBERTa, DeBERTa, GPT-2, GPT-3，训练参数虽少，模型微调质量更好，更高的训练吞吐量，而且不像适配器，没有额外的推理延迟。  </p><h2 id="引言-2"><a href="#引言-2" class="headerlink" title="引言"></a>引言</h2><p>　　微调会更新预训练模型的全部参数，下游任务的新模型和原模型参数一样多。许多研究者通过只更新部分参数或学习新任务的额外模块进行迁移，这样可以只保存和加载一小部分任务相关的参数即可，部署时提高了效率。但是现有方法通过延伸模型深度或者减少模型可用的序列长度会导致推理延迟。而且这些策略达不到微调的基线效果，在效率和模型质量上做了折中。<br><img src="\images\LoRA.png" class="lazyload" data-srcset="\images\LoRA.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="LoRA"></p><h2 id="问题陈述"><a href="#问题陈述" class="headerlink" title="问题陈述"></a>问题陈述</h2><p>　　给定一个预训练自回归语言模型$P_{\Phi}(y|x)$，$\Phi$为参数。将该模型用于下游任务。全量微调的话，模型将用预训练的权重$\Phi_0$作为初始化参数，并使用下方梯度计算公式来最大化目标以更新到$\Phi_0 + △\Phi$：<br>$$\underset{\Phi}{max}\sum_{(x,y)∈Z}\sum^{|y|}<em>{t=1}log(P</em>{\Phi}(y_t|x,y_{&lt;t}))$$  </p><p>　　全量微调的一个短板就是，下游任务不同就要学习不同的参数$△\Phi$，它的维度$|△\Phi|$和$|\Phi_0|$相同。而预训练模型的参数是很大的，这样就对存储和部署要求很高。<br>　　本文采用了一个更有效的方法，$△\Phi = △\Phi(\Theta)$是通过一个远小于$|△\Phi_{\Theta}|$的小尺寸参数$\Theta$编码得到。找到$△\Phi$变为了在$\Theta$上优化：<br>$$\underset{\Theta}{max}\sum_{(x,y)∈Z}\sum^{|y|}<em>{t=1}log(P</em>{\Phi}(y_t|x,y&lt;t))$$<br>　　本文提出了一种低秩表示来编码$△\Phi$。对于GPT-3 175B，$|\Theta|$的训练参数量是$|\Phi_0|$的0.01%。</p><h2 id="之前方法的缺点"><a href="#之前方法的缺点" class="headerlink" title="之前方法的缺点"></a>之前方法的缺点</h2><ul><li>适配器层引入了推理延迟  </li><li>直接优化Prompt很难<br>　　比如prefix tuning<h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><h3 id="低秩参数更新矩阵"><a href="#低秩参数更新矩阵" class="headerlink" title="低秩参数更新矩阵"></a>低秩参数更新矩阵</h3>假定$W_0∈\mathbb{R}^{d×k}$。<br>$W_0 + △W = W_0 + BA$，其中$B∈\mathbb{R}^{d×r}$，$A∈\mathbb{R}^{r×k}$，这个r的秩远小于min(d, k)。<br>训练时，冻住$W_0$，不接收梯度更新，同时A和B包含可训练参数。<br>设$h = W_0x$：<br>$$h = W_0x+△Wx = W_0x + BAx$$<br>当遇到不用的下游任务时，只需要替换BA就行，所以没有推理延迟。</li></ul><h3 id="将LoRA应用到Transformer"><a href="#将LoRA应用到Transformer" class="headerlink" title="将LoRA应用到Transformer"></a>将LoRA应用到Transformer</h3><p>在Transformer架构中，在自注意力模块有四个权重矩阵（$W_q$、$W_k$、$W_v$、$W_o$），在MLP模块有两个。本文将Transformer架构中的$W_q$（或者$W_k$，$W_v$）设为一个$d_{model}×d_{model}$的单矩阵。对于下游任务，只改变注意力权重，冻结MLP模块的。</p><h1 id="Llama-2-Open-Foundation-and-Fine-Tuned-Chat-Models"><a href="#Llama-2-Open-Foundation-and-Fine-Tuned-Chat-Models" class="headerlink" title="Llama 2: Open Foundation and Fine-Tuned Chat Models"></a>Llama 2: Open Foundation and Fine-Tuned Chat Models</h1><p>2023年7月  77页<br>GenAI, Meta<br><a href="https://arxiv.org/pdf/2307.09288.pdf">PDF</a><br><a href="https://github.com/facebookresearch/llama">CODE</a></p><h2 id="引言-3"><a href="#引言-3" class="headerlink" title="引言"></a>引言</h2><p>　　本文发布了两个模型：</p><ul><li>LLAMA 2，它是LLAMA 1的升级版本，训练语料新增40%，模型上下文长度翻倍，采用了分组查询注意力。发布了7B, 13B, 70B，34B也训了但没发布</li><li>LLAMA 2-CHAT，它是LLAMA 2用于用户对话的微调版本。发布了7B，13B，70B参数模型<br>　　提供了<a href="https://ai.meta.com/llama">用户手册</a>和<a href="‖https://github.com/facebookresearch/llama">代码样例</a></li></ul><h2 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h2><p>　　预训练数据：2 trillion<br>　　训练，与LLAMA 1相同之处：  </p><ul><li>标准transformer</li><li>RMSNorm预归一化</li><li>SwiGLU激活函数</li><li>旋转位置embedding RoPE<br>　　不同之处：</li><li>增加上下文长度</li><li>分组查询注意力（GQA）</li></ul><p>　　优化器：AdamW<br>　　分词器：与LLAMA 1相同，此表规模32k tokens</p><p>　　它甚至还写了LLAMA 2的碳排放情况…  </p><p>　　评价指标方面，LLAMA 2 70B在MMLU和GSM8K上与GPT-3.5相近，但是在代码基线上有差距，在几乎所有的基线上都比PaLM(540B)强。与GPT-4和PaLM-2-L相比，还有很大差距。</p><h2 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h2><h3 id="SFT监督微调"><a href="#SFT监督微调" class="headerlink" title="SFT监督微调"></a>SFT监督微调</h3><p>　　使用了公开的微调数据，自己标了一些，有27540这么多就不标了，因为数量少质量高效果也能好。<br>　　对于微调过程，每一个样本包含一个提示prompt和一个答案。为了确保模型序列长度都被填充，训练集里将全部的prompt和答案相连。用了特殊token划分prompt和答案片段。使用了一种自回归目标函数，并将来自用户prompt的token计算loss归零，所以只在答案token上反向传播。模型微调轮数为2。  </p><h3 id="RLHF-人类反馈的增强学习"><a href="#RLHF-人类反馈的增强学习" class="headerlink" title="RLHF 人类反馈的增强学习"></a>RLHF 人类反馈的增强学习</h3><p>　　RLHF是一种将微调模型行为与人类偏好和指令对齐的一种模型训练过程。首先让标注员写一个提示（prompt），然后对两个样本模型的回答根据制定的标准选择更好的一个，这种数据用于训练奖励模型（reward model）。为了多样性最大化，两个模型参数和超参数不同。为了让参与者强制选择，每个回答会打标程度（很好，好，一般，不确定）。合适的标注从两个方面考虑，有用性和安全性。在其它答案是安全的情况下，不会选择不安全的回答为最佳，因为本文认为安全回答也是更好的。<br>　　收集了更多的偏好数据后，奖励模型进步了，LLAMA 2-CHAT就会训练地更好，而它更好又会改变模型数据分布。如果不用最新的样本分布，奖励模型的精确度就会很快降低。所以在微调新一轮LLAMA 2-CHAT前使用当前最新的LLAMA 2-CHAT收集数据很重要。这一步让奖励模型保持正确的分布，也能保持最新模型的准确奖励值。<br>　　本文收集了超过一百万（1 million）人工标注数据，称做Meta奖励模型数据。不同领域提示和回答的数量不同，总结和在线公式数据一般有较长的提示，然而对话型提示通常较短。平均来看，本文的数据比开源数据集有更多轮的对话，并且更长。<br>　　奖励模型将模型回复和对应的提示（包括之前的多轮上下文）作为输入，输出一个标量分数来衡量模型生成质量。将这些分数作为奖励，通过RLHF优化LLAMA 2-CHAT获得更好的效果，提升有用性和安全性。<br>　　有用性和安全性往往需要折中，所以本文训练了两个分开的奖励模型，一个用来优化可用性（Helpfulness RM），一个用来优化安全性（Safety RM）。<br>　　本文使用预训练对话模型checkpoint来初始化奖励模型，这样可以确保所有的模型从预训练中得到知识。除了将下一个token预测分类头替换为一个标量奖励值的回归头输出以外，模型架构和超参数和预训练模型一致。  </p><p>　　为了训练奖励模型，将人工标注数据转为二分类排序标签格式（比如选择&amp;拒绝），让选择的回复有更高的分数。loss是二分类排序损失函数：$$L_{ranking}=-log(\sigma(r_\theta(x, y_c)-r_\theta(x,y_r)))$$<br>　　其中，$r_\theta(x, y)$是对于提示x和回答y的标量分数输出表示，$\theta$是模型权重。$y_c$是标注员选择的回答，$y_r$是被拒绝的回答。<br>　　输出是有四个分数的标量（比如很好），为了加大各分数差距，更好的区别有用性和安全性，将损失函数改为：<br>$$L_{ranking}=-log(\sigma(r_\theta(x, y_c)-r_\theta(x,y_r) - m(r)))$$<br>　　其中，$m(r)$是评分的离散函数，两个回答越不同，这个边距越大，两个回答越相似，这个边距越近。这个边距可以提升有用性。</p><p>　　训练细节：训了一轮，本文发现训久了过拟合。</p><p>　　本文采用了两种主要的RLHF微调算法：</p><ul><li>PPO(Proximal Policy Optimization)算法</li><li>拒绝采用微调(Rejection Sampling fine-tuning)，只在70B上用了<br>在K个模型输出中使用奖励模型选择最好的，将选择出来的做梯度更新。对于每个提示，包含最好奖励分数的样本作为新的标准。然后在新的样本中微调，加强奖励。<br>两个算法主要在广度和深度上有区别。<h3 id="多轮对话一致性的系统信息"><a href="#多轮对话一致性的系统信息" class="headerlink" title="多轮对话一致性的系统信息"></a>多轮对话一致性的系统信息</h3>有些指令应该贯穿对话始终，比如“扮演xx”指令，但是原始的RLHF模型在几轮后会忘记初始指令。为此，提出Ghost注意力（GAtt）。</li></ul><h1 id="LLaMA-Open-and-Efficient-Foundation-Language-Models"><a href="#LLaMA-Open-and-Efficient-Foundation-Language-Models" class="headerlink" title="LLaMA: Open and Efficient Foundation Language Models"></a>LLaMA: Open and Efficient Foundation Language Models</h1><p>Meta AI<br><a href="https://arxiv.org/pdf/2302.13971.pdf">PDF</a><br><a href="https://github.com/facebookresearch/llama">CODE</a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>　　不像Chinchilla、PaLM或者GPT-3，只使用公开可用的数据训练。<br>　　训练不是最快的，但是推理是最快的。<br>　　本文目标是打造一系列用更多token训练的最佳推理性能的大模型。LLaMA：6.7B、13.0B、32.5B、65.2B<br>　　LLaMA-13B超过GPT3。<br>　　LLaMA-65B与Chinchilla或PaLM-540B相当。</p><h2 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h2><h3 id="预训练数据"><a href="#预训练数据" class="headerlink" title="预训练数据"></a>预训练数据</h3><ul><li>English CommonCrawl(67%)：使用fastText去掉非英语文本、使用一个n-gram语言模型去掉低质量内容、用一个线性模型对维基百科中用作参考文献的页面与随机抽样的页面以及未归类为参考文献的废弃页面进行分类</li><li>C4(15%)：与CCNet的主要区别是质量过滤，它主要依赖于启发式，如标点符号的存在或网页中的单词和句子的数量</li><li>Github(4.5%):基于行长度或字母数字字符比例的启发式法过滤低质量文件</li><li>Wikipedia(4.5%)</li><li>Gutenberg and Book3(4.5%)：去掉了有90%重复的书籍</li><li>ArXiv(2.5%):删除了第一部分之前的所有内容、参考书目、.tex文件中的评论、用户编写的内联扩展定义和宏</li><li>Stack Exchange(2%)：问答数据，删除了文本中的HTML标签，并根据分数对答案进行了排序(由高到低)<br>　　分词：BPE算法<br>　　整个训练集经分词后有1.4T个token(33B和65B)</li></ul><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>　　transformer架构基础上魔改。<br>　　魔改点（中括号内为灵感来源）：</p><ul><li>预归一化[GPT3]：使用RMSNorm</li><li>SwiGLU激活函数[PaLM]</li><li>旋转embedding[GPTNeo]：将绝对位置编码换成了旋转位置嵌入RoPE</li></ul><p>　　优化器：AdamW</p><p>　　训练速度优化：</p><ul><li>随机多头注意力机制，不保存注意力权重，不计算key/query分数（masked）</li><li>减少了反向传播中重复计算的激活单元的数量，只保存最耗费计算的单元，比如线性层的输出；没有使用PyTorch autograd；使用了模型和序列并行化减少模型内存占用；尽量将激活单元的计算和GPU之间的网络通信通用</li></ul><p>　　训练时间：<br>　　65B参数模型：2048张A100 GPU，80GB内存，380 tokens/sec/GPU，1.4T tokens训练了21天</p><p>　　它甚至还写了LLAMA的碳排放情况…</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;&#92;images&#92;paper.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt; 　　&lt;br&gt;　　&lt;strong&gt;大模型相关论文阅读笔记。 &lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;倒序排列论文，最新阅读的在最上面。&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;2024年1月26日更新&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="大模型" scheme="https://hubojing.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="LLM" scheme="https://hubojing.github.io/tags/LLM/"/>
    
      <category term="论文" scheme="https://hubojing.github.io/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>Hexo + Github Action部署博客</title>
    <link href="https://hubojing.github.io/2023/11/16/Hexo+GithubAction%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2/"/>
    <id>https://hubojing.github.io/2023/11/16/Hexo+GithubAction部署博客/</id>
    <published>2023-11-16T14:20:55.000Z</published>
    <updated>2023-11-20T05:10:55.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\blog.png" class="lazyload" data-srcset="\images\blog.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br> 　　<br>　　<strong>真正快捷的多机部署方法！</strong><br><br>　　<strong>不是在采坑，就是在采坑的路上。</strong><br><br><br> </div><span id="more"></span><h1 id="更换部署方式的原因"><a href="#更换部署方式的原因" class="headerlink" title="更换部署方式的原因"></a>更换部署方式的原因</h1><p>（不关心的朋友可以跳过这一节）<br>　　以前许多年一直是<code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code>一键部署，这样导致每台机器上都需要配置环境，以前还挺喜欢折腾这些，写过<a href="https://hubojing.github.io/2017/11/19/hexo%E5%A4%9A%E6%9C%BA%E5%90%8C%E6%AD%A5/">Hexo多机同步</a> ，但是通过篇幅可以看出，太麻烦，不符合工作后能够快速更换设备的需求。近年来我逐渐注意到CI/CD的方法，先是在Gitlab上体验了一把，确实好用，后来某天惊喜发现Github出了官方的Github Action，于是有了本文的尝试。<br>　　更换后，换机再也不用安环境了，只需要把源文件项目<code>git clone</code>一下，写文，在<code>git add .</code>、<code>git commit -m &#39;update&#39;</code>、<code>git push</code>三部曲就好啦！</p><h1 id="两个项目"><a href="#两个项目" class="headerlink" title="两个项目"></a>两个项目</h1><p>　　源文件 user/blog-source  (privare)<br>　　前端显示 username/username.github.io  (public)</p><h1 id="两把钥匙"><a href="#两把钥匙" class="headerlink" title="两把钥匙"></a>两把钥匙</h1><p>　　在源文件项目git bash<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -f blog-deploy-key</span><br></pre></td></tr></table></figure><br>　　生成</p><ul><li>私钥 <code>blog-deploy-key</code></li><li>公钥 <code>blog-deploy-key.pub</code></li></ul><p>　　配置：</p><ul><li>源文件项目 settings - Secrets and variables - Actions 放入私钥</li><li>前端展示项目 settings - Deploy keys 放入公钥</li></ul><h1 id="workflow"><a href="#workflow" class="headerlink" title="workflow"></a>workflow</h1><p>　　创建相关文件夹和文件，源文件根路径下blog/.github/workflows/deploy.yml<br>　　参考模板在这里<a href="https://github.com/marketplace/actions/hexo-action">https://github.com/marketplace/actions/hexo-action</a><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># Deploy hexo blog website.</span><br><span class="line">   - name: Deploy</span><br><span class="line">     id: deploy</span><br><span class="line">     uses: sma11black/hexo-action@v1.0.3</span><br><span class="line">     with:</span><br><span class="line">       deploy_key: $&#123;&#123; secrets.HEXO_DEPLOY_PRI &#125;&#125;</span><br><span class="line">       user_name: username  # (or delete this input setting to use bot account)</span><br><span class="line">       user_email: your email  # (or delete this input setting to use bot account)</span><br><span class="line">       PUBLISH_REPOSITORY: username/username.github.io</span><br><span class="line">       BRANCH: master</span><br><span class="line">       PUBLISH_DIR: ./public</span><br><span class="line">       commit_msg: $&#123;&#123; github.event.head_commit.message &#125;&#125;  # (or delete this input setting to use hexo default settings)</span><br></pre></td></tr></table></figure></p><h1 id="关于主题的配置"><a href="#关于主题的配置" class="headerlink" title="关于主题的配置"></a>关于主题的配置</h1><p>　　这一部分写的人太少，疯狂采坑，我来详细说一下。<br>　　主题是作为submodule加入的，但是配置如果不想被看到的话，最好单独写成文件，具体看这里：<br>　　但是单独配置文件的写法需要hexo5.0以上才能实现，indigo主题才3.0+，所以最简单的方法是fork原主题后，设置为private。<br>　　要访问private项目是需要授权的。</p><h2 id="具体做法"><a href="#具体做法" class="headerlink" title="具体做法"></a>具体做法</h2><ul><li>Github-Settings-Developer settings-Personal access tokens-Tokens(classic)-Generate new token(classic)</li><li>复制该token</li><li>在源文件项目blog-source中在源文件项目blog-source中：Settings-Secrets and variables-Actions-New repository secret，粘贴该token</li><li>在workflow的配置文件中写<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with:</span><br><span class="line">        token: $&#123;&#123; secrets.PERSONAL_TOKEN &#125;&#125;</span><br><span class="line">        submodules: true</span><br></pre></td></tr></table></figure></li></ul><h1 id="完整的deploy-yml"><a href="#完整的deploy-yml" class="headerlink" title="完整的deploy.yml"></a>完整的deploy.yml</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">name: Deploy</span><br><span class="line"></span><br><span class="line">on: [push]</span><br><span class="line"></span><br><span class="line">jobs:</span><br><span class="line">  build:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    name: A job to deploy blog.</span><br><span class="line">    steps:</span><br><span class="line">    - name: Checkout</span><br><span class="line">      uses: actions/checkout@v1</span><br><span class="line">      with:</span><br><span class="line">        token: $&#123;&#123; secrets.PERSONAL_TOKEN &#125;&#125;</span><br><span class="line">        submodules: true # Checkout private submodules(themes or something else).</span><br><span class="line">    </span><br><span class="line">    # Caching dependencies to speed up workflows. (GitHub will remove any cache entries that have not been accessed in over 7 days.)</span><br><span class="line">    - name: Cache node modules</span><br><span class="line">      uses: actions/cache@v1</span><br><span class="line">      id: cache</span><br><span class="line">      with:</span><br><span class="line">        path: node_modules</span><br><span class="line">        key: $&#123;&#123; runner.os &#125;&#125;-node-$&#123;&#123; hashFiles(&#x27;**/package-lock.json&#x27;) &#125;&#125;</span><br><span class="line">        restore-keys: |</span><br><span class="line">          $&#123;&#123; runner.os &#125;&#125;-node-</span><br><span class="line">    - name: Install Dependencies</span><br><span class="line">      if: steps.cache.outputs.cache-hit != &#x27;true&#x27;</span><br><span class="line">      run: npm ci</span><br><span class="line">    </span><br><span class="line">    # Deploy hexo blog website.</span><br><span class="line">    - name: Deploy</span><br><span class="line">      id: deploy</span><br><span class="line">      uses: sma11black/hexo-action@v1.0.3</span><br><span class="line">      with:</span><br><span class="line">        deploy_key: $&#123;&#123; secrets.HEXO_DEPLOY_PRI &#125;&#125;</span><br><span class="line">        user_name: username  # (or delete this input setting to use bot account)</span><br><span class="line">        user_email: your email  # (or delete this input setting to use bot account)</span><br><span class="line">        PUBLISH_REPOSITORY: username/username.github.io</span><br><span class="line">        BRANCH: master</span><br><span class="line">        PUBLISH_DIR: ./public</span><br><span class="line">        commit_msg: $&#123;&#123; github.event.head_commit.message &#125;&#125;  # (or delete this input setting to use hexo default settings)</span><br><span class="line">    # Use the output from the `deploy` step(use for test action)</span><br><span class="line">    - name: Get the output</span><br><span class="line">      run: |</span><br><span class="line">        echo &quot;$&#123;&#123; steps.deploy.outputs.notify &#125;&#125;&quot;</span><br></pre></td></tr></table></figure><h1 id="无伤大雅的缺点"><a href="#无伤大雅的缺点" class="headerlink" title="无伤大雅的缺点"></a>无伤大雅的缺点</h1><p>　　这个应该是git操作的哪个部分出问题了，导致<code>git push</code>后前端项目历史push记录丢失了，损失就是github页的绿点没了，其它的没什么影响，毕竟前端页面的渲染结果没源文件有用。<code>git reflog</code>只剩下最新的一条，历史的都丢失了，不过不影响博客就算了。这个问题这些年也遇到好几次了，如果有大佬遇到过一样的问题，如愿赐教，将非常感谢。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.cnblogs.com/lastkiss/p/16955696.html">Hexo&amp;github action持续部署</a><br><a href="https://www.taniarascia.com/git-submodules-private-content/">Using Git Submodules for Private Content</a><br><a href="https://zhuanlan.zhihu.com/p/626270948">github action 部署 hexo踩坑记录</a><br><a href="https://zhuanlan.zhihu.com/p/408319831">Github Actions: submodule 下公私有仓库授权和通信</a><br><a href="https://sanonz.github.io/2020/deploy-a-hexo-blog-from-github-actions/">利用 Github Actions 自动部署 Hexo 博客</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;&#92;images&#92;blog.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt; 　　&lt;br&gt;　　&lt;strong&gt;真正快捷的多机部署方法！&lt;/strong&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;不是在采坑，就是在采坑的路上。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="博客" scheme="https://hubojing.github.io/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="博客" scheme="https://hubojing.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="Hexo" scheme="https://hubojing.github.io/tags/Hexo/"/>
    
      <category term="Github Action" scheme="https://hubojing.github.io/tags/Github-Action/"/>
    
  </entry>
  
  <entry>
    <title>InstructGPT笔记</title>
    <link href="https://hubojing.github.io/2023/03/14/InstructGPT/"/>
    <id>https://hubojing.github.io/2023/03/14/InstructGPT/</id>
    <published>2023-03-14T13:05:47.000Z</published>
    <updated>2023-03-14T13:05:47.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>简记。</strong><br><br><br> </div><span id="more"></span><h1 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h1><p>Training language models to follow instructions with human feedback</p><p>根据人类反馈指示来训练语言模型</p><p>OpenAI 2022</p><h1 id="核心"><a href="#核心" class="headerlink" title="核心"></a>核心</h1><p>该系统包含主要三个步骤实现：</p><p>1、使用一组广泛分布的互联网数据对GPT-3模型进行预训练。然后，针对典型的一组human prompts，让laber写下正确的答案并用这组12,725的监督数据对模型进行精调；</p><p>2、随机选择一组human prompts，并用模型对每个prompt产生多个输出的答案。让labeler对这些回答进行排序，并根据排序训练一个奖励模型 （reward model）。这组用来训练reward model的数据包含有33,207个prompts以及在不同回答组合下产生的10倍于此的答案；</p><p>3、再次随机采样human prompts，并基于PPO的强化学习算法（Proximal Policy Optimization Algorithm）对监督训练后精调过的模型进行再次fine-tune。每个采样的prompt输入PPO模型，并用reward model给出的奖励信号用31,144个prompts对模型进行训练。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;简记。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="GPT" scheme="https://hubojing.github.io/tags/GPT/"/>
    
  </entry>
  
  <entry>
    <title>命名实体识别（NER）论文泛读</title>
    <link href="https://hubojing.github.io/2023/03/08/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%EF%BC%88NER%EF%BC%89%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/"/>
    <id>https://hubojing.github.io/2023/03/08/命名实体识别（NER）论文泛读/</id>
    <published>2023-03-08T15:54:02.000Z</published>
    <updated>2023-03-08T15:59:44.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>论文泛读不定期更新。</strong><br><br><br> </div><span id="more"></span><h1 id="SpanBert"><a href="#SpanBert" class="headerlink" title="SpanBert"></a>SpanBert</h1><p><a href="https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00300/1923170/tacl_a_00300.pdf">PDF</a></p><h1 id="Global-Pointer-Novel-Efficient-Span-based-Approach-for-Named-Entity-Recognition"><a href="#Global-Pointer-Novel-Efficient-Span-based-Approach-for-Named-Entity-Recognition" class="headerlink" title="Global Pointer: Novel Efficient Span-based Approach for Named Entity Recognition"></a>Global Pointer: Novel Efficient Span-based Approach for Named Entity Recognition</h1><p>2022-12-11阅读</p><h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>苏剑林 2022年8月</p><h1 id="A-Unified-MRC-Framework-for-Named-Entity-Recognition"><a href="#A-Unified-MRC-Framework-for-Named-Entity-Recognition" class="headerlink" title="A Unified MRC Framework for Named Entity Recognition"></a>A Unified MRC Framework for Named Entity Recognition</h1><p>2022-12-07阅读</p><h2 id="论文概况-1"><a href="#论文概况-1" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2020<br><a href="https://arxiv.org/abs/1910.11476">PDF</a><br><a href="https://github.com/ShannonAI/mrc-for-flat-nested-ner">CODE</a></p><p>##笔记<br>使用MRC（Machine Reading Comprehension）思想，将NER任务转换为MRC任务。它能引入query先验知识，对重叠的NER实体相当于回答不同的问题，所以它能同时解决flat和nested NER问题。</p><h1 id="Named-Entity-Recognition-as-Dependency-Parsing"><a href="#Named-Entity-Recognition-as-Dependency-Parsing" class="headerlink" title="Named Entity Recognition as Dependency Parsing"></a>Named Entity Recognition as Dependency Parsing</h1><p>2022-12-05阅读</p><h2 id="论文概况-2"><a href="#论文概况-2" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2020<br><a href="https://aclanthology.org/2020.acl-main.577/">PDF</a><br><a href="https://github.com/juntaoy/biaffine-ner">CODE</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>以前NER常见模式是BiLSTM+CRF，BiLSTM用于输入编码，CRF用于分类。本文提出一种双仿射模型替代CRF用于分类。<br>" class="lazyload" data-srcset="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==<img src="" alt="架构图"></p><h1 id="Boundary-Enhanced-Neural-SpanClassification-for-Nested-Named-Entity-Recognition"><a href="#Boundary-Enhanced-Neural-SpanClassification-for-Nested-Named-Entity-Recognition" class="headerlink" title="Boundary Enhanced Neural SpanClassification for Nested Named Entity Recognition"></a>Boundary Enhanced Neural SpanClassification for Nested Named Entity Recognition</h1><p>边界增强神经跨度分类用于嵌套命名实体识别</p><p>阅读时间：2022-09-19</p><p>论文概况</p><p>AAAI 2020</p><p>阿里巴巴</p><p>Chuanqi Tan, Wei Qiu, Mosha Chen, Rui Wang, Fei Huang</p><p>问题提出</p><p>针对嵌套命名实体识别，基于span的方法有两个问题：</p><ol><li>对所有子序列进行分类在计算上是十分昂贵的，效率低下。</li><li>基于span的方法主要侧重于学习跨度表示，但缺乏明确的边界监督。</li></ol><p>为此，本文提出一种边界增强的神经跨度分类模型（BENSC），除了对span进行分类之外，本文还结合一个额外的边界检测任务来预测那些作为实体边界的单词。这两个任务在多任务学习框架下联合训练，通过额外的边界监督增强了跨度表示。被视为实体的span应该在span级别和边界级别都具有高概率。另外，边界检测模型具有生成高质量候选span的能力，大大降低了推理过程中的时间复杂度到几乎线性时间。</p><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>" class="lazyload" data-srcset="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==<img src="" alt=""></p><h1 id="Chinese-named-entity-recognition-The-state-of-the-art"><a href="#Chinese-named-entity-recognition-The-state-of-the-art" class="headerlink" title="Chinese named entity recognition: The state of the art"></a>Chinese named entity recognition: The state of the art</h1><p>中文命名实体识别：最新技术</p><p>阅读时间：2022-08-11</p><h2 id="论文概况-3"><a href="#论文概况-3" class="headerlink" title="论文概况"></a>论文概况</h2><p>2022年2月 Neurocomputing</p><p><a href="https://www.sciencedirect.com/science/article/pii/S0925231221016581/pdfft?md5=ab00af6205a671b5d2b841acf7111fd0&amp;pid=1-s2.0-S0925231221016581-main.pdf">PDF</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="命名实体识别" scheme="https://hubojing.github.io/tags/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/"/>
    
      <category term="NER" scheme="https://hubojing.github.io/tags/NER/"/>
    
  </entry>
  
  <entry>
    <title>向量检索技术</title>
    <link href="https://hubojing.github.io/2023/02/28/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF/"/>
    <id>https://hubojing.github.io/2023/02/28/向量检索技术/</id>
    <published>2023-02-28T13:48:28.000Z</published>
    <updated>2023-02-28T13:54:24.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\假装有图片.jpg" class="lazyload" data-srcset="\images\假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>笔记。</strong><br><br><br> </div><span id="more"></span><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>大数据领域检索分两类：</p><ul><li>结构化数据检索，如ElasticSearch、Solr、关系型数据库等</li><li>非结构化数据检索，如图片、音频、视频等</li></ul><p>向量检索第一步：对非结构化的数据进行向量化表示</p><p>即物品的向量要满足相似物品的距离近，不相似的距离远，这种对物品进行特征表示的方法称为<strong>度量学习（metric learning)</strong>。</p><p>传统度量学习方法：线性投影  核方法</p><p>缺点：无法解决非线性特征</p><p>深度度量学习：通过激活函数提供非线性变换能力</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>向量检索定义：在一个给定向量数据集中，按照某种度量方式，检索出与查询向量相近的K个向量（K-Nearest Neighbor, KNN），但KNN计算量大，通常只关注近似近邻（Approximate Nearest Neighbor, ANN）问题。</p><p>向量检索算法需解决两个问题：</p><ul><li>减少候选向量集：通过各种策略，比如构建索引结构，实现检索时绕开不相关向量；</li><li>降低单个向量计算的复杂度：找到候选向量后，要对单个向量的相似度进行计算，但复杂度搞，需要处理。</li></ul><p>经典检索算法有三个：</p><ul><li><p>NSW</p><p>关键是在构图过程中通过贪婪搜索算法记录下搜索最优路径。</p></li><li><p>HNSW</p><p>对NSW的升级，使用跳表结构代替NSW的链表结构通过空间换时间的方法将向量检索的复杂度从多重对数复杂度降至对数复杂度。</p></li><li><p>IVF_PQ</p><p>通过乘积量化（PQ）将向量进行压缩，降低计算复杂度；通过聚类加倒排（IVF）减少检索候选集。</p></li></ul><p>其它：</p><p>IVFSQ8、IVF_FLAT是IVF算法变种，分别在召回率、内存占用和响应时间做了折中处理；适用于测试生成groud truth集合的FLAT纯暴力检索算法。</p><p>常见的四种向量度量方式：</p><p>欧氏距离（L2）、余弦、内积（IP）、杰卡德距离</p><p>通常欧式距离用于图片检索，余弦用于人脸识别，内积、杰卡德距离多用于推荐。</p><h1 id="一些结论"><a href="#一些结论" class="headerlink" title="一些结论"></a>一些结论</h1><p>高召回率从高到底</p><p>FLAT（仅供测试使用） &gt; HNSW &gt; IVFFLAT &gt; IVF*SQ8 *&gt; IVF_PQ</p><p>查询响应时间从低到高</p><p>HNSW &gt; IVF*PQ *&gt; IVF_SQ8 &gt; IVF_FLAT &gt; FLAT</p><p>资源占用从高到底</p><p>IVF_PQ &gt; IVF_SQ8 &gt; HNSW</p><p>如，内存和磁盘足够，百万~千万级，选HNSW算法；召回率要求不高，相应时间要求较高，集群资源有限，数据集较大（亿级），选IVF_SQ8算法。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;&#92;images&#92;假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;笔记。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="软件开发" scheme="https://hubojing.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="向量检索" scheme="https://hubojing.github.io/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>2022年终总结</title>
    <link href="https://hubojing.github.io/2023/01/01/2022%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>https://hubojing.github.io/2023/01/01/2022年终总结/</id>
    <published>2023-01-01T13:20:04.000Z</published>
    <updated>2023-01-01T15:52:52.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="\images\假装有图片.jpg" class="lazyload" data-srcset="\images\假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>短短总结一下。</strong><br><br><br> </div><span id="more"></span><p>2022年是生命长河里记忆深刻的一年。<br>我再次离开校园，走向职场。</p><p>技术博客只谈技术。</p><h1 id="上半场"><a href="#上半场" class="headerlink" title="上半场"></a>上半场</h1><p>在学校时，我的研究方向是推荐算法、时空数据挖掘，小方向是兴趣点推荐。虽然现在没有从事推荐算法的工作，但我依然经常阅读和跟进推荐算法相关的技术，作为一种爱好吧。<br><a href="https://github.com/hubojing/POI-Recommendation">POI Recommendation</a><br>记得在学校时，有同学研究和交通有关的课题，那时的我对交通方面是没什么兴趣的。现在，当我人在外地时，想着回家可以快点、再快点时，突然明白了交通的重要性，明白了提速对于社会进步的重要性。</p><h1 id="下半场"><a href="#下半场" class="headerlink" title="下半场"></a>下半场</h1><p>进入职场后，我的研究方向是NLP算法，信息抽取方向。<br>对我来说，信息抽取是一个新方向，虽然之前接触到一些旁支，比如知识图谱相关的工作，但是没有专门研究过这一块。<br>所以一切都从最初快速学起。<br><a href="https://github.com/hubojing/Information-Extraction-Papers">Information-Extraction-Papers</a><br>在团队里认识了很多技术大佬，他们技术扎实，研究能力强，大家每周围在一起讨论的感觉很有读研时的样子。我可以感受到他们对技术和研究的热爱，当提到竞赛、模型和算法时，他们的眼神都会亮起来。热爱是能力提升的最大动力，我很荣幸能够有机会与他们共事。这种研究的氛围我很喜欢。</p><h1 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h1><p>技术展望的话，这一年我突然觉得机器人方向才是未来最有潜力的方向。<br>随着最近ChatGPT的大火，大模型或有一统NLP的趋势。</p><p>博客的更新速度这半年没有跟上。一方面，由于人在外地，日常通过平板远程到自用笔记本，键鼠操作的延迟不是很方便，导致自己不太愿意去写。另一方面，刚开始花费了一定的精力和时间去体验一个人在外的感觉，后来因为疫情又担心在家的爸妈，再后来，自己也阳了……每日工作后略感疲惫，心有余而力不足。找起借口来，总是有话说。总之，我对目前自身的技术现状是不够满意的。</p><p>一晃工作也半年了，业务、团队和环境都逐渐熟悉和适应了，身体也逐渐康复，理应在2023年里，在技术层面有一个新的提升。心里默默立了一些Flag，就不写出来献丑了。</p><p>希望自己能把技术打扎实，不要一直是浮在表面的菜狗一条。</p><p>本来想写的全面一点，但是阳康后不能熬夜，就先这样吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;&#92;images&#92;假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;短短总结一下。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="杂谈" scheme="https://hubojing.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="年终总结" scheme="https://hubojing.github.io/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Python深拷贝与浅拷贝bug实例浅析</title>
    <link href="https://hubojing.github.io/2022/12/03/Python%E6%B7%B1%E6%8B%B7%E8%B4%9D%E4%B8%8E%E6%B5%85%E6%8B%B7%E8%B4%9Dbug%E5%AE%9E%E4%BE%8B%E6%B5%85%E6%9E%90/"/>
    <id>https://hubojing.github.io/2022/12/03/Python深拷贝与浅拷贝bug实例浅析/</id>
    <published>2022-12-03T15:26:08.000Z</published>
    <updated>2022-12-03T15:38:24.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>一个bug引起的……thinking</strong><br><br><br> </div><span id="more"></span><h1 id="需求简述"><a href="#需求简述" class="headerlink" title="需求简述"></a>需求简述</h1><p>　　将excel学生信息表转换为json格式。<br>　　其中代码有一步要将excel每行的数据按照json模板格式替换掉默认值。</p><h1 id="原代码"><a href="#原代码" class="headerlink" title="原代码"></a>原代码</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xlrd</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GetStudentInfo</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, student_info_path</span>):</span><br><span class="line">        self.student_info_path = student_info_path</span><br><span class="line">        self.template = &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;ZhangSan&quot;</span>,</span><br><span class="line">            <span class="string">&quot;sex&quot;</span>: <span class="string">&quot;female&quot;</span>,</span><br><span class="line">            <span class="string">&quot;grade&quot;</span>: <span class="string">&quot;6&quot;</span>,</span><br><span class="line">            <span class="string">&quot;age&quot;</span>: <span class="string">&quot;12&quot;</span>,</span><br><span class="line">            <span class="string">&quot;id&quot;</span>: <span class="string">&quot;0&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_new_student</span>(<span class="params">self, name, student_id</span>):</span><br><span class="line">        new_student = self.template</span><br><span class="line">        new_student[<span class="string">&#x27;name&#x27;</span>] = name</span><br><span class="line">        new_student[<span class="string">&#x27;id&#x27;</span>] = student_id</span><br><span class="line">        <span class="keyword">return</span> new_student</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_whole_stu_info</span>(<span class="params">self</span>):</span><br><span class="line">        students = &#123;&#125;</span><br><span class="line">        tables = xlrd.open_workbook(self.student_info_path)</span><br><span class="line">        table = tables.sheets()[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, table.nrows - <span class="number">1</span>):</span><br><span class="line">            name = table.cell_value(row + <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">            student_id = table.cell_value(row + <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            new_student = self.create_new_student(name, student_id)</span><br><span class="line">            students[<span class="built_in">str</span>(row)] = new_student</span><br><span class="line">        self.get_new_file(students)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_new_file</span>(<span class="params">self, students</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./output.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">            json.dump(students, file, indent=<span class="number">4</span>, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==  <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    student_info_path = <span class="string">&#x27;./student_info.xlsx&#x27;</span></span><br><span class="line">    data = GetStudentInfo(student_info_path)</span><br><span class="line">    data.get_whole_stu_info()</span><br></pre></td></tr></table></figure><p>　　输出文件为</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;GouDong&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">4.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;1&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;GouDong&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">4.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;2&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;GouDong&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">4.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;3&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;GouDong&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">4.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h1 id="Bug定位"><a href="#Bug定位" class="headerlink" title="Bug定位"></a>Bug定位</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_new_student</span>(<span class="params">self, name, student_id</span>):</span><br><span class="line">    new_student = self.template <span class="comment"># 这一行有问题！</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">id</span>(new_student))</span><br><span class="line">    new_student[<span class="string">&#x27;name&#x27;</span>] = name</span><br><span class="line">    new_student[<span class="string">&#x27;id&#x27;</span>] = student_id</span><br><span class="line">    <span class="keyword">return</span> new_student</span><br></pre></td></tr></table></figure><p>　　发现每一次的<code>new_student</code>的id是一样的<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2110590375320</span></span><br><span class="line"><span class="number">2110590375320</span></span><br><span class="line"><span class="number">2110590375320</span></span><br><span class="line"><span class="number">2110590375320</span></span><br></pre></td></tr></table></figure></p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>修改为</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_new_student</span>(<span class="params">self, name, student_id</span>):</span><br><span class="line">    new_student = copy.deepcopy(self.template) <span class="comment"># 修改后（法一）</span></span><br><span class="line">    <span class="comment"># new_student = copy.copy(self.template) # 修改后（法二）</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">id</span>(new_student))</span><br><span class="line">    new_student[<span class="string">&#x27;name&#x27;</span>] = name</span><br><span class="line">    new_student[<span class="string">&#x27;id&#x27;</span>] = student_id</span><br><span class="line">    <span class="keyword">return</span> new_student</span><br></pre></td></tr></table></figure><p>　　此时输出的id不同了：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2392740865832</span><br><span class="line">2392740866072</span><br><span class="line">2392740866152</span><br><span class="line">2392740865752</span><br></pre></td></tr></table></figure></p><p>　　新的输出文件为</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;LiuBo&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;1&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;BoCai&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">2.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;2&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;CaiGou&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">3.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;3&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;GouDong&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;sex&quot;</span><span class="punctuation">:</span> <span class="string">&quot;female&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;grade&quot;</span><span class="punctuation">:</span> <span class="string">&quot;6&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;age&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">4.0</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>　　原代码中，<code>new_student = self.template</code>每一次都将*<code>new_student</code>指向<code>self.template</code>，<code>students[str(row)] = new_student</code>每一次都将<code>students[str(row)]</code>指向<code>new_student</code>。所以每次<code>new_student</code>修改后，<code>students[str(row)]</code>的全部值都会更改为最新版。</p><p>　　若要避免该问题，就涉及到浅拷贝和深拷贝的问题。</p><ul><li><strong>赋值</strong>：仅仅是个别名，引用，指向原有地址，id的地址和原有地址相同。（就像快捷方式。）</li><li><strong>浅拷贝</strong>：第一层拷贝了，里面子文件全是引用。（先建一个新对象，对象地址是新的，里面放原数据的地址，就像一个文件夹里放的全是快捷方式。）</li><li><strong>深拷贝</strong>：新对象的内存地址也会重新分配，跟原来的内存地址不一样。完全弄一个克隆版，克隆体和本体没有关系了，本体改了克隆体不变。（先建一个新对象，对象地址是新的，里面放的全是克隆体，其地址也是新的。就像一个文件夹里放的全是文件，而不是快捷方式。）</li></ul><p>　　再要分清Python里，“=”号、<code>copy.copy</code>和<code>copy.deepcopy</code>三者的区别。</p><ul><li>“=”号：对应赋值<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = a</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原来的a&#x27;</span>, a, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>, b, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(b))</span><br><span class="line">b = <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;此时的a&#x27;</span>, a, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(a))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;修改后的b&#x27;</span>, b, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(b))</span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># 原来的a 1 地址 140720364485696</span></span><br><span class="line"><span class="comment"># b 1 地址 140720364485696</span></span><br><span class="line"><span class="comment"># 此时的a 1 地址 140720364485696</span></span><br><span class="line"><span class="comment"># 修改后的b 2 地址 140720364485728</span></span><br></pre></td></tr></table></figure>修改后b此时地址变了，因为赋给一个全新完整的变量会重新生成新地址。<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">c = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原来的c&#x27;</span>, c, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(c))</span><br><span class="line">d = c</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;d&#x27;</span>, d, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(d))</span><br><span class="line">d[<span class="number">0</span>] = <span class="number">3</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;此时的c&#x27;</span>, c, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(c))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;修改后的d&#x27;</span>, d, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(d))</span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># 原来的c [1, 2] 地址 2758022890888</span></span><br><span class="line"><span class="comment"># d [1, 2] 地址 2758022890888</span></span><br><span class="line"><span class="comment"># 此时的c [3, 2] 地址 2758022890888</span></span><br><span class="line"><span class="comment"># 修改后的d [3, 2] 地址 2758022890888</span></span><br></pre></td></tr></table></figure>　　修改后d地址没变，因为只修改了d内的部分值。<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">e = &#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;ZhangSan&quot;</span>,</span><br><span class="line">    <span class="string">&quot;id&quot;</span>: <span class="string">&quot;0&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原来的e&#x27;</span>, e, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(e))</span><br><span class="line">f = e</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;f&#x27;</span>, f, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(f))</span><br><span class="line">f[<span class="string">&#x27;id&#x27;</span>] = <span class="string">&#x27;1&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;此时的e&#x27;</span>, e, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(e))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;修改后的f&#x27;</span>, f, <span class="string">&#x27;地址&#x27;</span>, <span class="built_in">id</span>(f))</span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># 原来的e &#123;&#x27;name&#x27;: &#x27;ZhangSan&#x27;, &#x27;id&#x27;: &#x27;0&#x27;&#125; 地址 2001978290072</span></span><br><span class="line"><span class="comment"># f &#123;&#x27;name&#x27;: &#x27;ZhangSan&#x27;, &#x27;id&#x27;: &#x27;0&#x27;&#125; 地址 2001978290072</span></span><br><span class="line"><span class="comment"># 此时的e &#123;&#x27;name&#x27;: &#x27;ZhangSan&#x27;, &#x27;id&#x27;: &#x27;1&#x27;&#125; 地址 2001978290072</span></span><br><span class="line"><span class="comment"># 修改后的f &#123;&#x27;name&#x27;: &#x27;ZhangSan&#x27;, &#x27;id&#x27;: &#x27;1&#x27;&#125; 地址 2001978290072</span></span><br></pre></td></tr></table></figure>　　修改后f地址没变，因为只修改了f内的部分值。</li><li><code>copy.copy</code>：对应浅拷贝</li><li><code>copy.deepcopy</code>：对应深拷贝<br>　　官方文档：<a href="https://docs.python.org/3/library/copy.html">copy函数</a><blockquote><p>The difference between shallow and deep copying is only relevant for compound objects (objects that contain other objects, like lists or class instances):<br>A shallow copy constructs a new compound object and then (to the extent possible) inserts <strong>references</strong> into it to the objects found in the original.<br>A deep copy constructs a new compound object and then, recursively, inserts <strong>copies</strong> into it of the objects found in the original.</p></blockquote></li></ul><p>　　注意加粗字体，区别在于一个是引用，一个是复制体本身。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;一个bug引起的……thinking&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="编程语言" scheme="https://hubojing.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Python" scheme="https://hubojing.github.io/tags/Python/"/>
    
      <category term="浅拷贝" scheme="https://hubojing.github.io/tags/%E6%B5%85%E6%8B%B7%E8%B4%9D/"/>
    
      <category term="深拷贝" scheme="https://hubojing.github.io/tags/%E6%B7%B1%E6%8B%B7%E8%B4%9D/"/>
    
  </entry>
  
  <entry>
    <title>Python数据处理代码笔记</title>
    <link href="https://hubojing.github.io/2022/10/06/Python%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/"/>
    <id>https://hubojing.github.io/2022/10/06/Python数据处理代码笔记/</id>
    <published>2022-10-06T06:59:36.000Z</published>
    <updated>2022-10-06T13:35:26.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>自用，一些工具代码。</strong><br><br><br> </div><span id="more"></span><h1 id="pd读取excel"><a href="#pd读取excel" class="headerlink" title="pd读取excel"></a>pd读取excel</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = pd.DataFrame(pd.read_excel(excel_path))</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> data.itertuples():</span><br><span class="line">    <span class="built_in">id</span> = <span class="built_in">getattr</span>(row, <span class="string">&#x27;uid&#x27;</span>)</span><br><span class="line">    text = <span class="built_in">getattr</span>(row, <span class="string">&#x27;文本&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> pd.isna(text):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    info = re.findall(<span class="string">r&#x27;&quot;重要&quot;：&quot;([^&quot;]+)&quot;,&#x27;</span>, <span class="built_in">str</span>(text))</span><br></pre></td></tr></table></figure><h1 id="pd输出excel"><a href="#pd输出excel" class="headerlink" title="pd输出excel"></a>pd输出excel</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">output_excel</span>(<span class="params">outputdata, result_path</span>):</span><br><span class="line">    title = [<span class="string">&#x27;姓名&#x27;</span>, <span class="string">&#x27;性别&#x27;</span>, <span class="string">&#x27;年龄&#x27;</span>]</span><br><span class="line">    writer = pd.ExcelWriter(result_path)</span><br><span class="line">    </span><br><span class="line">    df = pd.DataFrame(outputdata, columns=title)</span><br><span class="line">    df.to_excel(writer, sheet_name=<span class="string">&#x27;Sheet1&#x27;</span>, index=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    writer.save()</span><br></pre></td></tr></table></figure><h1 id="读取json"><a href="#读取json" class="headerlink" title="读取json"></a>读取json</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">files = os.listdir(data_dir)</span><br><span class="line"><span class="keyword">for</span> jsonfile <span class="keyword">in</span> files:</span><br><span class="line">    json_data = json.load(<span class="built_in">open</span>(data_dir + jsonfile, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br></pre></td></tr></table></figure><h1 id="输出json"><a href="#输出json" class="headerlink" title="输出json"></a>输出json</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">output_json</span>(<span class="params">outputdata, result_path</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(result_path, <span class="string">&#x27;w+&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        json.dump(outputdata, file, indent=<span class="number">4</span>, ensure_ascii=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h1 id="读写excel"><a href="#读写excel" class="headerlink" title="读写excel"></a>读写excel</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xlrd</span><br><span class="line">file = xlrd.open_workbook(<span class="string">&#x27;test.xlsx&#x27;</span>)</span><br><span class="line">sheet = flie.sheets()[<span class="number">0</span>]</span><br><span class="line">rows = sheet.nrows</span><br><span class="line">cols = sheet.ncols</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">    val = sheet.cell_value(i, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h1 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">User = <span class="built_in">dict</span>()</span><br><span class="line">User[<span class="built_in">id</span>] = []</span><br><span class="line">User[<span class="built_in">id</span>].append([val1, val2])</span><br><span class="line">userdic = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> data.readlines():</span><br><span class="line">    linestr = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    tmp1 = <span class="built_in">int</span>(linestr[<span class="number">0</span>])</span><br><span class="line">    tmp2 = <span class="built_in">int</span>(linestr[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">if</span> tmp1 <span class="keyword">not</span> <span class="keyword">in</span> userdic:</span><br><span class="line">        userdic[tmp1] = <span class="built_in">set</span>()</span><br><span class="line">    userdic[tmp1].add(tmp2)</span><br></pre></td></tr></table></figure><h1 id="读写word"><a href="#读写word" class="headerlink" title="读写word"></a>读写word</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> win32com <span class="keyword">import</span> client <span class="keyword">as</span> wc</span><br><span class="line"></span><br><span class="line">word = wc.Dispatch(<span class="string">&quot;Word.Application&quot;</span>)</span><br><span class="line"></span><br><span class="line">bookList = os.listdir(<span class="string">r&#x27;./result_new_2/&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> bookList:</span><br><span class="line">    <span class="comment">#print(file)</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        doc = word.Documents.Open(<span class="string">&quot;C:\\docdir\\&quot;</span> + file)</span><br><span class="line">        doc.SaveAs(<span class="string">&quot;&#123;&#125;x&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;C:\\docxdir\\&quot;</span> + file), <span class="number">12</span>)<span class="comment">#另存为后缀为&quot;.docx&quot;的文件，其中参数12指docx文件</span></span><br><span class="line">        doc.Close()</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(file)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">word.Quit()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;完成！&quot;</span>)</span><br></pre></td></tr></table></figure><h1 id="re"><a href="#re" class="headerlink" title="re"></a>re</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">text = re.findall(<span class="string">r&#x27;&quot;type&quot;:&quot;([^&quot;]+)&quot;,&#x27;</span>, <span class="built_in">str</span>(longtext))</span><br></pre></td></tr></table></figure><h1 id="以前的笔记"><a href="#以前的笔记" class="headerlink" title="以前的笔记"></a>以前的笔记</h1><p><a href="https://hubojing.github.io/2021/07/11/Pandas%E6%9D%82%E8%AE%B0/">Pandas自用笔记</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;自用，一些工具代码。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Waline评论服务端转移至Deta</title>
    <link href="https://hubojing.github.io/2022/09/12/Waline%E8%AF%84%E8%AE%BA%E6%9C%8D%E5%8A%A1%E7%AB%AF%E8%BD%AC%E7%A7%BB%E8%87%B3Deta/"/>
    <id>https://hubojing.github.io/2022/09/12/Waline评论服务端转移至Deta/</id>
    <published>2022-09-12T03:24:26.000Z</published>
    <updated>2022-09-12T06:58:40.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>和评论系统battle的第N年</strong><br>　　<strong>折腾不息</strong><br><br><br> </div><span id="more"></span><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>前阵子评论系统又挂了，原因是*.vercel.app域名被污染。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>法一：服务端换个域名<br>法二：换个服务端部署</p><p>我选法二。</p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><p>DETA官网：<a href="https://www.deta.sh/">https://www.deta.sh/</a></p><blockquote><p>Deta is free for ever.</p></blockquote><p>这句话很不错有木有~</p><ol><li>注册</li><li>根据注册后的引导新建一个默认的project</li><li>点击 <a href="https://web.deta.sh/deploy?path=https://github.com/walinejs/deta-starter">https://web.deta.sh/deploy?path=https://github.com/walinejs/deta-starter</a> 将Waline快速部署到deta平台</li><li>将部署url写入前端脚本的 serverURL 配置中，此时更新就可看到评论</li><li>将项目放到本地管理<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Mac or Linux</span></span><br><span class="line">curl -fsSL https://get.deta.dev/cli.sh | sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Windows for powershell</span></span><br><span class="line">iwr https://get.deta.dev/cli.ps1 -useb | iex</span><br></pre></td></tr></table></figure></li><li>cmd<code>deta login</code>登录</li><li>复制并执行页面中的<code>deta clone</code>命令，将项目下载到本地</li><li><code>deta deploy</code>实现部署</li><li>本地项目新增<code>.env</code>文件，将需要修改的环境变量使用<code>VAR_NAME=VALUE</code>的形式一行一个写在文件中</li><li>使用<code>deta update -e .env</code>进行环境变量更新</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://waline.js.org/guide/server/deta.html">Waline手册-Deta部署</a></li><li><a href="https://docs.deta.sh/docs/cli/install/">Deta CLI</a></li><li><a href="https://docs.deta.sh/docs/micros/env_vars/#setting-environment-variables">Deta环境变量配置</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;和评论系统battle的第N年&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;折腾不息&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="博客" scheme="https://hubojing.github.io/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="博客" scheme="https://hubojing.github.io/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="Waline" scheme="https://hubojing.github.io/tags/Waline/"/>
    
      <category term="Deta" scheme="https://hubojing.github.io/tags/Deta/"/>
    
  </entry>
  
  <entry>
    <title>关系抽取（RE）论文泛读</title>
    <link href="https://hubojing.github.io/2022/08/16/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96%EF%BC%88RE%EF%BC%89%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/"/>
    <id>https://hubojing.github.io/2022/08/16/关系抽取（RE）论文泛读/</id>
    <published>2022-08-16T11:37:35.000Z</published>
    <updated>2022-08-16T12:22:38.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/沉醉于知识的芬芳.png" class="lazyload" data-srcset="/images/沉醉于知识的芬芳.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>论文泛读不定期更新。</strong><br><br><br> </div><span id="more"></span><h1 id="Document-Level-Relation-Extraction-with-Adaptive-Focal-Loss-and-Knowledge-Distillation"><a href="#Document-Level-Relation-Extraction-with-Adaptive-Focal-Loss-and-Knowledge-Distillation" class="headerlink" title="Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation"></a>Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation</h1><p>具有自适应焦点损失和知识蒸馏的文档级关系抽取<br>阅读时间：2022-08-15</p><h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2022<br>阿里达摩院<br>Qingyu Tan, Ruidan He, Lidong Bing, Hwee Tou Ng<br><a href="https://arxiv.org/pdf/2203.10900">PDF</a><br><a href="https://github.com/tonytan48/KD-DocRE">CODE</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>文档级关系抽取要同时从多个句子中提取关系。本文提出DocRE算法，一个用于文档级别的关系抽取半监督算法，它有三个新组件。第一，用轴向注意力模块学习实体对之间的依赖关系。第二，提出了一个自适应的焦点损失来解决DocRE中类的不平衡问题。最后，利用知识蒸馏来克服人工标注数据与远程监督数据之间的差异。<br>现有问题：现存的方法关注实体对的句法特征，而忽略了实体对之间的交互作用；目前还没有工作可以直接的解决类的不平衡问题。现存的工作仅仅关注阈值学习来平衡正例和负例，但正例内部的类不平衡问题并没有得到解决；关于将远程监督数据应用于DocRE任务的研究很少。<br>贡献点：轴向注意力（提升two-hop关系的推理能力）、自适应焦点损失（解决标签分配不平衡的问题，长尾类在总的损失中占比较多）、知识蒸馏（克服标注数据和远程监督数据之间的差异）<br><img src="/images/KD-DocRE.png" class="lazyload" data-srcset="/images/KD-DocRE.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="KD-DocRE"></p><h1 id="Packed-Levitated-Marker-for-Entity-and-Relation-Extraction"><a href="#Packed-Levitated-Marker-for-Entity-and-Relation-Extraction" class="headerlink" title="Packed Levitated Marker for Entity and Relation Extraction"></a>Packed Levitated Marker for Entity and Relation Extraction</h1><p>打包悬浮标记用于实体和关系抽取<br>阅读时间：2022-08-15</p><h2 id="论文概述"><a href="#论文概述" class="headerlink" title="论文概述"></a>论文概述</h2><p>ACL 2022<br>Deming Ye, Yankai Lin, Peng Li, Maosong Sun<br>清华大学与腾讯微信模式识别中心合作<br><a href="https://aclanthology.org/2022.acl-long.337/">PDF</a><br><a href="https://github.com/thunlp/PL-Marker">CODE</a></p><h2 id="笔记-1"><a href="#笔记-1" class="headerlink" title="笔记"></a>笔记</h2><p>最近的命名实体识别和关系抽取工作专注于研究如何从预训练模型中获得更好的span表示。然而，许多工作忽略了span之间的相互关系。本文提出了一种基于悬浮标记的span表示方法，在编码过程中通过特定策略打包标记来考虑span之间的相互关系。对于命名实体识别任务，提出了一种面向邻居span的打包策略，以更好地建模实体边界信息。对于关系抽取任务，设计了一种面向头实体的打包策略，将每个头实体以及可能的尾实体打包，以共同建模同头实体的span对。<br><img src="/images/PL-Marker.png" class="lazyload" data-srcset="/images/PL-Marker.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="PL-Marker"></p><h1 id="Consistent-Representation-Learning-for-Continual-Relation-Extraction"><a href="#Consistent-Representation-Learning-for-Continual-Relation-Extraction" class="headerlink" title="Consistent Representation Learning for Continual Relation Extraction"></a>Consistent Representation Learning for Continual Relation Extraction</h1><p>一致表示学习用于连续关系抽取<br>阅读时间：2022-08-12</p><h2 id="论文概况-1"><a href="#论文概况-1" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2022<br>Kang Zhao, Hua Xu, Jiangong Yang, Kai Gao<br><a href="https://arxiv.org/pdf/2203.02721">PDF</a><br><a href="https://github.com/thuiar/CRL">CODE</a></p><h2 id="笔记-2"><a href="#笔记-2" class="headerlink" title="笔记"></a>笔记</h2><p>通过对比学习和回放记忆时的知识蒸馏，提出一种新颖的一致性表示学习方法。使用基于记忆库的监督对比学习来训练每一个新的任务，以使模型高效学习特征表示。为了防止对老任务的遗忘，构造了记忆样本的连续回放，同时让模型保留在知识蒸馏中历史任务之间的关系。<br><img src="/images/CRL.png" class="lazyload" data-srcset="/images/CRL.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="CRL"></p><h1 id="Pre-training-to-Match-for-Unified-Low-shot-Relation-Extraction"><a href="#Pre-training-to-Match-for-Unified-Low-shot-Relation-Extraction" class="headerlink" title="Pre-training to Match for Unified Low-shot Relation Extraction"></a>Pre-training to Match for Unified Low-shot Relation Extraction</h1><p>预训练用于匹配统一少样本关系抽取<br>阅读时间：2022-08-12</p><h2 id="论文概况-2"><a href="#论文概况-2" class="headerlink" title="论文概况"></a>论文概况</h2><p>ACL 2022<br>Fangchao Liu, Hongyu Lin, Xianpei Han, Boxi Cao, Le Sun<br><a href="https://arxiv.org/pdf/2203.12274">PDF</a><br><a href="https://github.com/fc-liu/MCMN">CODE</a></p><h2 id="笔记-3"><a href="#笔记-3" class="headerlink" title="笔记"></a>笔记</h2><p>低样本关系抽取旨在少样本甚至零样本场景下的关系抽取。由于低样本关系抽取所包含任务形式多样，传统方法难以统一处理。本文针对这一问题，提出了一种统一的低样本匹配网络：（1）基于语义提示（prompt）范式，构造了从关系描述到句子实例的匹配网络模型；（2）针对匹配网络模型学习，设计了三元组-复述的预训练方法，以增强模型对关系描述与实例之间语义匹配的泛化性。在零样本、小样本以及带负例的小样本关系抽取评测基准上的实验结果表明，该方法能有效提升低样本场景下关系抽取的性能，并且具备了较好的任务自适应能力。<br><img src="/images/MCMN.png" class="lazyload" data-srcset="/images/MCMN.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="MCMN"></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/沉醉于知识的芬芳.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="关系抽取" scheme="https://hubojing.github.io/tags/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/"/>
    
      <category term="RE" scheme="https://hubojing.github.io/tags/RE/"/>
    
  </entry>
  
  <entry>
    <title>兴趣点推荐（POI Recommendation）论文泛读</title>
    <link href="https://hubojing.github.io/2022/08/14/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90%EF%BC%88POI%20Recommendation%EF%BC%89%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/"/>
    <id>https://hubojing.github.io/2022/08/14/兴趣点推荐（POI Recommendation）论文泛读/</id>
    <published>2022-08-14T14:34:04.000Z</published>
    <updated>2022-08-14T16:16:26.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/沉醉于知识的芬芳.png" class="lazyload" data-srcset="/images/沉醉于知识的芬芳.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>论文泛读不定期更新。</strong><br><br><br> </div><span id="more"></span><h1 id="Hierarchical-Multi-Task-Graph-Recurrent-Network-for-Next-POI-Recommendation"><a href="#Hierarchical-Multi-Task-Graph-Recurrent-Network-for-Next-POI-Recommendation" class="headerlink" title="Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation"></a>Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation</h1><p>分层多任务图循环网络用于下一个兴趣点推荐<br>阅读时间：2022-08-11</p><h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>SIGIR2022<br>Nicholas Lim, Bryan Hooi, See-Kiong Ng,Yong Liang Goh, Renrong Weng, Rui Tan<br><a href="https://bhooi.github.io/papers/hmt_sigir22.pdf">PDF</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>解决问题：数据稀疏（用户-兴趣点矩阵稀疏）<br>提出HMT-GRN算法，该方法通过在多任务设置中学习不同的低稀疏用户区域矩阵来缓解数据稀疏问题，GRN模块同时对顺序依赖关系和全局时空POI-POI关系进行建模，然后对不同的区域和兴趣点分布采用分层束搜索（HBS），随着空间粒度增加来分层减少搜索空间并且预测下一个兴趣点。本文HBS通过减少搜索空间来提高效率，与穷举法相比速度提升5~7倍。本文还提出了一种新颖的选择层来预测下一个兴趣点用户是否曾经访问过，在个性化和探索之间取得平衡。</p><p><img src="/images/HMT-GRN.png" class="lazyload" data-srcset="/images/HMT-GRN.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="HMT-GRN"><br>个人备注：把bean search运用在POI推荐中；对于已访问过的POI设置了一个选择概率。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/沉醉于知识的芬芳.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="POI" scheme="https://hubojing.github.io/tags/POI/"/>
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
  <entry>
    <title>实体链接（EL）论文泛读</title>
    <link href="https://hubojing.github.io/2022/08/14/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5%EF%BC%88EL%EF%BC%89%E8%AE%BA%E6%96%87%E6%B3%9B%E8%AF%BB/"/>
    <id>https://hubojing.github.io/2022/08/14/实体链接（EL）论文泛读/</id>
    <published>2022-08-14T08:26:09.000Z</published>
    <updated>2022-08-14T09:12:56.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/沉醉于知识的芬芳.png" class="lazyload" data-srcset="/images/沉醉于知识的芬芳.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>论文泛读不定期更新。</strong><br><br><br> </div><span id="more"></span><h1 id="Entity-linking-meets-deep-learning-Techniques-and-solutions"><a href="#Entity-linking-meets-deep-learning-Techniques-and-solutions" class="headerlink" title="Entity linking meets deep learning: Techniques and solutions"></a>Entity linking meets deep learning: Techniques and solutions</h1><p>实体链接遇到深度学习：技术和解决方法<br>阅读时间：2022-08-11</p><h2 id="论文概况"><a href="#论文概况" class="headerlink" title="论文概况"></a>论文概况</h2><p>2021年 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING<br>CCF-A<br>Wei Shen, Yuhan Li, Yinan Liu, Jiawei Han,Fellow, IEEE, Jianyong Wang,Fellow, IEEE, Xiaojie Yuan<br><a href="https://arxiv.org/pdf/2109.12520">PDF</a></p><h2 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h2><p>从三个方面展开：嵌入（Embedding）、特征（Feature）、算法（Algorithm）<br>Embedding包括字（word）嵌入、Mention嵌入、实体（entity）嵌入、对齐（aligenment）嵌入。<br>特征包括先验流行度、表面形式相似度、类型相似度、上下文相似度、主题连贯性。<br>算法包括MLP、基于图的算法、强化学习。<br>给出了十种广泛使用的实体链接数据集。<br>未来方向：多源异质文本数据、NER和EL联合、更高级的语言模型、EL模型鲁棒性</p><h1 id="Multilingual-Autoregressive-Entity-Linking"><a href="#Multilingual-Autoregressive-Entity-Linking" class="headerlink" title="Multilingual Autoregressive Entity Linking"></a>Multilingual Autoregressive Entity Linking</h1><p>多语言自回归实体链接<br>阅读时间：2022-08-11</p><h2 id="论文概况-1"><a href="#论文概况-1" class="headerlink" title="论文概况"></a>论文概况</h2><p>2022年3月 Transactions of the Association for Computational Linguistics SCI Q1<br>Nicola De Cao, Ledell Wu, Kashyap Popat, Mikel Artetxe,Naman Goyal, Mikhail Plekhanov, Luke Zettlemoyer,Nicola Cancedda, Sebastian Riedel1,6, Fabio Petroni<br>Facebook AI<br><a href="https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00460/2004070/tacl_a_00460.pdf">PDF</a><br><a href="https://github.com/facebookresearch/GENRE">CODE</a></p><h2 id="笔记-1"><a href="#笔记-1" class="headerlink" title="笔记"></a>笔记</h2><p>提出mGENRE系统，它是一个用于多语言实体链接问题的序列到序列的系统，用于解析特定语言mention到多语言知识库。对于特定语言的mention，mGENRE以自回归的方式从左到右逐个（left-to-right, token-by-token）标记预测目标实体的名称。自回归公式有效地交叉编码关于字符串和实体名称，用来捕获比标准点积更多的交互。它还可以在大知识库中进行快速搜索，即使对于没出现在mention表中和不用大规模向量索引的mention也是如此。虽然先前的MEL工作对每个实体使用单一表示，但我们匹配尽可能多的多语言的实体名称，这允许利用源输入和目标名称之间的语言连接。此外，在完全没有训练数据的语言的零样本设置中，mGENRE将目标语言视为在预测时被边缘化的潜在变量。这使平均准确度提高了50%以上。<br><img src="/images/mGENRE.png" class="lazyload" data-srcset="/images/mGENRE.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="mGENRE"></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/沉醉于知识的芬芳.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="实体链接" scheme="https://hubojing.github.io/tags/%E5%AE%9E%E4%BD%93%E9%93%BE%E6%8E%A5/"/>
    
  </entry>
  
  <entry>
    <title>BERT</title>
    <link href="https://hubojing.github.io/2022/08/09/BERT/"/>
    <id>https://hubojing.github.io/2022/08/09/BERT/</id>
    <published>2022-08-09T12:59:07.000Z</published>
    <updated>2022-08-09T15:22:40.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/BERT架构图.png" class="lazyload" data-srcset="/images/BERT架构图.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>笔记</strong><br><br><br> </div><span id="more"></span><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>2019年 谷歌 Jacob Devlin<br>NAACL-HLT会议-NLP顶会<br><a href="https://arxiv.org/abs/1810.04805">PDF</a><br><a href="GitHub - google-research/bert: TensorFlow code and pre-trained models for BERT">CODE</a></p><h1 id="摘要重点"><a href="#摘要重点" class="headerlink" title="摘要重点"></a>摘要重点</h1><p>　　BERT(Bidirectional Encoder Rpresentation from Transformers)<br>　　BERT 旨在通过联合调节所有层的左右上下文，从未标记的文本中预训练深度双向表示。因此，预训练的 BERT 模型可以通过一个额外的输出层进行微调，从而为各种任务（例如问答和语言推理）创建最先进的模型，而无需大量特定任务架构修改。</p><h1 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h1><p>　　在下游任务中有两种方法使用预训练语言表示模型，一种是基于特征（feature-based）方法，一种是微调（fine-tuning）。本文认为现有技术限制了预训练表示的能力，尤其是微调方法。主要限制是标准语言模型是单向的，这限制了预训练可以使用的架构。例如，在 OpenAI GPT 中，作者使用从左到右的架构，其中每个标记只能关注Transformer的自注意力层中的先前标记。 这样的限制对于句子级任务来说是次优的，并且在将基于微调的方法应用于令牌级任务（例如问答）时可能非常有害，在这些任务中，从两个方向整合上下文至关重要。</p><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ul><li>我们解释了语言表示中双向预训练的重要性。不像之前的模型在预训练中使用双向语言模型，BERT使用掩码语言模型（masked language model）来预训练深度双向表示。也和以前使用从左到右和从右到左LM独立训练再浅层连结的方法不同。</li><li>预训练表示减少了许多特定任务的繁重工程架构。BERT是第一个基于表示模型微调并在一系列句子级别和token级别任务中实现SOTA性能的。</li><li>BERT在11个NLP任务中实现SOTA性能，代码开源。</li></ul><h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><p>基于特征的无监督方法（如ELMo）、微调无监督方法（如OpenAI GPT）</p><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p>　　两阶段：预训练+微调。<br>　　预训练阶段，模型在不同的预训练任务中使用未标注数据训练。<br>　　微调阶段，首先使用预训练参数初始化，所有的参数使用下游任务中的标注数据进行微调。即使每一个下游任务使用相同的预训练参数初始化，它们还是有单独的微调模型。如图为一个问答示例。<br><img src="/images/BERT架构图.png" class="lazyload" data-srcset="/images/BERT架构图.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="BERT"><br>　　记层数（Transformer块）为L，隐藏层为H，自注意力头数量为A。实验有两种模型规模：一种是$BERT_{BASE}$（L=12，H=768，A=12，总参数为110M）；另一种是$BERT_{LARGE}$（L=24，H=1024，A=16，总参数为340M）。<br>　　为压缩目的，$BERT_{BASE}$选择了和Open AI一样的模型规模。但是BERT Transformer使用了双向自注意力，GPT Transformer使用的是受限的自注意力，它的每个token只能获取它左边的上下文。<br>　　每一个token都以[CLS]开头。句子对会一起打包到一个序列中，分割句子使用两种方式。一是使用token[SEP]，二是在每个token中加入一个学习过的embedding表示它属于句子A还是句子B。如图1所示，输入embedding记为E，最后隐藏向量的[CLS]记为C，第i个输入token的最后的隐藏向量记为$T_i$。<br>对于给定的标记，其输入表示是通过对相应的标记、段和位置嵌入求和来构建的。这种结构的可视化可以在图2中看到。<br><img src="/images/BERT输入表示.png" class="lazyload" data-srcset="/images/BERT输入表示.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="BERT输入表示"></p><h2 id="预训练BERT"><a href="#预训练BERT" class="headerlink" title="预训练BERT"></a>预训练BERT</h2><h3 id="任务1：Masked-LM"><a href="#任务1：Masked-LM" class="headerlink" title="任务1：Masked LM"></a>任务1：Masked LM</h3><p>　　随机掩盖掉部分输入的tokens，然后预测这些被掩盖的tokens。这个过程记为“masked LM”(MLM)，类似于文学里的完形填空。与掩码标记对应的最终隐藏向量被送到词汇表上的softmax输出，就像在标准 LM 中一样。本文选择15%的tokens进行掩盖。由于[MASK] token在微调阶段不存在，所以预训练阶段和微调阶段不匹配。为了减轻影响，当选中第i个token时，按三条规则进行掩码：<br>（1） 80%时间使用[MASK] token<br>（2）10%时间选择随机token<br>（3）10%时间token不变<br>然后，使用交叉熵损失和$T_i$预测原始token。</p><h3 id="任务2：下一个句子预测（NSP）"><a href="#任务2：下一个句子预测（NSP）" class="headerlink" title="任务2：下一个句子预测（NSP）"></a>任务2：下一个句子预测（NSP）</h3><p>　　问答QA和自然语言推理（NLI）都是基于对两个句子关系的理解做的，而语言模型不能直接捕捉它。为了训练一个能理解句子关系的模型，我们预先训练一个二值化的下一个句子预测任务，该任务可以从任何单语语料库中轻松生成。在之前的工作中，只有句子嵌入被转移到下游任务， BERT 转移所有参数来初始化最终任务模型参数。</p><h2 id="微调BERT"><a href="#微调BERT" class="headerlink" title="微调BERT"></a>微调BERT</h2><p>　　微调很简单，因为Transformer中的自注意力机制允许 BERT 通过交换适当的输入和输出来对许多下游任务进行建模——无论它们涉及单个文本还是文本对。对于涉及文本对的应用程序，一种常见的模式是在应用双向交叉注意力之前独立编码文本对。BERT使用自我注意力机制来统一这两个阶段，因为使用自我注意对连接的文本对进行编码有效地包括了两个句子之间的双向交叉注意力。<br>　　对于每个任务，我们只需将任务特定的输入和输出插入BERT，端到端微调所有参数。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/BERT架构图.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;笔记&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="BERT" scheme="https://hubojing.github.io/tags/BERT/"/>
    
      <category term="NLP" scheme="https://hubojing.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>samba映射</title>
    <link href="https://hubojing.github.io/2022/07/31/samba%E6%98%A0%E5%B0%84/"/>
    <id>https://hubojing.github.io/2022/07/31/samba映射/</id>
    <published>2022-07-31T10:02:47.000Z</published>
    <updated>2022-07-31T10:43:46.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br><br>　　<strong>更方便地使用服务器。</strong><br><br><br> </div><span id="more"></span><h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>　　将服务器资源可通过windows进行管理，很方便。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>　　在ubuntu服务器上<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt-get install samba</span><br><span class="line">samba --version</span><br></pre></td></tr></table></figure></p><h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/samba/smb.conf</span><br></pre></td></tr></table></figure><p>　　在文件末尾追加：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">security = share</span><br><span class="line"></span><br><span class="line">[share]</span><br><span class="line">path = /home/想映射的文件夹/</span><br><span class="line">available = yes</span><br><span class="line">browsealbe = yes</span><br><span class="line">public = yes</span><br><span class="line">guest ok = yes</span><br><span class="line">writable = yes</span><br><span class="line">create mask = 0664</span><br><span class="line">directory mask = 0664</span><br><span class="line">force user =root</span><br><span class="line">valid users = 用户名</span><br></pre></td></tr></table></figure><br>　　配置samba密码：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo touch /etc/samba/smbpasswd</span><br><span class="line">sudo smbpasswd -a 用户名</span><br></pre></td></tr></table></figure><br>　　之后输入密码。<br>　　配置samba服务：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo /etc/init.d/samba restart</span><br><span class="line">sudo service smbd restart</span><br></pre></td></tr></table></figure></p><h1 id="windows映射操作"><a href="#windows映射操作" class="headerlink" title="windows映射操作"></a>windows映射操作</h1><p>　　此电脑-计算机-映射网络驱动器<br>　　填写”\服务器ip\文件夹名称”，勾选使用其他凭据连接，输入用户名和密码。</p><p>　　完成。</p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;更方便地使用服务器。&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="互联网" scheme="https://hubojing.github.io/categories/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
    
      <category term="samba" scheme="https://hubojing.github.io/tags/samba/"/>
    
  </entry>
  
  <entry>
    <title>JingSLink</title>
    <link href="https://hubojing.github.io/2022/07/03/JingSLink/"/>
    <id>https://hubojing.github.io/2022/07/03/JingSLink/</id>
    <published>2022-07-03T13:26:39.000Z</published>
    <updated>2022-07-04T06:39:34.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/假装有图片.jpg" class="lazyload" data-srcset="/images/假装有图片.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br>　　<strong>简单开发一个截图保存并返回链接的小工具JingSLink</strong><br>　　<strong>JingPic迎来重构版JingSLink</strong><br>　　<strong>自用简陋小工具系列</strong><br><br><br> </div><span id="more"></span><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>　　写markdown文章时，贴图这件事儿真的很麻烦。我需要把图片手动保存到对应文件夹，再手动在文章里引入图片链接。所以很多时候我能不配图就不配图。多年前为了方便插入图床链接，用MFC做了个自用小工具<a href="https://github.com/hubojing/JingPic">JingPic</a>。但是它是基于保存了的图片进行的操作，将图片转移到需要的位置。后期也没有维护，操作上依然不够简洁。比如我更喜欢直接截图能自动保存到指定位置，这样就减少一步自己保存的操作。</p><p>　　自己定制还是最爽的，我想要什么功能我自己开发好了。而且这个小工具开发起来也很简单，几十行很快就写完了。</p><p>　　首先，要起个名字，以前的叫JingPic，这个重构版就叫JingSLink（Jinger Screenshot for Link）吧。</p><h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ul><li>能够截图</li><li>截图能保存到指定文件夹中</li><li>截图完成后，自动将图片相对路径复制到剪贴板</li><li>有exe可执行文件</li></ul><h1 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h1><p>　　语言：Python<br>　　用到的库：tkinter, PIL, keyboard, pyperclip</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>　　一开始我是想自己实现截图操作的，后来一想，我平日用QQ截图最多，它功能齐全，那我直接调用它的截图不就好了。<br>　　所以，大体实现思路如下：</p><ul><li>监听键盘，捕捉QQ截图快捷键ctrl+alt+a，并设置一个结束键ctrl。</li><li>使用PIL库的ImageGrab读取截图。</li><li>弹出一个输入框，输入图片名称。<br><img src="/images/JingSLink.png" class="lazyload" data-srcset="/images/JingSLink.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="输入框"></li><li>拼凑出图片完整链接，将图片保存到该地址。</li><li>拼凑出hexo博文中所需的图片插入相对地址，复制到剪贴板。<br>　　当然，为了不每次都打开pycharm编译器，得导出一个exe文件。</li></ul><p>　　打包exe：<br>　　安装pyinstaller。<br>　　在pycharm中，<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pyinstaller -F main.py</span><br><span class="line">pyinstaller -F -w main.py<span class="comment">#（-w是取消dos窗口）</span></span><br><span class="line">pyinstaller -F -w --icon=ico main.py</span><br><span class="line"><span class="comment"># (ico为图标的文件名，与dist目录为同目录)</span></span><br></pre></td></tr></table></figure></p><p>　　最后生成的exe文件在dist文件夹下。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/hubojing/JingSLink">https://github.com/hubojing/JingSLink</a></p><h1 id="后期优化"><a href="#后期优化" class="headerlink" title="后期优化"></a>后期优化</h1><p>　　如有必要：</p><ul><li>一些异常情况的提示</li><li>右下角有最小化托盘，右键有设置和退出菜单</li><li>可扩展性：可以更改文件夹路径</li><li>可扩展性：可以更改图片路径格式（绝对路径/相对路径）</li><li>换pyqt框架</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://tkdocs.com/tutorial/index.html">http://tkdocs.com/tutorial/index.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/假装有图片.jpg&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;简单开发一个截图保存并返回链接的小工具JingSLink&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;JingPic迎来重构版JingSLink&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;自用简陋小工具系列&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="软件开发" scheme="https://hubojing.github.io/categories/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"/>
    
    
      <category term="截图" scheme="https://hubojing.github.io/tags/%E6%88%AA%E5%9B%BE/"/>
    
      <category term="链接" scheme="https://hubojing.github.io/tags/%E9%93%BE%E6%8E%A5/"/>
    
      <category term="markdown" scheme="https://hubojing.github.io/tags/markdown/"/>
    
      <category term="软件开发" scheme="https://hubojing.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>TEMN</title>
    <link href="https://hubojing.github.io/2022/07/03/Paper_TEMN/"/>
    <id>https://hubojing.github.io/2022/07/03/Paper_TEMN/</id>
    <published>2022-07-03T05:03:28.000Z</published>
    <updated>2022-07-04T09:37:12.000Z</updated>
    
    <content type="html"><![CDATA[<div align="left"><br><img src="/images/TEMN架构图.png" class="lazyload" data-srcset="/images/TEMN架构图.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" width="300" height="180" style="float:right;"/><br><br>　　<strong>陆续上架前几个月写的库存</strong><br>　　<strong>主题增强记忆网络个性化兴趣点推荐</strong><br><br><br> </div><span id="more"></span><h1 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h1><p>　　Topic-Enhanced Memory Networks for Personalised Point-of-Interest Recommendation<br>　　主题增强记忆网络个性化兴趣点推荐<br>　　KDD 2019<br><a href="https://arxiv.org/pdf/1905.13127.pdf">PDF</a><br><a href="https://github.com/XiaoZHOUCAM/TEMN">CODE</a></p><p>　　关键词：推荐系统；神经网络；主题建模</p><h1 id="问题提出"><a href="#问题提出" class="headerlink" title="问题提出"></a>问题提出</h1><p>　　现有问题：数据稀疏；现有算法使用一个单一向量刻画用户偏好限制了表达和可解释性。</p><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>　　Topic-Enhanced Memory Network (TEMN)<br>　　TEMN是一个统一的混合模型，利用TLDA和外部记忆网络以及神经注意机制来捕捉用户的全局和细粒度偏好。<br><img src="/images/TEMN架构图.png" class="lazyload" data-srcset="/images/TEMN架构图.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="TEMN"><br>　　三部分组成：记忆网络，TLDA和地理建模部分。<br>　　前两部分相互联系，用于建模从基于领域的记忆网络中学到的非线性交互（通过历史记录）以及从主题模型中学到的全局偏好。</p><p>　　每一部分分别对应不同的损失函数，进行联合训练。</p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>　　微信朋友圈签到数据集（未开源）<br><img src="/images/TEMN数据集.png" class="lazyload" data-srcset="/images/TEMN数据集.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="数据集"></p><h2 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h2><ul><li>MF</li><li>BPR</li><li>LDA</li><li>CML</li><li>LRML</li><li>TEMN(GPR) 保留了记忆模块，将TLDA替换为LDA，去掉了地理模块。</li><li>LORE</li><li>ST-RNN</li><li>TEMN(SPR) 完整TEMN模型使用微信（SPR）数据</li><li>GeoMF</li><li>TLDA</li><li>TEMN(CPR) 完整TEMN模型使用微信（GPR）数据<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><img src="/images/TEMN性能.png" class="lazyload" data-srcset="/images/TEMN性能.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="性能"></li></ul><h1 id="贡献点"><a href="#贡献点" class="headerlink" title="贡献点"></a>贡献点</h1><ul><li>提出一种融合基于领域和全局的用户偏好的端到端深度学习框架。</li><li>在兴趣点推荐中设计了能融合多种上下文信息的灵活架构，并使之能在多种推荐场景应用。</li><li>提出一种结合监督和非监督学习的混合模型，并利用了记忆网络和主题模型。通过相互学习机制，模型还能得出用户在受记忆网络影响的主题上的概率分布。</li><li>在微信数据集上进行模型验证，超过基线模型。</li><li>通过在TEMN中引入神经注意机制和主题模型，POI推荐的可解释性得到了显著提高。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;div align=&quot;left&quot;&gt;&lt;br&gt;&lt;img src=&quot;/images/TEMN架构图.png&quot; width=&quot;300&quot; height=&quot;180&quot; style=&quot;float:right;&quot;/&gt;&lt;br&gt;&lt;br&gt;　　&lt;strong&gt;陆续上架前几个月写的库存&lt;/strong&gt;&lt;br&gt;　　&lt;strong&gt;主题增强记忆网络个性化兴趣点推荐&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/div&gt;
    
    </summary>
    
      <category term="论文" scheme="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="推荐算法" scheme="https://hubojing.github.io/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="兴趣点推荐" scheme="https://hubojing.github.io/tags/%E5%85%B4%E8%B6%A3%E7%82%B9%E6%8E%A8%E8%8D%90/"/>
    
  </entry>
  
</feed>
