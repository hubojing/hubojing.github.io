<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>推荐系统 on 靖待</title>
        <link>https://hubojing.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</link>
        <description>Recent content in 推荐系统 on 靖待</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>靖待</copyright>
        <lastBuildDate>Wed, 15 Jun 2022 10:41:55 +0000</lastBuildDate><atom:link href="https://hubojing.github.io/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>《推荐系统：原理与实践》笔记</title>
        <link>https://hubojing.github.io/bxjrrhxn/</link>
        <pubDate>Wed, 15 Jun 2022 10:41:55 +0000</pubDate>
        
        <guid>https://hubojing.github.io/bxjrrhxn/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\假装有图片.jpg&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;砖头书笔记（自用）&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;前言&#34;&gt;前言
&lt;/h1&gt;&lt;p&gt;　　有几本砖头书在图书馆里我不断续借，网上又没有PDF，现在要毕业了，只有勉强把它看完了&amp;hellip;&amp;hellip;&lt;/p&gt;
&lt;h1 id=&#34;高级论问题和应用&#34;&gt;高级论问题和应用
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;推荐系统中的冷启动问题
太常见不说了。&lt;/li&gt;
&lt;li&gt;抗攻击推荐系统
只要指恶意评论。&lt;/li&gt;
&lt;li&gt;组推荐系统
针对一组用户推荐，而不是单一用户。&lt;/li&gt;
&lt;li&gt;多标准推荐系统
如，用户可以给予情节、音乐、特效等对电影进行评分。在多标准推荐系统中，用户可能根本没有给出整体评分。&lt;/li&gt;
&lt;li&gt;推荐系统中的主动学习
鼓励用户输入评分以完善系统的机制。例如，用户可能会为某些物品评分获得奖励。因此，必须明智地选择由特定用户进行评分的物品。如，某用户已评价大量动作片，那么要求该用户去评价另一部动作电影对预测其他的动作电影评分帮助不大，并且对预测属于无关种类的电影评分的帮助甚至更少。另一方面，要求用户评价不太热门种类的电影将对预测这种类型的电影评分有显著帮助。当然，如果用户被要求评价无关的电影，他不一定能够提供反馈，因为他可能根本没有看过那部电影。**（此处举例我存疑）**因此，在推荐系统的主动学习问题中有许多在其他问题领域（如分类问题）没有遇到的有趣权衡问题。&lt;/li&gt;
&lt;li&gt;推荐系统中的隐私问题&lt;/li&gt;
&lt;li&gt;保护隐私的推荐算法。&lt;/li&gt;
&lt;li&gt;应用领域&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;推荐系统评估&#34;&gt;推荐系统评估
&lt;/h1&gt;&lt;h2 id=&#34;评估设计的总体目标&#34;&gt;评估设计的总体目标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;精确性&lt;/li&gt;
&lt;li&gt;覆盖率&lt;/li&gt;
&lt;li&gt;置信度和信任度&lt;/li&gt;
&lt;li&gt;新颖度&lt;/li&gt;
&lt;li&gt;惊喜度&lt;/li&gt;
&lt;li&gt;多样性&lt;/li&gt;
&lt;li&gt;健壮性和稳定性&lt;/li&gt;
&lt;li&gt;可扩展性&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;离线评估的精确性指标&#34;&gt;离线评估的精确性指标
&lt;/h2&gt;&lt;h3 id=&#34;独立预测评分的精确性&#34;&gt;独立预测评分的精确性
&lt;/h3&gt;&lt;p&gt;　　RMSE, MAE
　　RMSE计算时用的是误差的平方，所以它更加显著地被大的误差值或者异常值所影响。一些被预测失败的评分会显著地破坏RMSE方法。在各种评分的预测健壮性非常重要的应用中，RMSE可能是一个更加合适的方法。另一方面，当评估的异常值有限时，MAE能更好地反映精确性。RMSE主要的问题是它不是平均误差的真实反映，而且它又是会导致有误导的结果。&lt;/p&gt;
&lt;h3 id=&#34;通过相关性评估排名&#34;&gt;通过相关性评估排名
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Spearman等级相关系数&lt;/li&gt;
&lt;li&gt;肯德尔等级相关系数&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;通过效用评估排名&#34;&gt;通过效用评估排名
&lt;/h3&gt;&lt;p&gt;　　基于效用方法的总体目标就是给出用户可能找到推荐系统排名的有用程度的简单量化。这种方法下隐含的一个重要准则就是相对于物品的总量而言，推荐列表是简短的。因此一个具体评分的效用大部分情况下应该基于在推荐列表中相关性高的物品。这种情况下，RMSE指标有一个缺点，因为它对低排名物品和那些高排名物品赋予了同样的权重。&lt;/p&gt;
&lt;p&gt;　　NDCG, ARHR（平均逆命中率）
　　ARHR也被称作是平均倒数排名（MRR）&lt;/p&gt;
&lt;h3 id=&#34;通过roc曲线评估排名&#34;&gt;通过ROC曲线评估排名
&lt;/h3&gt;&lt;h1 id=&#34;抵抗攻击的推荐系统&#34;&gt;抵抗攻击的推荐系统
&lt;/h1&gt;&lt;h2 id=&#34;攻击类型&#34;&gt;攻击类型
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;随机攻击&lt;/li&gt;
&lt;li&gt;均值攻击&lt;/li&gt;
&lt;li&gt;bandwagon攻击&lt;/li&gt;
&lt;li&gt;流行攻击&lt;/li&gt;
&lt;li&gt;爱/憎攻击&lt;/li&gt;
&lt;li&gt;反向bandwagon攻击&lt;/li&gt;
&lt;li&gt;探测攻击&lt;/li&gt;
&lt;li&gt;分段攻击&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;健壮推荐设计策略&#34;&gt;健壮推荐设计策略
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;用CAPTCHA防止自动攻击&lt;/li&gt;
&lt;li&gt;使用社会信任&lt;/li&gt;
&lt;li&gt;设计健壮的推荐算法&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;排名学习&#34;&gt;排名学习
&lt;/h1&gt;&lt;p&gt;　　pointwise
　　pairwise: BPR, Eigen Rank, pLPA, CR
　　listwise: NDCG, MRR&lt;/p&gt;
&lt;h1 id=&#34;多臂赌博机算法&#34;&gt;多臂赌博机算法
&lt;/h1&gt;&lt;h1 id=&#34;组推荐系统&#34;&gt;组推荐系统
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;协同和基于内容的系统&lt;/li&gt;
&lt;li&gt;基于知识的系统&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;多标准推荐系统&#34;&gt;多标准推荐系统
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;基于近邻的方法&lt;/li&gt;
&lt;li&gt;基于集成的方法&lt;/li&gt;
&lt;li&gt;无整体评分的多标准系统&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;推荐系统中的主动学习&#34;&gt;推荐系统中的主动学习
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;基于异质性的模型&lt;/li&gt;
&lt;li&gt;基于性能的模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;推荐系统中的隐私&#34;&gt;推荐系统中的隐私
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;基于冷凝的隐私&lt;/li&gt;
&lt;li&gt;高维数据的挑战&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;应用领域&#34;&gt;应用领域
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;门户内容个性化&lt;/li&gt;
&lt;li&gt;计算广告与推荐系统&lt;/li&gt;
&lt;li&gt;互惠推荐系统
　　基本思想是当考虑多个具有不对称兴趣的利益相关人的推荐的效用时，推荐的任务会发生改变。如在线约会的互惠推荐系统。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;用户意识到交易的成功取决于另一方的许可。另一方是互惠环境中的“物品”。&lt;/li&gt;
&lt;li&gt;用户和物品在系统中可能只出现一次，在一次成功的事物后它们可能永远不会重现。冷启动问题在互惠场景中更加显著。
　　方法：&lt;/li&gt;
&lt;li&gt;利用混合方法
在这些方法中，两个传统的推荐方法被构造出来，分别对应着两个互惠方的喜好。然后，这两个互惠方的预测被组合起来。&lt;/li&gt;
&lt;li&gt;利用链路预测方法
当冷启动问题不是很严重或者可以用来自类似用户和物品的数据来增加评分数据时，可以在系统中采用链路预测方法。&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
        <item>
        <title>Hulu AI Class Quiz</title>
        <link>https://hubojing.github.io/gqeubb8v/</link>
        <pubDate>Thu, 23 Jul 2020 16:00:29 +0000</pubDate>
        
        <guid>https://hubojing.github.io/gqeubb8v/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\Hulu AI Class Quiz1-cover.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;Quiz for traditional recommendation models.&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;quiz1&#34;&gt;Quiz1
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;从基于用户的协同过滤和基于物品的协同过滤的原理思考，下列场景中使用哪种协同过滤算法更加合适？为什么？
(1)新闻资讯推荐
(2)电商网站推荐&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
（1）在新闻推荐的场景中，我们更推荐使用基于用户的协同过滤。
　　主要原因在于：
　　1.新闻推荐通常具有一定的社交属性，通过User-based CF，用户能够通过朋友的浏览行为更新自己的推荐列表。
　　2.新闻推荐的实时性和热点性往往比较重要，使用User-based CF能够快速发现热点，跟踪热点趋势。&lt;/p&gt;
&lt;p&gt;（2）在电商推荐的场景中，我们更推荐使用基于物品的协同过滤，主要原因在于:
　　1.用户在短时间内的兴趣点往往比较稳定，利用Item-CF推荐相似商品比较符合用户的动机，也方便用户进行物品之间的比较。
　　2.电商网站的物品列表相对来讲比较稳定，通过积累大量的历史数据更容易准确地反映物品之间的相似性。
　　3.电商网站中通常用户数量远远大于商品的数量，进行Item-based CF的计算量更小。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;为什么逻辑回归模型在工业界受到的了广泛应用？LR相对于其他的模型，尤其是GBOT模型，突出的优点是什么？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　逻辑回归模型形式比较简单，可解释性强，模型训练的速度快，适合线上学习。相对于GBDT模型，其突出的优点在于可以支持并行化训练以及线上学习。
　　
　　点评:
　　设计这个问题的目的是复习课程中所讲的逻辑回归算法，强化逻辑回归可以用于线上学习的概念。所谓“天下武功，无坚不破，唯快不破”，希望大家能够意识到模型实时性的重要性。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;为什么说提升树模型(GBOT)难以并行化？从Boosting方法的原理上给出简单的解释。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　Boosting方法的本质上是构建一系列的弱学习器去不断逼近目标，每个弱学习器的训练目标是修正之前学习器的错误，需要依赖于前面学习器的结果，是一个串行训练过程。
　　
　　点评：
　　设计这个问题的目的是复习课程中所讲的提升算法原理，并加深大家对于Boosting串行训练的理解与思考。&lt;/p&gt;
&lt;h1 id=&#34;quiz2&#34;&gt;Quiz2
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;在一个机器学习项目中，特征工程是否对模型效果起到决定性作用？
A.是 B.否&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　B数据决定算法的上限，特征工程帮助算法逼近上限。&lt;/p&gt;
&lt;p&gt;2.一个算法工程师面对一个分类问题，打算将花10天时间来清洗数据，花10天时间来做特征工程，最后花1天的时间简单的训练出一个逻辑回归模型，请问他的时间安排是否合理？
A.合理
B.不合理，他应该花10天时间来调优模型&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　A 不必纠结于具体的天数，本题着重强调数据的重要性，在实践中可以发现，同样的数据，交替不同的模型(例如lr或者gbdt) , 在效果上提升和下降有限。相反，数据和特征的不同对预测的结果有巨大的意义。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;深度学习模型具备了自动特征工程的能力，算法工程师只需将数据输入模型，模型会自动寻找最优特征工程，请问是否还有必要做特征工程？请给出理由。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　有必要:
　　1)更好的特征工程可以减弱噪声的影响，提高数据表达能力，提升效果;
　　2) 如果特征工程足够好，可使用更简单的模型，快速训练快速部署，这对实际生产具有重要的意义
　　3)特征工程往往具有很强的业务意义，可以提高模型解释性。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;芒果台最新综艺《乘风破浪的姐姐》吸粉无数，作为一名学过hulu AI Class 的优秀学员，请你思考一个利用人工智能来更好的帮助节目的方案。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　本题为开放问题，强调算法工程师需要有将业务需求抽象成算法问题的能力。下面是示例答案。
　　1) 以不同的姐姐分cluster, 筛选用户特征
　　2)对微博的相关的话题做文本挖掘，舆情分析，以便更好提前制作爆点。
　　3)第一个点是本节目的修音有点过于失真了，可以引入一个基于GAN的声音修正技术提高现场的真实感；第二在广告投放上，可以利用look-alike等技术对潜在的节目目标人群进行筛选，提高广告投放的效率，减少对用户的打扰，提升用户体验。&lt;/p&gt;
&lt;h1 id=&#34;quiz3&#34;&gt;Quiz3
&lt;/h1&gt;&lt;p&gt;1.对于-系列电影，如果有以下几种类型的数据，想要为每个电影生成嵌入(Embdding)表示，你会选用何种算法/模型，为什么？
(1)每个电影的标题、描述文本、风格类型(提示:如何建模纯文本信息？)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　这道题涉及的知识点是如何对文本类信息进行嵌入表示。我们拥有三个数据源:标题、描述文本和风格类型，其中前两个数据源是纯文本，最后一个数据源可以理解为纯文本，也可以解读为类别信息，因为电影的风格类型是共享且有限的。
　　对于建模标题和描述文本这类纯文本信息，最简单的方法是使用Word2Vec或者其它预训练的词向量模型对文本中每个词查到一个嵌入表示（词向量），再通过一些聚合方法聚合得到标题和描述文本的整体嵌入表示。最简单且容易想到的聚合方法就是把句子中所有单词的词向量计算其平均向量作为句子的嵌入表示，更复杂的聚合方法也可考虑如Word mover embedding等等。在得到电影的标题/描述文本的嵌入表示之后，我们就可以选择加权或者拼接加PCA降维的方式得到最后的电影的嵌入表示。
　　相对于以上通过词向量聚合得到句子嵌入表示的方法，我们也可以选择利用文本序列建模方法端到端地生成标题/描述文本的句子表示，进而得到电影的嵌入表示。此类方法有本课中提到的BERT，也包含Seq2Seq等经典方法。值得一提的是，这类方法为句子生成表示时往往需要一些标签信息如句子和词的类别（当然BERT这类模型我们可以使用一一些无监督的伪任务），这时我们就可以利用第三个数据源:电影的风格类型，来作为训练句子嵌入表示的标签。使用这类方法，我们既可以得到电影的标题和描述文本的单独的表示，也可以将它们串联成一一个句子得到一个整体表示，最后就可以使用这个表示作为电影的嵌入表示啦。&lt;/p&gt;
&lt;p&gt;(2)电影和电影间的相关度矩阵，大小为M * M, M为电影的数目，矩阵值为-1.0到1.0间的浮点数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　这道题的数据源是电影间的相关度矩阵，不难理解矩阵分解是最直观的方法:我们为每个电影初始化一一个嵌入表示，然后进一步学习和调整这些表示，使不同电影间嵌入表示的相关度(如余弦相关度)能和给定的相关度矩阵保持一致。&lt;/p&gt;
&lt;p&gt;(3)用户一周内的观影历史，一共有N个用户， 每个用户的观影历史为一长度不定的向量，向量值为0到M-1范围内的整数，表示电影的ID。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　首先，这道题的数据源是序列信息，每个用户的观影序列可以理解为一个一个的句子，句子中的单词(Word)就是电影，因此首先想到的方法应该是使用Word2Vec直接学习每个电影的嵌入表示。另一方面，既然有用户的观影序列，我们就可以进一步统计以上信息得到用户-电影的交互矩阵，这样就可以参照(2)中的方法就行矩阵分解得到电影的嵌入表示。
　　
　　点评:
　　这道题的目的是考察大家对不同的嵌入表示生成方法对数据的要求的理解。在算法研发过程中，除了目标指标，影响算法选型的另外一个重要因素往往是我们有什么类型、多大体量以及多高质量的数据，了解这些算法的适用条件是在工作中正确应用它们的重要前提。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;基于深度神经网络的排序模型相对于传统的逻辑回归模型(LR)有什么优劣，试从模型准确度、推断效率和工程代价进行分析。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　模型准确度上，深度神经网络由于模型复杂、自由度大，从而拥有更强的理论建模能力，其准确度往往优于逻辑回归。但是由于用户的个体差异性，其准确度领先幅度并不特别显著，在近年的学术论文上看，目标数据集上，基于深度神经网络的排序模型在离线AUC这个指标上领先逻辑回归通常不超过1%-2%。
　　推断效率上，深度神经网络明显劣于逻辑回归模型。深度神经网络的理论计算量巨大，比逻辑回归高几个量级，且网络内部各层计算量均一性差，因此单次推断的并行效率也劣于逻辑回归，最终体现在模型推断时延较高且对计算资源需求较大。
　　工程代价上，深度神经网络更大的计算复杂度会在多个环节带来问题，如如何及时地完成模型的离线训练和高效地进行在线推断等。这对推荐系统框架在部署、任务和资源调度、运行效率优化等多个方面都会带来额外复杂度。一个例子是，有的深度神经网络模型由于计算复杂度大，无法直接在线部署，而需要将部分计算离线/近线(Nearline)化以减轻线上的计算压力，以空间换时间，同时还需付出更多额外的努力对在线推断部分进行效率优化，这就是典型的模型复杂度升高对工程框架的挑战。
　　
　　点评：
　　这道题的目的是考察大家对深度神经网络的优劣的整体认识，在工程实践中，模型准确度只是决定选型的部分因素，计算量和实现框架的约束，以及复杂度的增加和准确度提升间的取舍也是非常重要的。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;在推荐模型中，为什么有的连续的特征，如年龄，要按范围被离散化(把用户年龄分成互不交叉的几组)？这样做的好处是什么？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;参考答案&lt;/strong&gt;
　　简单而言，是为了平滑特征。用户之间存在个体差异，像年龄值这样的涉及用户属性的连续特征有时会过于“精确”， 从而不利于提升模型的泛化能力。
　　具体来说，首先在推荐的场景下，年龄一定是影响用户兴趣的重要因素，但是这种影响通常是来自于“年龄段&amp;quot;而非具体的“年龄值”。在“年轻人比老年人更喜欢看恐怖片”的假设下，“18-26岁的用户比大于56岁的用户更喜欢看恐怖片”往往比“X岁的用户A比(X+1)岁的用户B更喜欢看恐怖片”这样的推论更加准确和鲁棒。
　　更进一步而言，年龄值和兴趣之间的关联性存在个体差异，这种差异远比年龄段和兴趣的关联的个体差异大的多。如用户A可能在18-26岁间爱看恐怖片，但是用户B可能在30岁才发展出看恐怖片的兴趣。这种关联的强个体差异意味着模型的学习没有统一且有效的ground truth，从而导致训练过程的震荡和推断能力的退化。&lt;/p&gt;
&lt;p&gt;　　点评：
　　这道题的目的是考察对推荐模型输入特征的一个细节理解，也是检验同学们是否有仔细听课。模型的准确度不仅仅取决于模型结构数据，输入特征的属性和表示方式也是非常重要的。&lt;/p&gt;</description>
        </item>
        <item>
        <title>《推荐系统实践》笔记</title>
        <link>https://hubojing.github.io/leqnlq9y/</link>
        <pubDate>Sat, 30 Nov 2019 18:45:33 +0000</pubDate>
        
        <guid>https://hubojing.github.io/leqnlq9y/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/《推荐系统实践》笔记——推荐系统实践.jpg&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;to be continued&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;第1章-好的推荐系统&#34;&gt;第1章 好的推荐系统
&lt;/h1&gt;&lt;h2 id=&#34;什么是推荐系统&#34;&gt;什么是推荐系统
&lt;/h2&gt;&lt;p&gt;　　推荐系统的基本任务是联系用户和物品，解决信息过载的问题。&lt;br&gt;
　　社会化推荐(social recommendation)：向朋友咨询&lt;br&gt;
　　基于内容的推荐(content-based filtering)：寻找和自己之前喜欢的物品相似的物品&lt;br&gt;
　　基于协同过滤(collaborative filtering)：找到和自己历史兴趣相似的用户所喜欢的物品&lt;/p&gt;
&lt;h2 id=&#34;推荐系统评测&#34;&gt;推荐系统评测
&lt;/h2&gt;&lt;h3 id=&#34;实验方法&#34;&gt;实验方法
&lt;/h3&gt;&lt;p&gt;　　离线实验（offline experiment）、用户调查（user study）、在线实验（online experiment）&lt;br&gt;
　　离线实验步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集;&lt;/li&gt;
&lt;li&gt;将数据集按照一定的规则分成训练集和测试集;&lt;/li&gt;
&lt;li&gt;在训练集上训练用户兴趣模型，在测试集上进行预测;&lt;/li&gt;
&lt;li&gt;通过事先定义的离线指标评测算法在测试集上的预测结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;　　在线实验：AB测试&lt;br&gt;
　　AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。&lt;/p&gt;
&lt;h3 id=&#34;评测指标&#34;&gt;评测指标
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;用户满意度&lt;/li&gt;
&lt;li&gt;预测准确度
　　评分预测：均方根误差RMSE和平均绝对误差（MAE）
　　TopN推荐：准确率（precision）和召回率（recall）&lt;/li&gt;
&lt;li&gt;覆盖率（coverage）
　　信息熵和基尼系数（Gini Index）&lt;/li&gt;
&lt;li&gt;多样性&lt;/li&gt;
&lt;li&gt;新颖性&lt;/li&gt;
&lt;li&gt;惊喜度&lt;/li&gt;
&lt;li&gt;信任度&lt;/li&gt;
&lt;li&gt;实时性&lt;/li&gt;
&lt;li&gt;健壮性&lt;/li&gt;
&lt;li&gt;商业目标&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;评测维度&#34;&gt;评测维度
&lt;/h3&gt;&lt;p&gt;　　用户维度
　　物品维度
　　时间维度&lt;/p&gt;
&lt;h1 id=&#34;第2章-利用用户行为数据&#34;&gt;第2章 利用用户行为数据
&lt;/h1&gt;&lt;p&gt;　　基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为协同过滤算法。&lt;br&gt;
　　按反馈的明确性分，显式反馈（explicit feedback）和隐式反馈（implicit feedback）&lt;br&gt;
　　按反馈的方向分，正反馈（用户的行为倾向于指用户喜欢该物品）和负反馈（用户的行为倾向于指用户不喜欢该物品）&lt;br&gt;
　　有代表性的数据集：&lt;br&gt;
　　无上下文信息的隐性反馈数据集：每一条行为记录仅仅包含用户ID和物品ID。&lt;br&gt;
　　无上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品的评分。&lt;br&gt;
　　有上下文信息的隐性反馈数据集：每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。&lt;br&gt;
　　有上下文信息的显性反馈数据集：每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。&lt;/p&gt;
&lt;h2 id=&#34;用户活跃度和物品流行度的分布&#34;&gt;用户活跃度和物品流行度的分布
&lt;/h2&gt;$$f(x)=αx^k$$$$f_i(k)=a_ik^{β_i}$$$$f_u(k)=a_uk^{β_u}$$&lt;p&gt;
　　物品的流行度指对物品产生过行为的用户总数。
　　用户的活跃度为用户产生过行为的物品总数。&lt;/p&gt;
&lt;h2 id=&#34;用户活跃度和物品流行度的关系&#34;&gt;用户活跃度和物品流行度的关系
&lt;/h2&gt;&lt;p&gt;　　仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法。
　　基于邻域的方法（neighborhood-based）：基于用户的协同过滤算法（推荐和用户兴趣相似的其他用户喜欢的物品）、基于物品的协同过滤算法（推荐和他之前喜欢的物品相似的物品）
　　隐语义模型（latent factor model）
　　基于图的随机游走算法（random walk on graph）&lt;/p&gt;
&lt;h2 id=&#34;基于邻域的算法&#34;&gt;基于邻域的算法
&lt;/h2&gt;&lt;h3 id=&#34;基于用户的协同过滤算法&#34;&gt;基于用户的协同过滤算法
&lt;/h3&gt;&lt;h4 id=&#34;基础算法&#34;&gt;基础算法
&lt;/h4&gt;&lt;p&gt;　　步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;找到和目标用户兴趣相似的用户集合。&lt;/li&gt;
&lt;li&gt;找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。
　　步骤1关键是计算两个用户的兴趣相似度。
　　利用行为的相似度计算兴趣相似度。Jaccard公式计算用户u和用户v的兴趣相似度。
$$w_{uv}=\frac{|{N(u)∩N(v)}|}{|{N(u)∪N(v)}|}$$
　　或者通过余弦相似度
$$w_{uv}=\frac{|{N(u)∩N(v)}}{|\sqrt{|{N(u)||N(v)}|}}$$
　　N(u)表示用户u曾经有过正反馈的物品集合，N(v)为用户曾经有过正反馈的物品集合。&lt;br&gt;
　　时间复杂度：O(|U|*|U|)
　　用户数很大时耗时，并且很多时候|N(u)∩N(v)|=0。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;改进算法&#34;&gt;改进算法
&lt;/h4&gt;$$w_uv = \frac{\sum i\epsilon N(u)∩N(v)\frac{1}{log1+|N(i)|}}{\sqrt{|N(u)||N(v)|}}$$&lt;p&gt;
　　该公式通过$\frac{1}{log1+|N(i)|}$惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响。&lt;/p&gt;
&lt;h3 id=&#34;基于物品的协同过滤算法&#34;&gt;基于物品的协同过滤算法
&lt;/h3&gt;&lt;p&gt;　　ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为，物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。&lt;br&gt;
　　步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算物品之间的相似度&lt;/li&gt;
&lt;li&gt;根据物品的相似度和用户的历史行为给用户生成推荐列表
$$w_{ij}=\frac{|N(i)∩N(j)|}{|N(i)|}$$
　　|N(i)|是喜欢物品i的用户数，分子|N(i)∩N(j)|是同时喜欢物品i和物品j的用户数。
　　公式可理解为喜欢物品i的用户中有多少比例的用户也喜欢物品j。&lt;/li&gt;
&lt;/ol&gt;
$$w_{ij}=\frac{|N(i)∩N(j)|}{\sqrt{|N(i)||N(j)|}}$$&lt;p&gt;
　　该公式惩罚了物品j的权重，因此减轻了热门物品和很多物品相似的可能性。&lt;/p&gt;
&lt;p&gt;　　从定义可看出，在协同过滤中两个物品产生相似度是因为它们共同被很多用户喜欢，即每个用户都可以通过他们的历史兴趣列表给物品贡献相似度。&lt;/p&gt;
&lt;h4 id=&#34;用户活跃度对物品相似度的影响&#34;&gt;用户活跃度对物品相似度的影响
&lt;/h4&gt;$$w_uv = \frac{\sum u\epsilon N(i)∩N(j)\frac{1}{log1+|N(u)|}}{\sqrt{|N(i)||N(j)|}}$$&lt;ul&gt;
&lt;li&gt;物品相似度的归一化
$$w_{ij} = \frac{w_{ij}}{max w_{ij}}$$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;usercf和itemcf对比&#34;&gt;UserCF和ItemCF对比
&lt;/h3&gt;&lt;p&gt;　　UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF的推荐结果着重于维系用户的历史兴趣。换句话说，UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承。&lt;/p&gt;
&lt;p&gt;　　UserCF使用场景：新闻推荐
　　ItemCF使用场景：图书、电子商务、电影网站&lt;/p&gt;
&lt;p&gt;　　在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ItemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大，相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。&lt;/p&gt;
&lt;h2 id=&#34;隐语义模型&#34;&gt;隐语义模型
&lt;/h2&gt;&lt;h3 id=&#34;基础算法-1&#34;&gt;基础算法
&lt;/h3&gt;&lt;p&gt;　　思想：通过隐含特征（latent factor）联系用户兴趣和物品。
　　基于兴趣分类的方法大概需解决三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何给物品进行分类？&lt;/li&gt;
&lt;li&gt;如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？&lt;/li&gt;
&lt;li&gt;对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;　　隐含语义分析技术采取基于用户行为统计的自动聚类。
　　隐含语义分析技术从诞生到今天产生了很多著名模型和方法：pLSA、LDA、隐含类别模型（latent class model）、隐含主题模型（latent topic model）、矩阵分解（matrix factorization）。&lt;/p&gt;
&lt;h4 id=&#34;lfm&#34;&gt;LFM
&lt;/h4&gt;$$Preference(u,i) = r_{ui} = p_u^Tq_i = \sum_{f=1}^Fp_{u,k}q_{i,k}$$&lt;p&gt;
　　$p_{u,k}$和$q_{i,k}$是模型参数，$p_{u,k}$度量了用户u的兴趣和第k个隐类的关系，而$q_{i,k}$度量了第k个隐类和物品i之间的关系。&lt;br&gt;
　　这两个参数是从数据集中计算出来的。要计算这两个参数，需要一个训练集，对于每个用户u，训练集里都包含了用户u喜欢的物品和不感兴趣的物品，通过学习这个数据集，就可以获得上面的模型参数。&lt;/p&gt;
&lt;p&gt;　　推荐系统的用户行为分为显性反馈和隐性反馈。 LFM在显性反馈数据(也就是评分数据)上解决评分预测问题并达到了很好的精度。
隐性反馈数据集：只有正样本（用户喜欢什么物品），没有负样本（用户对什么物品不感兴趣）。
在隐性反馈数据集上应用LFM解决TopN推荐的第一个关键问题就是如何给每个用户生成负样本。&lt;/p&gt;
&lt;p&gt;生成负样本方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于一个用户，用他所有没有过行为的物品作为负样本。//负样本太多，正负样本数目相差悬殊，计算复杂度很高，结果精度差。&lt;/li&gt;
&lt;li&gt;对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。&lt;/li&gt;
&lt;li&gt;对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。&lt;/li&gt;
&lt;li&gt;对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品。
第三种好于第二种，第二种好于第四种。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对负样本采样时应遵循以下原则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对每个用户，要保证正负样本的平衡（数目相似）。&lt;/li&gt;
&lt;li&gt;对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。
一般认为，很热门而用户却没有行为更加代表用户对这个物品不感兴趣。因为对于冷门的物品，用户可能是没发现这个物品，所以谈不上是否感兴趣。
LFM模型在实际使用中有一个困难：它很难实现实时的推荐。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lfm和基于领域的方法比较&#34;&gt;LFM和基于领域的方法比较
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;理论基础
LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标建立最优的模型。基于邻域的方法更多的是一种基于统计的方法，并没有学习过程。&lt;/li&gt;
&lt;li&gt;离线计算的空间复杂度
用户相关表，则需要O(M*M)的空间，而对于物品相关表，则需要O(N*N)的空间。
LFM在建模过程中，如果是F个隐类，那么它需要的存储空间是O(F*(M+N))，这在M和N很大时可以很好地节省离线计算的内存。&lt;/li&gt;
&lt;li&gt;离线计算的时间复杂度
假设有M个用户、 N个物品、 K条用户对物品的行为记录。UserCF计算用户相关表的时间复杂度是O(N * (K/N)^2)，而ItemCF计算物品相关表的时间复杂度是O(M*(K/M)^2)。而对于LFM，如果用F个隐类，迭代S次，那么它的计算复杂度是O(K * F * S)。总体上没有质的差别。&lt;/li&gt;
&lt;li&gt;在线实时推荐
UserCF、ItemCF可，LFM不可。&lt;/li&gt;
&lt;li&gt;推荐解释
ItemCF解释很好，LFM无法解释。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;基于图的模型graph-based-model&#34;&gt;基于图的模型（graph-based model）
&lt;/h2&gt;&lt;h3 id=&#34;用户行为数据的二分图表示&#34;&gt;用户行为数据的二分图表示
&lt;/h3&gt;&lt;p&gt;很多研究者把基于邻域的模型也称为基于图的模型，因为基于邻域的模型可看做基于图的模型的简单形式。
二元组（u, i）表示用户u对物品i产生过行为。令G（V, E）表示用户物品二分图，其中$V = V_U∪V_1$由用户顶点集合$V_U$和物品顶点集合$V_1$组成。对于数据集中每一个二元组（u, i），图中都有一套对应的边e（$v_u$, $v_i$），其中$v_u\epsilon V_U$是用户u对应的顶点，$v_i\epsilon V_1$是物品i对应的顶点。
&lt;img src=&#34;https://hubojing.github.io/images/%e3%80%8a%e6%8e%a8%e8%8d%90%e7%b3%bb%e7%bb%9f%e5%ae%9e%e8%b7%b5%e3%80%8b%e7%ac%94%e8%ae%b0%e2%80%94%e2%80%94%e4%ba%8c%e5%88%86%e5%9b%be.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;用户物品二分图模型&#34;
	
	
&gt;
图中是一个简单的用户物品二分图模型，其中圆形节点代表用户，方形节点代表物品，圆形节点和方形节点之间的边代表用户对物品的行为。比如图中用户节点A和物品节点a、 b、 d相连，说明用户A对物品a、 b、 d产生过行为。&lt;/p&gt;
&lt;h3 id=&#34;基于图的推荐算法graph-based-model&#34;&gt;基于图的推荐算法（graph-based model）
&lt;/h3&gt;&lt;p&gt;可把基于领域的模型看做基于图的模型的简单形式。
相关性高的一对顶点一般具有如下特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个顶点之间有很多路径相连&lt;/li&gt;
&lt;li&gt;连接两个顶点之间的路径长度都比较短&lt;/li&gt;
&lt;li&gt;连接两个顶点之间的路径不会经过出度比较大的顶点&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;基于随机游走的personalrank算法&#34;&gt;基于随机游走的PersonalRank算法
&lt;/h4&gt;&lt;p&gt;假设要给用户u进行个性化推荐，可以从用户u对应的节点vu开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率α决定是继续游走，还是停止这次游走并从vu节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。&lt;/p&gt;
&lt;p&gt;缺点：复杂度高，耗时&lt;/p&gt;
&lt;h1 id=&#34;第三章-冷启动问题&#34;&gt;第三章 冷启动问题
&lt;/h1&gt;&lt;p&gt;冷启动问题（cold start）分三类：
用户冷启动（新用户到来）、物品冷启动（新物品到来）、系统冷启动（新开发网站，没有用户和用户行为，只有物品信息）
解决方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提供非个性化推荐：比如热门排行榜&lt;/li&gt;
&lt;li&gt;利用用户注册时提供的年龄、性别等数据做粗粒度的个性化&lt;/li&gt;
&lt;li&gt;利用用户社交网络账号（需用户授权），导入用户好友信息，给用户推荐好友喜欢的物品&lt;/li&gt;
&lt;li&gt;要求用户登录时对物品进行反馈，收集兴趣信息从而推荐和物品相似的物品&lt;/li&gt;
&lt;li&gt;新加入的物品利用内容信息，将它们推荐给喜欢过相似物品的用户&lt;/li&gt;
&lt;li&gt;系统冷启动引入专家知识&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;用户注册信息分3种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;人口统计学信息：年龄、性别、职业、民族、学历和居住地&lt;/li&gt;
&lt;li&gt;用户兴趣描述&lt;/li&gt;
&lt;li&gt;其它网站导入用户站外行为数据&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基于人口统计学特征的推荐系统其典型代表是Bruce Krulwich开发的Lifestyle Finder。&lt;/p&gt;
&lt;p&gt;基于注册信息的个性化推荐流程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;获取用户的注册信息；&lt;/li&gt;
&lt;li&gt;根据用户的注册信息对用户分类；&lt;/li&gt;
&lt;li&gt;给用户推荐他所属分类中用户喜欢的物品。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有两个推荐系统数据集包含了人口统计学信息，BookCrossing数据集和Last.fm数据集。
BookCrossing数据集包含用户对图书的行为信息，包含3个文件。
BX-Users.csv，包含用户的ID、位置和年龄。
BX-Books.csv，包含图书的ISBN、标题、作者、发表年代、出版社和缩略。
BX-Book-Ratings.csv，包含用户对图书的评分信息。&lt;/p&gt;
&lt;p&gt;ItemCF算法存在严重的冷启动问题。&lt;/p&gt;
$$d_i = {(e_1, w_1),(e_2,w_2),...}$$&lt;p&gt;
其中$e_i$是关键词，$w_i$是关键词权重。
若物品是文本，可用信息检索领域著名的TF-IDF公式计算词的权重：&lt;/p&gt;
&lt;p&gt;&amp;hellip;先让我更新一下友链&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
