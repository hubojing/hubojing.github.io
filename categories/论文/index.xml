<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>论文 on 靖待</title>
        <link>https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/</link>
        <description>Recent content in 论文 on 靖待</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>靖待</copyright>
        <lastBuildDate>Wed, 22 Nov 2023 22:20:55 +0000</lastBuildDate><atom:link href="https://hubojing.github.io/categories/%E8%AE%BA%E6%96%87/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大模型相关论文笔记</title>
        <link>https://hubojing.github.io/9ocgomtj/</link>
        <pubDate>Wed, 22 Nov 2023 22:20:55 +0000</pubDate>
        
        <guid>https://hubojing.github.io/9ocgomtj/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\paper.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
 　　
　　**大模型相关论文阅读笔记。 **
　　**倒序排列论文，最新阅读的在最上面。**
　　**2024年1月26日更新**
 &lt;/div&gt;
&lt;h1 id=&#34;retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks&#34;&gt;Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
&lt;/h1&gt;&lt;p&gt;用于知识密集型NLP任务的检索增强生成
Facebook 2020
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2005.11401v4.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/huggingface/transformers/tree/main/examples/research_projects/rag&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;br&gt;
（论文代码链接已失效，以上是最新链接）&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;大模型有幻觉问题（hallucinations），检索增强生成(retrieval-augmented generation, RAG)可以解决它。&lt;/p&gt;
&lt;h2 id=&#34;方法&#34;&gt;方法
&lt;/h2&gt;&lt;p&gt;输入为x，外部检索资源为z，生成目标序列y。
模型有两块：一个检索器$p_\eta(z|x)$，$\eta$为参数，给定一个查询q，根据文本返回top-K个分布；一个生成器$p_\theta(y_i|x,z,y_{1:i-1})$，参数为$\theta$，它基于过去i-1个tokens $y_{1:i-1}$、原始输入x和检索器信息z，产生一个当前的token。
为了端到端的训练检索器和生成器，我们将检索文档作为一个隐变量。我们提出了两个模型，他们以不同的方式边缘化隐变量，从而在文本上产生分布。在我们的方法里，第一步，RAG-Sequence，这个模型使用相同的文本预测每一个目标token；第二步，RAG-Token，基于不同的文件预测每一个目标token。&lt;/p&gt;
&lt;h3 id=&#34;模型&#34;&gt;模型
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;RAG-Sequence模型
$$p_{RAG-Sequence}(y|x)≈\sum_{z∈top-k(p(·|x))}p_\eta(z|x)p_\theta(y|x,z)=\sum_{z∈top-k(p(·|x))}p_\eta(z|x)\prod^N_ip_\theta(y_i|x,z,y_{1:i-1})$$&lt;/li&gt;
&lt;li&gt;RAG-Token模型
$$p_{RAG-Token}(y|x)≈\prod^N_i\sum_{z∈top-k(p(·|x))}p_\eta(z|x)p_\theta(y_i|x,z,y_{1:i-1})$$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;检索器dpr&#34;&gt;检索器：DPR
&lt;/h3&gt;$$p_\eta(z|x)∝exp(d(z)^Tq(x)) ~~~ d(z)=BERT_d(z), q(x)=BERT_q(x)$$&lt;p&gt;
其中，d(z)是使用BERT编码得到的密集表示，q(x)是问题通过BERT编码得到的表示。计算top-k($p_\eta(·|x)$)是一个MIPS(Maximum Inner Product Search)问题，可以在亚线性时间内解决。我们使用一个基于DPR的预训练双向编码器来初始化我们的检索器并建立索引，将其视为非参数记忆(non-parametric memory)。&lt;/p&gt;
&lt;h3 id=&#34;生成器bart&#34;&gt;生成器：BART
&lt;/h3&gt;&lt;p&gt;生成器可以使用任何编码器-解码器。我们使用的是BART-large。&lt;/p&gt;
&lt;h3 id=&#34;训练&#34;&gt;训练
&lt;/h3&gt;&lt;p&gt;求最小似然log-likelihood、Adam&lt;/p&gt;
&lt;h3 id=&#34;解码&#34;&gt;解码
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;RAG-Toke&lt;br&gt;
$$p^{&#39;}_\theta(y_i|x,y_{1:i-1})=\sum_{z∈top-k(p(·|x))}p_\eta(z_i|x)p_\theta(y_i|x,z_i,y_{1:i-1})$$
将$p^{&amp;rsquo;}&lt;em&gt;\theta(y_i|x,y&lt;/em&gt;{1:i-1})$送入标准beam解码器中。&lt;/li&gt;
&lt;li&gt;RAG-Sequence&lt;br&gt;
Thorough Decoding
Fast Decoding&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;flashattention-fast-and-memory-efficient-exact-attention-with-io-awareness&#34;&gt;FLASHATTENTION: Fast and Memory-Efficient Exact Attention with IO-Awareness
&lt;/h1&gt;&lt;p&gt;FlashAttention: 具有IO感知的快速和有效存储精确注意力
2022年6月24日
&lt;a class=&#34;link&#34; href=&#34;https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/Dao-AILab/flash-attention&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要
&lt;/h2&gt;&lt;p&gt;　　自注意力的时间和空间复杂度在序列长度上是二次关系，近似注意力机制尝试在模型质量和复杂度计算中折中来解决该问题，但是经常不能实现wall-clock加速。本文认为，需要一种规范，可以根据GPU读写水平使注意力IO感知。为此，本文提出FLASHATTENTION，一种IO感知的精确注意力机制，它使用tiling技术来减少GPU HBM（high bandwidth memory）和GPU芯片内SRAM的存储读写次数。FLASHATTENTION相比标准注意力机制要减少这方面开销。&lt;/p&gt;
&lt;h2 id=&#34;引言-1&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cFlashAttention.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;FlashAttention&#34;
	
	
&gt;&lt;br&gt;
　　现代GPU的计算速度比存储速度快，在Transformer里的许多操作都受限于存储接入。现在的公共Python接口，比如PyTorch和Tensorflow对于内存接入没有精细化管理。本文提出FLASHATTENTION，一种计算注意力时减少内存接入操作的新注意力算法。它的目标是减少在HBM中读写的注意力矩阵。这需要
（1）在不访问整体输入的情况下计算softmax reduction；
（2）反向传播时不存大量中间过程的注意力矩阵。
　　本文提出两种方法解决上面的问题。
（1）我们重新构建了注意力计算模块，将输入分块，在输入块中形成多个通道，因此递增地执行softmax reduction（也就是tiling)；
（2）从前向传播到反向传播中快速重新计算片上注意力，我们存储了其中的softmax标准化因素，这比从HBM读取中间注意力矩阵的标准方法要快。
　　在CUDA使用FLASHATTENTION去实现精细化存储控制以及在GPU内核中融合所有的注意力操作。即使因为重计算会增加FLOP（Floating Point Operations），相对于标准注意力而言，我们的算法依然更快、需要更少的内存，在序列长度上是线性的，这是因为HBM的接入大量减少。
　　FLASHATTENTION在HBM上的复杂度是O(N^2d^2M^{-1})，其中d是头head的维度，M是SRAM的规模，标准注意力的复杂度是$Ω(Nd+N^2)$。
　　本文贡献点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更快的模型训练速度&lt;/li&gt;
&lt;li&gt;更高的模型质量&lt;/li&gt;
&lt;li&gt;比现有基线注意力都要快&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景
&lt;/h2&gt;&lt;h3 id=&#34;硬件性能&#34;&gt;硬件性能
&lt;/h3&gt;&lt;p&gt;　　重点描述GPU。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU存储等级
　　HBM、SRAM&lt;/li&gt;
&lt;li&gt;执行模型
　　GPU有很多线程去执行一个操作（称为核）。每个核从HBM登记加载输入，SRAM计算，再将输出写入HBM。&lt;/li&gt;
&lt;li&gt;性能特点&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;计算密集型Compute-bound&lt;/li&gt;
&lt;li&gt;存储密集型Memory-bound&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;内核融合
　　最常见的加速存储密集操作的就是内核融合。如果多个操作同时应用在相同的输入时，可以从HBM一次性加载输入。编译器会自动融合许多elementwise操作。然而，根据模型训练的上下文，中间过程的值为了反向传播仍然需要写入HBM，这降低了原生内核融合的效率。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;标准注意力&#34;&gt;标准注意力
&lt;/h4&gt;$$S=QK^T∈\mathbb{R}^{N×N}, P=softmax(S)∈\mathbb{R}^{N×N}, O=PV∈\mathbb{R}^{N×d}$$&lt;p&gt;
softmax按行(row-wise)使用。
　　标准注意力将S和P扔给HBM，这花费了$O(N^2)$存储。一般来说，N&amp;raquo;d，比如GPT2里N=1024，d=64。大部分操作是存储密集型（比如softmax），大量的存储读写造成wall-clock时间变慢。
　　其它操作更加加剧了这个问题，比如加在注意力矩阵的elementwise操作、加在S上的遮罩或者加在P上的dropout。为此，有很多融合几种elementwise操作的方法尝试，比如一些文献用softmax融合遮罩。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cFlashAttention-StandardAttention%e4%bc%aa%e4%bb%a3%e7%a0%81.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;标准注意力伪代码&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;flashattention&#34;&gt;FLASHATTENTION
&lt;/h2&gt;&lt;p&gt;　　两种方法：tiling和recomputation
　　主要思路：将输入的Q、K、V分块，将它们从慢的HBM放到快的SRAM中，计算了注意力输出后再返回到各自块里。在每个快的输出相加之前，通过标准化进行缩放，最终得到结果。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tiling&lt;/li&gt;
&lt;li&gt;Recomputation
　　我们的目标之一是不要存储反向传播中间过程值$O(N^2)$。反向传播需要矩阵$S,P∈\mathbb{R}^{N×N}$来计算Q、K、V的梯度。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cFlashAttention%e4%bc%aa%e4%bb%a3%e7%a0%81.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;FlashAttention伪代码&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;lora-low-rank-adaptation-of-large-language-models&#34;&gt;LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS
&lt;/h1&gt;&lt;p&gt;　　大模型的低秩适配器&lt;br&gt;
　　微软 2021年&lt;br&gt;
　　Low-Rank Adaptation, LORA&lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2106.09685.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/microsoft/LoRA&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;
　　冻结预训练模型的参数，在Transformer架构每一层注入一个可训练的低秩分解矩阵（rank decomposition matrices），大幅减少了下游任务的训练参数。&lt;br&gt;
　　对比GPT-3 175B Adam微调，LoRA可以减少10000倍训练参数、3倍GPU存储。&lt;br&gt;
　　对比RoBERTa, DeBERTa, GPT-2, GPT-3，训练参数虽少，模型微调质量更好，更高的训练吞吐量，而且不像适配器，没有额外的推理延迟。&lt;/p&gt;
&lt;h2 id=&#34;引言-2&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;　　微调会更新预训练模型的全部参数，下游任务的新模型和原模型参数一样多。许多研究者通过只更新部分参数或学习新任务的额外模块进行迁移，这样可以只保存和加载一小部分任务相关的参数即可，部署时提高了效率。但是现有方法通过延伸模型深度或者减少模型可用的序列长度会导致推理延迟。而且这些策略达不到微调的基线效果，在效率和模型质量上做了折中。&lt;br&gt;
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cLoRA.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;LoRA&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;问题陈述&#34;&gt;问题陈述
&lt;/h2&gt;$$\underset{\Phi}{max}\sum_{(x,y)∈Z}\sum^{|y|}_{t=1}log(P_{\Phi}(y_t|x,y_{&lt;t}))$$$$\underset{\Theta}{max}\sum_{(x,y)∈Z}\sum^{|y|}_{t=1}log(P_{\Phi}(y_t|x,y&lt;t))$$&lt;p&gt;
　　本文提出了一种低秩表示来编码$△\Phi$。对于GPT-3 175B，$|\Theta|$的训练参数量是$|\Phi_0|$的0.01%。&lt;/p&gt;
&lt;h2 id=&#34;之前方法的缺点&#34;&gt;之前方法的缺点
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;适配器层引入了推理延迟&lt;/li&gt;
&lt;li&gt;直接优化Prompt很难&lt;br&gt;
　　比如prefix tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;本文方法&#34;&gt;本文方法
&lt;/h2&gt;&lt;h3 id=&#34;低秩参数更新矩阵&#34;&gt;低秩参数更新矩阵
&lt;/h3&gt;$$h = W_0x+△Wx = W_0x + BAx$$&lt;p&gt;
当遇到不用的下游任务时，只需要替换BA就行，所以没有推理延迟。&lt;/p&gt;
&lt;h3 id=&#34;将lora应用到transformer&#34;&gt;将LoRA应用到Transformer
&lt;/h3&gt;&lt;p&gt;在Transformer架构中，在自注意力模块有四个权重矩阵（$W_q$、$W_k$、$W_v$、$W_o$），在MLP模块有两个。本文将Transformer架构中的$W_q$（或者$W_k$，$W_v$）设为一个$d_{model}×d_{model}$的单矩阵。对于下游任务，只改变注意力权重，冻结MLP模块的。&lt;/p&gt;
&lt;h1 id=&#34;llama-2-open-foundation-and-fine-tuned-chat-models&#34;&gt;Llama 2: Open Foundation and Fine-Tuned Chat Models
&lt;/h1&gt;&lt;p&gt;2023年7月  77页
GenAI, Meta
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2307.09288.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/facebookresearch/llama&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;引言-3&#34;&gt;引言
&lt;/h2&gt;&lt;p&gt;　　本文发布了两个模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLAMA 2，它是LLAMA 1的升级版本，训练语料新增40%，模型上下文长度翻倍，采用了分组查询注意力。发布了7B, 13B, 70B，34B也训了但没发布&lt;/li&gt;
&lt;li&gt;LLAMA 2-CHAT，它是LLAMA 2用于用户对话的微调版本。发布了7B，13B，70B参数模型
　　提供了&lt;a class=&#34;link&#34; href=&#34;https://ai.meta.com/llama&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;用户手册&lt;/a&gt;和&lt;a class=&#34;link&#34; href=&#34;%e2%80%96https://github.com/facebookresearch/llama&#34; &gt;代码样例&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;预训练&#34;&gt;预训练
&lt;/h2&gt;&lt;p&gt;　　预训练数据：2 trillion&lt;br&gt;
　　训练，与LLAMA 1相同之处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;标准transformer&lt;/li&gt;
&lt;li&gt;RMSNorm预归一化&lt;/li&gt;
&lt;li&gt;SwiGLU激活函数&lt;/li&gt;
&lt;li&gt;旋转位置embedding RoPE
　　不同之处：&lt;/li&gt;
&lt;li&gt;增加上下文长度&lt;/li&gt;
&lt;li&gt;分组查询注意力（GQA）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　优化器：AdamW&lt;br&gt;
　　分词器：与LLAMA 1相同，此表规模32k tokens&lt;/p&gt;
&lt;p&gt;　　它甚至还写了LLAMA 2的碳排放情况&amp;hellip;&lt;/p&gt;
&lt;p&gt;　　评价指标方面，LLAMA 2 70B在MMLU和GSM8K上与GPT-3.5相近，但是在代码基线上有差距，在几乎所有的基线上都比PaLM(540B)强。与GPT-4和PaLM-2-L相比，还有很大差距。&lt;/p&gt;
&lt;h2 id=&#34;微调&#34;&gt;微调
&lt;/h2&gt;&lt;h3 id=&#34;sft监督微调&#34;&gt;SFT监督微调
&lt;/h3&gt;&lt;p&gt;　　使用了公开的微调数据，自己标了一些，有27540这么多就不标了，因为数量少质量高效果也能好。 &lt;br&gt;
　　对于微调过程，每一个样本包含一个提示prompt和一个答案。为了确保模型序列长度都被填充，训练集里将全部的prompt和答案相连。用了特殊token划分prompt和答案片段。使用了一种自回归目标函数，并将来自用户prompt的token计算loss归零，所以只在答案token上反向传播。模型微调轮数为2。&lt;/p&gt;
&lt;h3 id=&#34;rlhf-人类反馈的增强学习&#34;&gt;RLHF 人类反馈的增强学习
&lt;/h3&gt;&lt;p&gt;　　RLHF是一种将微调模型行为与人类偏好和指令对齐的一种模型训练过程。首先让标注员写一个提示（prompt），然后对两个样本模型的回答根据制定的标准选择更好的一个，这种数据用于训练奖励模型（reward model）。为了多样性最大化，两个模型参数和超参数不同。为了让参与者强制选择，每个回答会打标程度（很好，好，一般，不确定）。合适的标注从两个方面考虑，有用性和安全性。在其它答案是安全的情况下，不会选择不安全的回答为最佳，因为本文认为安全回答也是更好的。&lt;br&gt;
　　收集了更多的偏好数据后，奖励模型进步了，LLAMA 2-CHAT就会训练地更好，而它更好又会改变模型数据分布。如果不用最新的样本分布，奖励模型的精确度就会很快降低。所以在微调新一轮LLAMA 2-CHAT前使用当前最新的LLAMA 2-CHAT收集数据很重要。这一步让奖励模型保持正确的分布，也能保持最新模型的准确奖励值。&lt;br&gt;
　　本文收集了超过一百万（1 million）人工标注数据，称做Meta奖励模型数据。不同领域提示和回答的数量不同，总结和在线公式数据一般有较长的提示，然而对话型提示通常较短。平均来看，本文的数据比开源数据集有更多轮的对话，并且更长。&lt;br&gt;
　　奖励模型将模型回复和对应的提示（包括之前的多轮上下文）作为输入，输出一个标量分数来衡量模型生成质量。将这些分数作为奖励，通过RLHF优化LLAMA 2-CHAT获得更好的效果，提升有用性和安全性。
　　有用性和安全性往往需要折中，所以本文训练了两个分开的奖励模型，一个用来优化可用性（Helpfulness RM），一个用来优化安全性（Safety RM）。&lt;br&gt;
　　本文使用预训练对话模型checkpoint来初始化奖励模型，这样可以确保所有的模型从预训练中得到知识。除了将下一个token预测分类头替换为一个标量奖励值的回归头输出以外，模型架构和超参数和预训练模型一致。&lt;/p&gt;
$$L_{ranking}=-log(\sigma(r_\theta(x, y_c)-r_\theta(x,y_r)))$$$$L_{ranking}=-log(\sigma(r_\theta(x, y_c)-r_\theta(x,y_r) - m(r)))$$&lt;p&gt;
　　其中，$m(r)$是评分的离散函数，两个回答越不同，这个边距越大，两个回答越相似，这个边距越近。这个边距可以提升有用性。&lt;/p&gt;
&lt;p&gt;　　训练细节：训了一轮，本文发现训久了过拟合。&lt;/p&gt;
&lt;p&gt;　　本文采用了两种主要的RLHF微调算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PPO(Proximal Policy Optimization)算法&lt;/li&gt;
&lt;li&gt;拒绝采用微调(Rejection Sampling fine-tuning)，只在70B上用了
在K个模型输出中使用奖励模型选择最好的，将选择出来的做梯度更新。对于每个提示，包含最好奖励分数的样本作为新的标准。然后在新的样本中微调，加强奖励。
两个算法主要在广度和深度上有区别。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;多轮对话一致性的系统信息&#34;&gt;多轮对话一致性的系统信息
&lt;/h3&gt;&lt;p&gt;有些指令应该贯穿对话始终，比如“扮演xx”指令，但是原始的RLHF模型在几轮后会忘记初始指令。为此，提出Ghost注意力（GAtt）。&lt;/p&gt;
&lt;h1 id=&#34;llama-open-and-efficient-foundation-language-models&#34;&gt;LLaMA: Open and Efficient Foundation Language Models
&lt;/h1&gt;&lt;p&gt;Meta AI
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2302.13971.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/facebookresearch/llama&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述
&lt;/h2&gt;&lt;p&gt;　　不像Chinchilla、PaLM或者GPT-3，只使用公开可用的数据训练。
　　训练不是最快的，但是推理是最快的。
　　本文目标是打造一系列用更多token训练的最佳推理性能的大模型。LLaMA：6.7B、13.0B、32.5B、65.2B
　　LLaMA-13B超过GPT3。
　　LLaMA-65B与Chinchilla或PaLM-540B相当。&lt;/p&gt;
&lt;h2 id=&#34;方法-1&#34;&gt;方法
&lt;/h2&gt;&lt;h3 id=&#34;预训练数据&#34;&gt;预训练数据
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;English CommonCrawl(67%)：使用fastText去掉非英语文本、使用一个n-gram语言模型去掉低质量内容、用一个线性模型对维基百科中用作参考文献的页面与随机抽样的页面以及未归类为参考文献的废弃页面进行分类&lt;/li&gt;
&lt;li&gt;C4(15%)：与CCNet的主要区别是质量过滤，它主要依赖于启发式，如标点符号的存在或网页中的单词和句子的数量&lt;/li&gt;
&lt;li&gt;Github(4.5%):基于行长度或字母数字字符比例的启发式法过滤低质量文件&lt;/li&gt;
&lt;li&gt;Wikipedia(4.5%)&lt;/li&gt;
&lt;li&gt;Gutenberg and Book3(4.5%)：去掉了有90%重复的书籍&lt;/li&gt;
&lt;li&gt;ArXiv(2.5%):删除了第一部分之前的所有内容、参考书目、.tex文件中的评论、用户编写的内联扩展定义和宏&lt;/li&gt;
&lt;li&gt;Stack Exchange(2%)：问答数据，删除了文本中的HTML标签，并根据分数对答案进行了排序(由高到低)&lt;br&gt;
　　分词：BPE算法&lt;br&gt;
　　整个训练集经分词后有1.4T个token(33B和65B)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;架构&#34;&gt;架构
&lt;/h3&gt;&lt;p&gt;　　transformer架构基础上魔改。&lt;br&gt;
　　魔改点（中括号内为灵感来源）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预归一化[GPT3]：使用RMSNorm&lt;/li&gt;
&lt;li&gt;SwiGLU激活函数[PaLM]&lt;/li&gt;
&lt;li&gt;旋转embedding[GPTNeo]：将绝对位置编码换成了旋转位置嵌入RoPE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　优化器：AdamW&lt;/p&gt;
&lt;p&gt;　　训练速度优化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机多头注意力机制，不保存注意力权重，不计算key/query分数（masked）&lt;/li&gt;
&lt;li&gt;减少了反向传播中重复计算的激活单元的数量，只保存最耗费计算的单元，比如线性层的输出；没有使用PyTorch autograd；使用了模型和序列并行化减少模型内存占用；尽量将激活单元的计算和GPU之间的网络通信通用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　训练时间：&lt;br&gt;
　　65B参数模型：2048张A100 GPU，80GB内存，380 tokens/sec/GPU，1.4T tokens训练了21天&lt;/p&gt;
&lt;p&gt;　　它甚至还写了LLAMA的碳排放情况&amp;hellip;&lt;/p&gt;</description>
        </item>
        <item>
        <title>InstructGPT笔记</title>
        <link>https://hubojing.github.io/kte2ngfx/</link>
        <pubDate>Tue, 14 Mar 2023 21:05:47 +0000</pubDate>
        
        <guid>https://hubojing.github.io/kte2ngfx/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/假装有图片.jpg&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;简记。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文概况&#34;&gt;论文概况
&lt;/h1&gt;&lt;p&gt;Training language models to follow instructions with human feedback&lt;/p&gt;
&lt;p&gt;根据人类反馈指示来训练语言模型&lt;/p&gt;
&lt;p&gt;OpenAI 2022&lt;/p&gt;
&lt;h1 id=&#34;核心&#34;&gt;核心
&lt;/h1&gt;&lt;p&gt;该系统包含主要三个步骤实现：&lt;/p&gt;
&lt;p&gt;1、使用一组广泛分布的互联网数据对GPT-3模型进行预训练。然后，针对典型的一组human prompts，让laber写下正确的答案并用这组12,725的监督数据对模型进行精调；&lt;/p&gt;
&lt;p&gt;2、随机选择一组human prompts，并用模型对每个prompt产生多个输出的答案。让labeler对这些回答进行排序，并根据排序训练一个奖励模型 （reward model）。这组用来训练reward model的数据包含有33,207个prompts以及在不同回答组合下产生的10倍于此的答案；&lt;/p&gt;
&lt;p&gt;3、再次随机采样human prompts，并基于PPO的强化学习算法（Proximal Policy Optimization Algorithm）对监督训练后精调过的模型进行再次fine-tune。每个采样的prompt输入PPO模型，并用reward model给出的奖励信号用31,144个prompts对模型进行训练。&lt;/p&gt;</description>
        </item>
        <item>
        <title>命名实体识别（NER）论文泛读</title>
        <link>https://hubojing.github.io/9tdsnz5r/</link>
        <pubDate>Wed, 08 Mar 2023 23:54:02 +0000</pubDate>
        
        <guid>https://hubojing.github.io/9tdsnz5r/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/假装有图片.jpg&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;spanbert&#34;&gt;SpanBert
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00300/1923170/tacl_a_00300.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;global-pointer-novel-efficient-span-based-approach-for-named-entity-recognition&#34;&gt;Global Pointer: Novel Efficient Span-based Approach for Named Entity Recognition
&lt;/h1&gt;&lt;p&gt;2022-12-11阅读&lt;/p&gt;
&lt;h2 id=&#34;论文概况&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;苏剑林 2022年8月&lt;/p&gt;
&lt;h1 id=&#34;a-unified-mrc-framework-for-named-entity-recognition&#34;&gt;A Unified MRC Framework for Named Entity Recognition
&lt;/h1&gt;&lt;p&gt;2022-12-07阅读&lt;/p&gt;
&lt;h2 id=&#34;论文概况-1&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;ACL 2020
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1910.11476&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/ShannonAI/mrc-for-flat-nested-ner&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;##笔记
使用MRC（Machine Reading Comprehension）思想，将NER任务转换为MRC任务。它能引入query先验知识，对重叠的NER实体相当于回答不同的问题，所以它能同时解决flat和nested NER问题。&lt;/p&gt;
&lt;h1 id=&#34;named-entity-recognition-as-dependency-parsing&#34;&gt;Named Entity Recognition as Dependency Parsing
&lt;/h1&gt;&lt;p&gt;2022-12-05阅读&lt;/p&gt;
&lt;h2 id=&#34;论文概况-2&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;ACL 2020
&lt;a class=&#34;link&#34; href=&#34;https://aclanthology.org/2020.acl-main.577/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/juntaoy/biaffine-ner&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;以前NER常见模式是BiLSTM+CRF，BiLSTM用于输入编码，CRF用于分类。本文提出一种双仿射模型替代CRF用于分类。
&lt;img src=&#34;https://hubojing.github.io/&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构图&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;boundary-enhanced-neural-spanclassification-for-nested-named-entity-recognition&#34;&gt;Boundary Enhanced Neural SpanClassification for Nested Named Entity Recognition
&lt;/h1&gt;&lt;p&gt;边界增强神经跨度分类用于嵌套命名实体识别&lt;/p&gt;
&lt;p&gt;阅读时间：2022-09-19&lt;/p&gt;
&lt;p&gt;论文概况&lt;/p&gt;
&lt;p&gt;AAAI 2020&lt;/p&gt;
&lt;p&gt;阿里巴巴&lt;/p&gt;
&lt;p&gt;Chuanqi Tan, Wei Qiu, Mosha Chen, Rui Wang, Fei Huang&lt;/p&gt;
&lt;p&gt;问题提出&lt;/p&gt;
&lt;p&gt;针对嵌套命名实体识别，基于span的方法有两个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对所有子序列进行分类在计算上是十分昂贵的，效率低下。&lt;/li&gt;
&lt;li&gt;基于span的方法主要侧重于学习跨度表示，但缺乏明确的边界监督。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为此，本文提出一种边界增强的神经跨度分类模型（BENSC），除了对span进行分类之外，本文还结合一个额外的边界检测任务来预测那些作为实体边界的单词。这两个任务在多任务学习框架下联合训练，通过额外的边界监督增强了跨度表示。被视为实体的span应该在span级别和边界级别都具有高概率。另外，边界检测模型具有生成高质量候选span的能力，大大降低了推理过程中的时间复杂度到几乎线性时间。&lt;/p&gt;
&lt;h2 id=&#34;模型架构&#34;&gt;模型架构
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;chinese-named-entity-recognition-the-state-of-the-art&#34;&gt;Chinese named entity recognition: The state of the art
&lt;/h1&gt;&lt;p&gt;中文命名实体识别：最新技术&lt;/p&gt;
&lt;p&gt;阅读时间：2022-08-11&lt;/p&gt;
&lt;h2 id=&#34;论文概况-3&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;2022年2月 Neurocomputing&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.sciencedirect.com/science/article/pii/S0925231221016581/pdfft?md5=ab00af6205a671b5d2b841acf7111fd0&amp;amp;pid=1-s2.0-S0925231221016581-main.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>关系抽取（RE）论文泛读</title>
        <link>https://hubojing.github.io/nx3rj2gp/</link>
        <pubDate>Tue, 16 Aug 2022 19:37:35 +0000</pubDate>
        
        <guid>https://hubojing.github.io/nx3rj2gp/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/沉醉于知识的芬芳.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;document-level-relation-extraction-with-adaptive-focal-loss-and-knowledge-distillation&#34;&gt;Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation
&lt;/h1&gt;&lt;p&gt;具有自适应焦点损失和知识蒸馏的文档级关系抽取
阅读时间：2022-08-15&lt;/p&gt;
&lt;h2 id=&#34;论文概况&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;ACL 2022
阿里达摩院
Qingyu Tan, Ruidan He, Lidong Bing, Hwee Tou Ng
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2203.10900&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/tonytan48/KD-DocRE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;文档级关系抽取要同时从多个句子中提取关系。本文提出DocRE算法，一个用于文档级别的关系抽取半监督算法，它有三个新组件。第一，用轴向注意力模块学习实体对之间的依赖关系。第二，提出了一个自适应的焦点损失来解决DocRE中类的不平衡问题。最后，利用知识蒸馏来克服人工标注数据与远程监督数据之间的差异。
现有问题：现存的方法关注实体对的句法特征，而忽略了实体对之间的交互作用；目前还没有工作可以直接的解决类的不平衡问题。现存的工作仅仅关注阈值学习来平衡正例和负例，但正例内部的类不平衡问题并没有得到解决；关于将远程监督数据应用于DocRE任务的研究很少。
贡献点：轴向注意力（提升two-hop关系的推理能力）、自适应焦点损失（解决标签分配不平衡的问题，长尾类在总的损失中占比较多）、知识蒸馏（克服标注数据和远程监督数据之间的差异）
&lt;img src=&#34;https://hubojing.github.io/images/KD-DocRE.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;KD-DocRE&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;packed-levitated-marker-for-entity-and-relation-extraction&#34;&gt;Packed Levitated Marker for Entity and Relation Extraction
&lt;/h1&gt;&lt;p&gt;打包悬浮标记用于实体和关系抽取
阅读时间：2022-08-15&lt;/p&gt;
&lt;h2 id=&#34;论文概述&#34;&gt;论文概述
&lt;/h2&gt;&lt;p&gt;ACL 2022
Deming Ye, Yankai Lin, Peng Li, Maosong Sun
清华大学与腾讯微信模式识别中心合作
&lt;a class=&#34;link&#34; href=&#34;https://aclanthology.org/2022.acl-long.337/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/thunlp/PL-Marker&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记-1&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;最近的命名实体识别和关系抽取工作专注于研究如何从预训练模型中获得更好的span表示。然而，许多工作忽略了span之间的相互关系。本文提出了一种基于悬浮标记的span表示方法，在编码过程中通过特定策略打包标记来考虑span之间的相互关系。对于命名实体识别任务，提出了一种面向邻居span的打包策略，以更好地建模实体边界信息。对于关系抽取任务，设计了一种面向头实体的打包策略，将每个头实体以及可能的尾实体打包，以共同建模同头实体的span对。
&lt;img src=&#34;https://hubojing.github.io/images/PL-Marker.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;PL-Marker&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;consistent-representation-learning-for-continual-relation-extraction&#34;&gt;Consistent Representation Learning for Continual Relation Extraction
&lt;/h1&gt;&lt;p&gt;一致表示学习用于连续关系抽取
阅读时间：2022-08-12&lt;/p&gt;
&lt;h2 id=&#34;论文概况-1&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;ACL 2022
Kang Zhao, Hua Xu, Jiangong Yang, Kai Gao
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2203.02721&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/thuiar/CRL&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记-2&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;通过对比学习和回放记忆时的知识蒸馏，提出一种新颖的一致性表示学习方法。使用基于记忆库的监督对比学习来训练每一个新的任务，以使模型高效学习特征表示。为了防止对老任务的遗忘，构造了记忆样本的连续回放，同时让模型保留在知识蒸馏中历史任务之间的关系。
&lt;img src=&#34;https://hubojing.github.io/images/CRL.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;CRL&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;pre-training-to-match-for-unified-low-shot-relation-extraction&#34;&gt;Pre-training to Match for Unified Low-shot Relation Extraction
&lt;/h1&gt;&lt;p&gt;预训练用于匹配统一少样本关系抽取
阅读时间：2022-08-12&lt;/p&gt;
&lt;h2 id=&#34;论文概况-2&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;ACL 2022
Fangchao Liu, Hongyu Lin, Xianpei Han, Boxi Cao, Le Sun
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2203.12274&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/fc-liu/MCMN&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记-3&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;低样本关系抽取旨在少样本甚至零样本场景下的关系抽取。由于低样本关系抽取所包含任务形式多样，传统方法难以统一处理。本文针对这一问题，提出了一种统一的低样本匹配网络：（1）基于语义提示（prompt）范式，构造了从关系描述到句子实例的匹配网络模型；（2）针对匹配网络模型学习，设计了三元组-复述的预训练方法，以增强模型对关系描述与实例之间语义匹配的泛化性。在零样本、小样本以及带负例的小样本关系抽取评测基准上的实验结果表明，该方法能有效提升低样本场景下关系抽取的性能，并且具备了较好的任务自适应能力。
&lt;img src=&#34;https://hubojing.github.io/images/MCMN.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;MCMN&#34;
	
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>兴趣点推荐（POI Recommendation）论文泛读</title>
        <link>https://hubojing.github.io/adedun3u/</link>
        <pubDate>Sun, 14 Aug 2022 22:34:04 +0000</pubDate>
        
        <guid>https://hubojing.github.io/adedun3u/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/沉醉于知识的芬芳.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;hierarchical-multi-task-graph-recurrent-network-for-next-poi-recommendation&#34;&gt;Hierarchical Multi-Task Graph Recurrent Network for Next POI Recommendation
&lt;/h1&gt;&lt;p&gt;分层多任务图循环网络用于下一个兴趣点推荐
阅读时间：2022-08-11&lt;/p&gt;
&lt;h2 id=&#34;论文概况&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;SIGIR2022
Nicholas Lim, Bryan Hooi, See-Kiong Ng,Yong Liang Goh, Renrong Weng, Rui Tan
&lt;a class=&#34;link&#34; href=&#34;https://bhooi.github.io/papers/hmt_sigir22.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;解决问题：数据稀疏（用户-兴趣点矩阵稀疏）
提出HMT-GRN算法，该方法通过在多任务设置中学习不同的低稀疏用户区域矩阵来缓解数据稀疏问题，GRN模块同时对顺序依赖关系和全局时空POI-POI关系进行建模，然后对不同的区域和兴趣点分布采用分层束搜索（HBS），随着空间粒度增加来分层减少搜索空间并且预测下一个兴趣点。本文HBS通过减少搜索空间来提高效率，与穷举法相比速度提升5~7倍。本文还提出了一种新颖的选择层来预测下一个兴趣点用户是否曾经访问过，在个性化和探索之间取得平衡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/HMT-GRN.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;HMT-GRN&#34;
	
	
&gt;
个人备注：把bean search运用在POI推荐中；对于已访问过的POI设置了一个选择概率。&lt;/p&gt;</description>
        </item>
        <item>
        <title>实体链接（EL）论文泛读</title>
        <link>https://hubojing.github.io/7mjmdmcq/</link>
        <pubDate>Sun, 14 Aug 2022 16:26:09 +0000</pubDate>
        
        <guid>https://hubojing.github.io/7mjmdmcq/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/沉醉于知识的芬芳.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;论文泛读不定期更新。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;entity-linking-meets-deep-learning-techniques-and-solutions&#34;&gt;Entity linking meets deep learning: Techniques and solutions
&lt;/h1&gt;&lt;p&gt;实体链接遇到深度学习：技术和解决方法
阅读时间：2022-08-11&lt;/p&gt;
&lt;h2 id=&#34;论文概况&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;2021年 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
CCF-A
Wei Shen, Yuhan Li, Yinan Liu, Jiawei Han,Fellow, IEEE, Jianyong Wang,Fellow, IEEE, Xiaojie Yuan
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2109.12520&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;从三个方面展开：嵌入（Embedding）、特征（Feature）、算法（Algorithm）
Embedding包括字（word）嵌入、Mention嵌入、实体（entity）嵌入、对齐（aligenment）嵌入。
特征包括先验流行度、表面形式相似度、类型相似度、上下文相似度、主题连贯性。
算法包括MLP、基于图的算法、强化学习。
给出了十种广泛使用的实体链接数据集。
未来方向：多源异质文本数据、NER和EL联合、更高级的语言模型、EL模型鲁棒性&lt;/p&gt;
&lt;h1 id=&#34;multilingual-autoregressive-entity-linking&#34;&gt;Multilingual Autoregressive Entity Linking
&lt;/h1&gt;&lt;p&gt;多语言自回归实体链接
阅读时间：2022-08-11&lt;/p&gt;
&lt;h2 id=&#34;论文概况-1&#34;&gt;论文概况
&lt;/h2&gt;&lt;p&gt;2022年3月 Transactions of the Association for Computational Linguistics SCI Q1
Nicola De Cao, Ledell Wu, Kashyap Popat, Mikel Artetxe,Naman Goyal, Mikhail Plekhanov, Luke Zettlemoyer,Nicola Cancedda, Sebastian Riedel1,6, Fabio Petroni
Facebook AI
&lt;a class=&#34;link&#34; href=&#34;https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00460/2004070/tacl_a_00460.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/facebookresearch/GENRE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记-1&#34;&gt;笔记
&lt;/h2&gt;&lt;p&gt;提出mGENRE系统，它是一个用于多语言实体链接问题的序列到序列的系统，用于解析特定语言mention到多语言知识库。对于特定语言的mention，mGENRE以自回归的方式从左到右逐个（left-to-right, token-by-token）标记预测目标实体的名称。自回归公式有效地交叉编码关于字符串和实体名称，用来捕获比标准点积更多的交互。它还可以在大知识库中进行快速搜索，即使对于没出现在mention表中和不用大规模向量索引的mention也是如此。虽然先前的MEL工作对每个实体使用单一表示，但我们匹配尽可能多的多语言的实体名称，这允许利用源输入和目标名称之间的语言连接。此外，在完全没有训练数据的语言的零样本设置中，mGENRE将目标语言视为在预测时被边缘化的潜在变量。这使平均准确度提高了50%以上。
&lt;img src=&#34;https://hubojing.github.io/images/mGENRE.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;mGENRE&#34;
	
	
&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>BERT</title>
        <link>https://hubojing.github.io/nxk7vdtv/</link>
        <pubDate>Tue, 09 Aug 2022 20:59:07 +0000</pubDate>
        
        <guid>https://hubojing.github.io/nxk7vdtv/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/BERT架构图.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;笔记&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;2019年 谷歌 Jacob Devlin
NAACL-HLT会议-NLP顶会
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1810.04805&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
[CODE](GitHub - google-research/bert: TensorFlow code and pre-trained models for BERT)&lt;/p&gt;
&lt;h1 id=&#34;摘要重点&#34;&gt;摘要重点
&lt;/h1&gt;&lt;p&gt;　　BERT(Bidirectional Encoder Rpresentation from Transformers)
　　BERT 旨在通过联合调节所有层的左右上下文，从未标记的文本中预训练深度双向表示。因此，预训练的 BERT 模型可以通过一个额外的输出层进行微调，从而为各种任务（例如问答和语言推理）创建最先进的模型，而无需大量特定任务架构修改。&lt;/p&gt;
&lt;h1 id=&#34;问题提出&#34;&gt;问题提出
&lt;/h1&gt;&lt;p&gt;　　在下游任务中有两种方法使用预训练语言表示模型，一种是基于特征（feature-based）方法，一种是微调（fine-tuning）。本文认为现有技术限制了预训练表示的能力，尤其是微调方法。主要限制是标准语言模型是单向的，这限制了预训练可以使用的架构。例如，在 OpenAI GPT 中，作者使用从左到右的架构，其中每个标记只能关注Transformer的自注意力层中的先前标记。 这样的限制对于句子级任务来说是次优的，并且在将基于微调的方法应用于令牌级任务（例如问答）时可能非常有害，在这些任务中，从两个方向整合上下文至关重要。&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;我们解释了语言表示中双向预训练的重要性。不像之前的模型在预训练中使用双向语言模型，BERT使用掩码语言模型（masked language model）来预训练深度双向表示。也和以前使用从左到右和从右到左LM独立训练再浅层连结的方法不同。&lt;/li&gt;
&lt;li&gt;预训练表示减少了许多特定任务的繁重工程架构。BERT是第一个基于表示模型微调并在一系列句子级别和token级别任务中实现SOTA性能的。&lt;/li&gt;
&lt;li&gt;BERT在11个NLP任务中实现SOTA性能，代码开源。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;相关工作&#34;&gt;相关工作
&lt;/h1&gt;&lt;p&gt;基于特征的无监督方法（如ELMo）、微调无监督方法（如OpenAI GPT）&lt;/p&gt;
&lt;h1 id=&#34;模型架构&#34;&gt;模型架构
&lt;/h1&gt;&lt;p&gt;　　两阶段：预训练+微调。
　　预训练阶段，模型在不同的预训练任务中使用未标注数据训练。
　　微调阶段，首先使用预训练参数初始化，所有的参数使用下游任务中的标注数据进行微调。即使每一个下游任务使用相同的预训练参数初始化，它们还是有单独的微调模型。如图为一个问答示例。
&lt;img src=&#34;https://hubojing.github.io/images/BERT%e6%9e%b6%e6%9e%84%e5%9b%be.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;BERT&#34;
	
	
&gt;
　　记层数（Transformer块）为L，隐藏层为H，自注意力头数量为A。实验有两种模型规模：一种是$BERT_{BASE}$（L=12，H=768，A=12，总参数为110M）；另一种是$BERT_{LARGE}$（L=24，H=1024，A=16，总参数为340M）。
　　为压缩目的，$BERT_{BASE}$选择了和Open AI一样的模型规模。但是BERT Transformer使用了双向自注意力，GPT Transformer使用的是受限的自注意力，它的每个token只能获取它左边的上下文。
　　每一个token都以[CLS]开头。句子对会一起打包到一个序列中，分割句子使用两种方式。一是使用token[SEP]，二是在每个token中加入一个学习过的embedding表示它属于句子A还是句子B。如图1所示，输入embedding记为E，最后隐藏向量的[CLS]记为C，第i个输入token的最后的隐藏向量记为$T_i$。
对于给定的标记，其输入表示是通过对相应的标记、段和位置嵌入求和来构建的。这种结构的可视化可以在图2中看到。
&lt;img src=&#34;https://hubojing.github.io/images/BERT%e8%be%93%e5%85%a5%e8%a1%a8%e7%a4%ba.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;BERT输入表示&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;预训练bert&#34;&gt;预训练BERT
&lt;/h2&gt;&lt;h3 id=&#34;任务1masked-lm&#34;&gt;任务1：Masked LM
&lt;/h3&gt;&lt;p&gt;　　随机掩盖掉部分输入的tokens，然后预测这些被掩盖的tokens。这个过程记为“masked LM”(MLM)，类似于文学里的完形填空。与掩码标记对应的最终隐藏向量被送到词汇表上的softmax输出，就像在标准 LM 中一样。本文选择15%的tokens进行掩盖。由于[MASK] token在微调阶段不存在，所以预训练阶段和微调阶段不匹配。为了减轻影响，当选中第i个token时，按三条规则进行掩码：
（1） 80%时间使用[MASK] token
（2）10%时间选择随机token
（3）10%时间token不变
然后，使用交叉熵损失和$T_i$预测原始token。&lt;/p&gt;
&lt;h3 id=&#34;任务2下一个句子预测nsp&#34;&gt;任务2：下一个句子预测（NSP）
&lt;/h3&gt;&lt;p&gt;　　问答QA和自然语言推理（NLI）都是基于对两个句子关系的理解做的，而语言模型不能直接捕捉它。为了训练一个能理解句子关系的模型，我们预先训练一个二值化的下一个句子预测任务，该任务可以从任何单语语料库中轻松生成。在之前的工作中，只有句子嵌入被转移到下游任务， BERT 转移所有参数来初始化最终任务模型参数。&lt;/p&gt;
&lt;h2 id=&#34;微调bert&#34;&gt;微调BERT
&lt;/h2&gt;&lt;p&gt;　　微调很简单，因为Transformer中的自注意力机制允许 BERT 通过交换适当的输入和输出来对许多下游任务进行建模——无论它们涉及单个文本还是文本对。对于涉及文本对的应用程序，一种常见的模式是在应用双向交叉注意力之前独立编码文本对。BERT使用自我注意力机制来统一这两个阶段，因为使用自我注意对连接的文本对进行编码有效地包括了两个句子之间的双向交叉注意力。
　　对于每个任务，我们只需将任务特定的输入和输出插入BERT，端到端微调所有参数。&lt;/p&gt;</description>
        </item>
        <item>
        <title>TEMN</title>
        <link>https://hubojing.github.io/wpzth4rk/</link>
        <pubDate>Sun, 03 Jul 2022 13:03:28 +0000</pubDate>
        
        <guid>https://hubojing.github.io/wpzth4rk/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/TEMN架构图.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;陆续上架前几个月写的库存&lt;/strong&gt;
　　&lt;strong&gt;主题增强记忆网络个性化兴趣点推荐&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Topic-Enhanced Memory Networks for Personalised Point-of-Interest Recommendation
　　主题增强记忆网络个性化兴趣点推荐
　　KDD 2019
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1905.13127.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/XiaoZHOUCAM/TEMN&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　关键词：推荐系统；神经网络；主题建模&lt;/p&gt;
&lt;h1 id=&#34;问题提出&#34;&gt;问题提出
&lt;/h1&gt;&lt;p&gt;　　现有问题：数据稀疏；现有算法使用一个单一向量刻画用户偏好限制了表达和可解释性。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;　　Topic-Enhanced Memory Network (TEMN)
　　TEMN是一个统一的混合模型，利用TLDA和外部记忆网络以及神经注意机制来捕捉用户的全局和细粒度偏好。
&lt;img src=&#34;https://hubojing.github.io/images/TEMN%e6%9e%b6%e6%9e%84%e5%9b%be.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;TEMN&#34;
	
	
&gt;
　　三部分组成：记忆网络，TLDA和地理建模部分。
　　前两部分相互联系，用于建模从基于领域的记忆网络中学到的非线性交互（通过历史记录）以及从主题模型中学到的全局偏好。&lt;/p&gt;
&lt;p&gt;　　每一部分分别对应不同的损失函数，进行联合训练。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;h2 id=&#34;数据集&#34;&gt;数据集
&lt;/h2&gt;&lt;p&gt;　　微信朋友圈签到数据集（未开源）
&lt;img src=&#34;https://hubojing.github.io/images/TEMN%e6%95%b0%e6%8d%ae%e9%9b%86.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;MF&lt;/li&gt;
&lt;li&gt;BPR&lt;/li&gt;
&lt;li&gt;LDA&lt;/li&gt;
&lt;li&gt;CML&lt;/li&gt;
&lt;li&gt;LRML&lt;/li&gt;
&lt;li&gt;TEMN(GPR) 保留了记忆模块，将TLDA替换为LDA，去掉了地理模块。&lt;/li&gt;
&lt;li&gt;LORE&lt;/li&gt;
&lt;li&gt;ST-RNN&lt;/li&gt;
&lt;li&gt;TEMN(SPR) 完整TEMN模型使用微信（SPR）数据&lt;/li&gt;
&lt;li&gt;GeoMF&lt;/li&gt;
&lt;li&gt;TLDA&lt;/li&gt;
&lt;li&gt;TEMN(CPR) 完整TEMN模型使用微信（GPR）数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性能&#34;&gt;性能
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/TEMN%e6%80%a7%e8%83%bd.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;提出一种融合基于领域和全局的用户偏好的端到端深度学习框架。&lt;/li&gt;
&lt;li&gt;在兴趣点推荐中设计了能融合多种上下文信息的灵活架构，并使之能在多种推荐场景应用。&lt;/li&gt;
&lt;li&gt;提出一种结合监督和非监督学习的混合模型，并利用了记忆网络和主题模型。通过相互学习机制，模型还能得出用户在受记忆网络影响的主题上的概率分布。&lt;/li&gt;
&lt;li&gt;在微信数据集上进行模型验证，超过基线模型。&lt;/li&gt;
&lt;li&gt;通过在TEMN中引入神经注意机制和主题模型，POI推荐的可解释性得到了显著提高。&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        <item>
        <title>LSTPM</title>
        <link>https://hubojing.github.io/mnykvgbq/</link>
        <pubDate>Fri, 25 Feb 2022 15:59:46 +0000</pubDate>
        
        <guid>https://hubojing.github.io/mnykvgbq/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/LSTPM架构.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation&lt;/strong&gt;
　　下一步去哪儿：用户长短期偏好建模用于兴趣点推荐&lt;/p&gt;
&lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Where to Go Next: Modeling Long- and Short-Term User Preferences for Point-of-Interest Recommendation
　　下一步去哪儿：用户长短期偏好建模用于兴趣点推荐
　　AAAI 2020
　　&lt;a class=&#34;link&#34; href=&#34;https://ojs.aaai.org/index.php/AAAI/article/view/5353&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
　　&lt;a class=&#34;link&#34; href=&#34;https://github.com/NLPWM-WHU/LSTPM&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CODE&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;问题提出&#34;&gt;问题提出
&lt;/h1&gt;&lt;p&gt;　　现有的基于RNN的方法在对用户的短期偏好建模时，要么忽略了用户的长期偏好，要么忽略了最近访问的兴趣点之间的地理关系，从而使得推荐结果不可靠。（所有基于RNN/LSTM的短期偏好建模方法都存在不能对两个非连续兴趣点之间的关系建模的缺点。）
　　为此，提出LSTPM（Long- and Short-Term Preference Modeling）架构。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e6%9e%b6%e6%9e%84.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　它包含三个部分：长期偏好建模、短期偏好建模和预测模块。&lt;/p&gt;
&lt;h2 id=&#34;长期偏好建模&#34;&gt;长期偏好建模
&lt;/h2&gt;&lt;p&gt;　　核心：使用非局部神经操作（nonlocal neural operation）建模长期偏好。
　　以前的做法是直接用LSTM建模签到序列，但是对时间戳的认识不够深。比如人们会在中午时间去餐馆，在晚上去酒吧。所以本文提出了融合时间戳去捕捉时间敏感的属性。论文将一周分成48个段slot（24个工作日段和24个周末段）。计算每两个时间段之间用户签到的兴趣点集合相似性。重合的兴趣点越多，相似性越高。
　　所以历史签到轨迹就可以用这些时间段的兴趣点来表示，从而可以给这些时间段加权重。时间越近影响越大。
　　同时，地理方面计算了各轨迹的中心，计算中心与最近轨迹相似度，得出距离加权公式。&lt;/p&gt;
$$y_i = \frac{1}{C(x)}\sum{_{\forall j}f(x_i, x_j)g(x_j)}$$&lt;p&gt;
　　&lt;code&gt;f&lt;/code&gt;用来度量输出位置和周围其他位置的尺度（例如相似度），&lt;code&gt;g&lt;/code&gt;是在位置j对于输入信号的表示（如卷积操作）。对于non-local behaiver来说，上式中的&lt;code&gt;j&lt;/code&gt;是取遍所有可能的邻居，而对于local操作，如3*3的卷积来说，&lt;code&gt;j&lt;/code&gt;只是取了周围8个像素点。
　　所以这里借鉴这个思想，将每个轨迹S都和历史轨迹和当前轨迹进行了分数计算，并除以标准化因素（全部特征求和）。&lt;/p&gt;
&lt;h2 id=&#34;短期偏好建模&#34;&gt;短期偏好建模
&lt;/h2&gt;&lt;p&gt;　　核心：使用联合方式的地理扩张LSTM建模短期偏好。
　　RNN本身只能用于序列建模，所以有人提出了跳步RNN。但是跳步RNN总是事先定义好和固定好的。所以提出geo-dilated LSTM根据地理和时间因素，来自动决定使用哪些相关输入。
&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e6%9e%b6%e6%9e%842.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;geo-dilated LSTM&#34;
	
	
&gt;
　　直观地，我们的地理扩张LSTM首先从当前轨迹中挑选poi作为输入，其具有由地理相关性确定的不同跳跃长度，然后通过扩展LSTM方案学习短期用户偏好。具体的算法论文给出了伪代码。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;关键理解&lt;/strong&gt;：那它究竟是怎么自动确定跳跃长度的呢？
　　如上图所示，标准的LSTM序列是从l1-&amp;gt;l2-&amp;gt;l3-&amp;gt;l4-&amp;gt;l5。但是加入地理距离后发现，对于l3的前面两个兴趣点l1和l2来说，l1到l3的距离比l1到l2的距离要近，所以留下{l1, l2}路径。依次类推，留下{l1, l2}{l2, l5}路径，也就是两跳。所以，将LSTM设计为两跳。&lt;/p&gt;
&lt;p&gt;　　最后的表示，是标准LSTM和geo-dilated LSTM的平均向量。&lt;/p&gt;
&lt;h2 id=&#34;预测&#34;&gt;预测
&lt;/h2&gt;&lt;p&gt;　　将长短期偏好联结起来，设置一个W全部兴趣点的可训练投影矩阵参数。预测的是下一个时间段t内目标用户最可能访问的兴趣点。损失函数是负对数似然函数。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;h2 id=&#34;数据集&#34;&gt;数据集
&lt;/h2&gt;&lt;p&gt;　　Foursqure, Gowalla&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM_datasets.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;LSTM&lt;/li&gt;
&lt;li&gt;Time-LSTM&lt;/li&gt;
&lt;li&gt;ST-RNN&lt;/li&gt;
&lt;li&gt;TMCA&lt;/li&gt;
&lt;li&gt;CARA&lt;/li&gt;
&lt;li&gt;DCRF&lt;/li&gt;
&lt;li&gt;DeepMove&lt;/li&gt;
&lt;li&gt;STGN&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;评价指标&#34;&gt;评价指标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;召回率Recall&lt;/li&gt;
&lt;li&gt;NDCG&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性能&#34;&gt;性能
&lt;/h2&gt;&lt;h3 id=&#34;基线对比&#34;&gt;基线对比
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e6%80%a7%e8%83%bd.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;消融实验&#34;&gt;消融实验
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e8%87%aa%e8%ba%ab%e5%af%b9%e6%af%94.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;消融实验&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;参数分析&#34;&gt;参数分析
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM%e5%8f%82%e6%95%b0%e5%88%86%e6%9e%90.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;参数分析&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;跳数自动化&#34;&gt;跳数自动化
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/LSTPM_LSTM%e5%af%b9%e6%af%94.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;LSTM对比&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;提出LSTPM框架解决上述存在的问题。&lt;/li&gt;
&lt;li&gt;LSTPM受非局部操作（nonlocal operations）和dilated RNNs的启发，在构建长期偏好时，设计了非局部操作网络结构来探索历史和最近轨迹的时空联系。在克服RNN在短期用户偏好建模的限制时，提出geo-dilated RNN来全面探索非连续兴趣点间的地理联系。&lt;/li&gt;
&lt;li&gt;在真实世界数据集上效果超过SOTA模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;参考资料&#34;&gt;参考资料
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/py184473894/article/details/85322937&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/py184473894/article/details/85322937&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/85776086&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/85776086&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>ASGNN</title>
        <link>https://hubojing.github.io/gwmprssu/</link>
        <pubDate>Sat, 29 Jan 2022 14:27:42 +0000</pubDate>
        
        <guid>https://hubojing.github.io/gwmprssu/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-1.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;Attentive sequential model based on graph neuralnetwork for next poi recommendation&lt;/strong&gt;
　　基于图神经网络的注意力序列模型用于下一个兴趣点推荐&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Attentive sequential model based on graph neuralnetwork for next poi recommendation
　　基于图神经网络的注意力序列模型用于下一个兴趣点推荐
　　WWW21
&lt;a class=&#34;link&#34; href=&#34;https://link.springer.com/content/pdf/10.1007/s11280-021-00961-9.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;
　　关键词：推荐系统、序列推荐、兴趣点推荐、图神经网络、注意力机制&lt;/p&gt;
&lt;h1 id=&#34;现有问题&#34;&gt;现有问题
&lt;/h1&gt;&lt;p&gt;　　传统推荐方法忽略了用户短时偏好的动态变化。另外，许多现有方法不能完全探索兴趣点签到序列中复杂的联系和转变形式。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;　　提出ASGNN。
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　ASGNN包括四部分：兴趣点签到序列图构建、特征表示学习、长短时偏好获取、兴趣点推荐&lt;/p&gt;
&lt;h2 id=&#34;兴趣点签到序列图构建&#34;&gt;兴趣点签到序列图构建
&lt;/h2&gt;&lt;p&gt;　　G(V, E), V = (U, L)，U是用户集，L是兴趣点集。E包括用户-兴趣点边和兴趣点-兴趣点边。
　　图中边的权重代表用户在兴趣点的签到次数。&lt;/p&gt;
&lt;h2 id=&#34;特征表示学习&#34;&gt;特征表示学习
&lt;/h2&gt;&lt;p&gt;　　图构建好后，使用GNN学习到用户和兴趣点的低维表示。这避免了马尔科夫决策过程需要的大量状态。
　　为了提高效率更新节点，使用了GGNN。
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;矩阵表示&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;长短时偏好获取&#34;&gt;长短时偏好获取
&lt;/h2&gt;&lt;p&gt;　　设计了两层注意力机制分别捕获长短时用户偏好。&lt;/p&gt;
&lt;h2 id=&#34;兴趣点推荐&#34;&gt;兴趣点推荐
&lt;/h2&gt;&lt;p&gt;　　上一步得到的个性化用户偏好参数和兴趣点特征点乘，得到每个兴趣点分数，通过softmax标准化输出概率值。
　　训练的损失函数为交叉熵函数。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;p&gt;　　围绕下列问题展开：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ASGNN在序列兴趣点推荐任务上性能如何（基线对比）&lt;/li&gt;
&lt;li&gt;ASGNN的关键组件效果如何（组件实验）&lt;/li&gt;
&lt;li&gt;ASGNN的嵌入维度对推荐的影响（维度分析）&lt;/li&gt;
&lt;li&gt;ASGNN和基线在不同稀疏性的数据集上的性能如何（数据稀疏性影响）&lt;/li&gt;
&lt;li&gt;ASGNN学习兴趣点嵌入是否有效（可视化说明）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据集&#34;&gt;数据集
&lt;/h2&gt;&lt;p&gt;　　Gowalla, FourSquare, Brightkite
&lt;a class=&#34;link&#34; href=&#34;https://snap.stanford.edu/data/loc-gowalla.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://snap.stanford.edu/data/loc-gowalla.html&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://sites.google.com/site/yangdingqi/home/foursquare-dataset&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://sites.google.com/site/yangdingqi/home/foursquare-dataset&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://snap.stanford.edu/data/loc-brightkite.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://snap.stanford.edu/data/loc-brightkite.html&lt;/a&gt;
&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;POP&lt;/li&gt;
&lt;li&gt;BPR&lt;/li&gt;
&lt;li&gt;FPMC&lt;/li&gt;
&lt;li&gt;HRM&lt;/li&gt;
&lt;li&gt;CPAM&lt;/li&gt;
&lt;li&gt;SHAN&lt;/li&gt;
&lt;li&gt;SRGNN&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;评测指标&#34;&gt;评测指标
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;召回率Recall&lt;/li&gt;
&lt;li&gt;MRR&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;基线对比&#34;&gt;基线对比
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;组件实验&#34;&gt;组件实验
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;组件分析&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;维度分析&#34;&gt;维度分析
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;维度分析&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据稀疏性影响&#34;&gt;数据稀疏性影响
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;不同数据集&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;可视化说明&#34;&gt;可视化说明
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/ASGNN-RQ5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;可视化&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;提出ASGNN，它将用户签到行为视为图，并使用GNN局部方式学习用户行为模式和他们的偏好用于下一个兴趣点推荐。&lt;/li&gt;
&lt;li&gt;设计了一个个性化层级注意力机制捕捉用户长短时偏好，并将它们适应于序列推荐。&lt;/li&gt;
&lt;li&gt;实验结果显示ASGNN超过基线和部分SOTA模型。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/HduDBSI/ASGNN&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/HduDBSI/ASGNN&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>STAN</title>
        <link>https://hubojing.github.io/fhfxfwzp/</link>
        <pubDate>Mon, 24 Jan 2022 11:20:37 +0000</pubDate>
        
        <guid>https://hubojing.github.io/fhfxfwzp/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\STAN-2.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;STAN: Spatio-Temporal Attention Network for Next Location Recommendation&lt;/strong&gt;
　　STAN：基于时空注意力网络的下一个兴趣点推荐&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　STAN: Spatio-Temporal Attention Network for Next Location Recommendation
　　STAN：基于时空注意力网络的下一个兴趣点推荐
　　WWW 21
　　&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2102.04095.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;现有问题&#34;&gt;现有问题
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;引入&#34;
	
	
&gt;
　　0、1、2分别代表家、工作地、商场，3、4、5、6分别代表餐馆。虽然3、4、5、6时间和空间都不连续，但它们是有关联的。现有文献很少关注这种非相邻位置和非连续签到的情况。&lt;/p&gt;
&lt;h1 id=&#34;说明和定义&#34;&gt;说明和定义
&lt;/h1&gt;&lt;p&gt;　　用户U=${u_1, u_2, &amp;hellip;, u_U}$
　　兴趣点L=${l_1, l_2, &amp;hellip;, l_L}$
　　时间T=${t_1, t_2, &amp;hellip;, t_T}$&lt;/p&gt;
&lt;p&gt;　　用户轨迹$tra(u_i) = (r_1, r_2, &amp;hellip;, r_{m_i})$&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　STAN包括多模态嵌入模块、一个自注意力聚合层、一个注意力匹配层、一个平衡采样器。&lt;/p&gt;
&lt;h2 id=&#34;多模态嵌入模块&#34;&gt;多模态嵌入模块
&lt;/h2&gt;&lt;p&gt;　　该模块分为两部分：轨迹嵌入层和时空嵌入层。&lt;/p&gt;
&lt;h3 id=&#34;用户轨迹嵌入层&#34;&gt;用户轨迹嵌入层
&lt;/h3&gt;&lt;p&gt;　　使用了用户、地理位置、时间，嵌入向量记为$e^u$、$e^l$、$e^t$。时间戳被分为7*24=168个维度。所以，$e^u$、$e^l$、$e^t$的维度是U，L和168。
　　输出$e^r = e^u + e^l + e^t$&lt;/p&gt;
&lt;h3 id=&#34;时空嵌入层&#34;&gt;时空嵌入层
&lt;/h3&gt;&lt;p&gt;　　创造了两种矩阵，轨迹时空关系矩阵$△^{t, s}$和候选关系矩阵$N^{t, s}$。前者将两个轨迹间的时间差和地理距离作为关联信息，后者将轨迹中的兴趣点与候选集中可能的预测兴趣点采用同样的信息关联起来。使用线性插值方法。
　　这一层将这两种矩阵进行映射和求和，得到最终的嵌入表示E(△)和E(N)。&lt;/p&gt;
&lt;h2 id=&#34;自注意力聚合层&#34;&gt;自注意力聚合层
&lt;/h2&gt;&lt;p&gt;　　这一层是用来考虑轨迹中有不同距离和时间间隔的两次兴趣点签到的关联程度的。自注意力层可以捕捉长时依赖并为轨迹中的兴趣点分配不同的权重。将轨迹E(u)和时空关系矩阵E(△)通过自注意力聚合层，计算得到新的序列S表示。&lt;/p&gt;
&lt;h2 id=&#34;注意力匹配层&#34;&gt;注意力匹配层
&lt;/h2&gt;&lt;p&gt;　　这一层的作用是根据用户轨迹的最新表示在L中召回最合适的兴趣点候选。
　　A(u) = Matching(E(l), S(u), E(N))，得到的是概率。
　　$Matching(Q, K, N) = Sum(softmax(\frac{QK^T+N}{\sqrt{d}}))$
　　这个公式减少了其它自注意力模型中的PIF信息。&lt;/p&gt;
&lt;h2 id=&#34;平衡采样器&#34;&gt;平衡采样器
&lt;/h2&gt;&lt;p&gt;　　因为正负样本不均衡，优化交叉熵损失不再有用。本文修改了交叉熵损失公式中负样本数量，对于每个正样本$a_k$，需要同时计算L-1个负样本，这称为作为平衡采样器。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据&#34;
	
	
&gt;
　　数据集：Gowalla, SIN, TKY, NYC.
　　输入：$(u_i, l_k, t_k)$, $(l_k, lon_k, lat_k)$
　　输出：候选兴趣点概率值&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;STRNN&lt;/li&gt;
&lt;li&gt;DeepMove&lt;/li&gt;
&lt;li&gt;STGN&lt;/li&gt;
&lt;li&gt;ARNN&lt;/li&gt;
&lt;li&gt;LSTPM&lt;/li&gt;
&lt;li&gt;TiSARec&lt;/li&gt;
&lt;li&gt;GeoSAN&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性能&#34;&gt;性能
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cSTAN-4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;提出STAN，一种时空双向注意力模型，全面考虑了聚合相关联位置的时空效应。第一个将非相邻位置和非相邻签到时间的兴趣点的时空联系应用在兴趣点推荐中。&lt;/li&gt;
&lt;li&gt;使用简单的线性插值技术替代GPS网格进行空间离散化，它能恢复空间距离和反映时空偏好，而不仅仅是聚合邻居。&lt;/li&gt;
&lt;li&gt;提出了一种双向注意力架构用于PIF（personalized item frequency），第一层聚合了轨迹信息中相关的兴趣点用于更新表示，那么第二层就可以给全部的签到信息匹配目标。&lt;/li&gt;
&lt;li&gt;在四个真实世界数据集上性能比SOTA模型超过10%。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/yingtaoluo/Spatial-Temporal-Attention-Network-for-POI-Recommendation&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/yingtaoluo/Spatial-Temporal-Attention-Network-for-POI-Recommendation&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>CHAML</title>
        <link>https://hubojing.github.io/pd2tgrcn/</link>
        <pubDate>Sat, 22 Jan 2022 18:02:37 +0000</pubDate>
        
        <guid>https://hubojing.github.io/pd2tgrcn/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\CHAML-2.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;Curriculum Meta-Learning for Next POI Recommendation&lt;/strong&gt;
　　基于课程元学习的下一个兴趣点推荐&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　Curriculum Meta-Learning for Next POI Recommendation
　　基于课程元学习的下一个兴趣点推荐
　　KDD 21
　　&lt;a class=&#34;link&#34; href=&#34;https://dl.acm.org/doi/abs/10.1145/3447548.3467132&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;现有问题&#34;&gt;现有问题
&lt;/h1&gt;&lt;p&gt;　　在下一个兴趣点推荐的研究中，在有限的用户-兴趣点交互数据下，在冷启动城市中提供满意的推荐是重要问题，这需要许多其它城市丰富数据下隐含的知识进行迁移。现有文献没有考虑到城市转移的问题或者不能同时处理数据稀疏和用户在多个城市的模式多样性的问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cCHAML-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;问题描述&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;　　问题描述如图所示。
　　该问题关键是提出一个合适的迁移算法，但难点有二：
　　1. 不同城市的数据太少
　　2. 用户在不同城市下有不同的多样性表达
　　现有算法不能同时解决这两个问题。传统的预训练和微调技术不能解决问题2，跨域推荐不能解决问题1。&lt;/p&gt;
&lt;h1 id=&#34;架构&#34;&gt;架构
&lt;/h1&gt;&lt;p&gt;　　提出 Curriculum Hardness Aware Meta-Learning (CHAML) 框架。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cCHAML-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;架构&#34;
	
	
&gt;
　　架构分为两部分，一部分是基础推荐器，另一部分是MAML扩展。后者用于将元学习引入到POI推荐中。
　　两种采用策略组件，一种是硬意识元学习(hardness aware meta-learning)，另一种是城市级别采样课程(city-level sampling curriculum)。这用于细致思考采样多样性问题。
　　一些概念：
　　Curriculum Learning，主张让模型先从容易的样本开始学习，并逐渐进阶到复杂的样本和知识。
　　meta-learning，又叫learning to learn，即学习如何学习，元学习围绕任务（task）展开。元学习是要去学习任务中的特征表示，从而在新的任务上泛化。&lt;/p&gt;
&lt;h2 id=&#34;基础推荐器&#34;&gt;基础推荐器
&lt;/h2&gt;&lt;p&gt;　　使用DIN作为基础推荐器，由三部分组成，嵌入模块（Embedding module）、注意力模块（Attention module）和输出模块（Output module）。&lt;/p&gt;
&lt;h2 id=&#34;元学习&#34;&gt;元学习
&lt;/h2&gt;&lt;p&gt;　　使用MAML策略。
　　MAML论文：Model-agnostic meta-learning for fast adaptation of deep networks&lt;/p&gt;
&lt;p&gt;　　每轮MAML包括两步骤：局部更新和全局更新。见图中左上部分。
　　每一次元学习任务都有支持训练集$D^{spt}$用于训练，query训练集$D^{qry}$用于测试。
　　元学习目标就是学习一个选学习器F，F可以预测推荐器f中的参数$\theta$，使损失函数最小化。&lt;/p&gt;
&lt;h2 id=&#34;硬意识元学习-hardness-aware-meta-learning&#34;&gt;硬意识元学习 Hardness Aware Meta-Learning
&lt;/h2&gt;&lt;p&gt;　　这里的&amp;quot;hardness&amp;quot;是模型在query样本上的现有性能自判的。
　　分为两个阶段，hard_city阶段和hard_user阶段。两个任务交替循环。对应图右上。&lt;/p&gt;
&lt;h2 id=&#34;城市级别采样课程-city-level-sampling-curriculum&#34;&gt;城市级别采样课程 City-level Sampling Curriculum
&lt;/h2&gt;&lt;p&gt;　　见图下方。
　　分为两阶段，一是困难度测量，使用诸如AUC指标来衡量。二是调度器用于城市pool，定义了一个函数g。课程学习使模型有更大的概率在优化过程中选择容易的梯度步骤。&lt;/p&gt;
&lt;h1 id=&#34;实验&#34;&gt;实验
&lt;/h1&gt;&lt;p&gt;　　数据集：百度地图MapSmall、MapLarge（未开源）
　　输入：POI ID, POI category, time, user-POI dist
　　输出：POI预测分数$y^{hat}_i$&lt;/p&gt;
&lt;h2 id=&#34;基线&#34;&gt;基线
&lt;/h2&gt;&lt;p&gt;　　针对POI推荐：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NeuMF&lt;/li&gt;
&lt;li&gt;HGN&lt;/li&gt;
&lt;li&gt;ATST-LSTM&lt;/li&gt;
&lt;li&gt;PLSPL&lt;/li&gt;
&lt;li&gt;iMTL&lt;/li&gt;
&lt;li&gt;DIN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　针对迁移策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No transfer&lt;/li&gt;
&lt;li&gt;Pretrain and Fine-Tune(FT)&lt;/li&gt;
&lt;li&gt;MAML&lt;/li&gt;
&lt;li&gt;$s^2$Meta&lt;/li&gt;
&lt;li&gt;HAML&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;贡献点&#34;&gt;贡献点
&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;第一个探索城市迁移的下一个兴趣点推荐，并将元学习用于该问题。&lt;/li&gt;
&lt;li&gt;提出CHAML框架，通过使用用户和城市级别的硬采样挖掘以及城市级别的课程学习（curriculum learning）增强元学习器，达到同时解决数据稀疏和冷启动城市的样本多样性的问题。&lt;/li&gt;
&lt;li&gt;在两个真实世界地图查找数据集中性能超越SOTA方法。
该框架已在百度地图上进行过A/B测试。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/PaddlePaddle/Research/tree/master/ST_DM/KDD2021-CHAML&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/PaddlePaddle/Research/tree/master/ST_DM/KDD2021-CHAML&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://github.com/victorsoda/chaml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/victorsoda/chaml&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>【Paper】DIN模型</title>
        <link>https://hubojing.github.io/rup2htsf/</link>
        <pubDate>Thu, 06 May 2021 10:55:35 +0000</pubDate>
        
        <guid>https://hubojing.github.io/rup2htsf/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\DIN架构.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;阿里DIN模型&lt;/strong&gt;
　　&lt;strong&gt;10.21总算写完了&amp;hellip;&amp;hellip;&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;论文：Deep Interesting Network for Click-Through Rate Prediction
&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1706.06978&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;下载地址&lt;/a&gt;
2018年 阿里&lt;/p&gt;
&lt;h1 id=&#34;现有问题&#34;&gt;现有问题
&lt;/h1&gt;&lt;p&gt;　　目前的深度学习模型都是先将稀疏输入特征映射为低维嵌入向量，再转换为固定长度的向量，最后联结起来送入MLP。这个固定长度的向量会成为瓶颈，无法从历史行为中捕获用户不同的兴趣。因此，本文提出深度兴趣网络Deep Interest Network（DIN）。它设计了一个局部激活单元从用户历史行为中自适应学习用户兴趣。另外，本文提出了两大技术：小批量感知正则化（mini-batch aware regularization）和数据自适应激活函数（data adaptive activation function）。&lt;/p&gt;
&lt;h1 id=&#34;关键词&#34;&gt;关键词
&lt;/h1&gt;&lt;p&gt;点击率预测（Click-Through Rate Prediction）、展示广告（Display Advertising），线上贸易（E-commerce）&lt;/p&gt;
&lt;h1 id=&#34;引言-introduction&#34;&gt;引言 INTRODUCTION
&lt;/h1&gt;&lt;p&gt;　　Embedding &amp;amp; MLP方法通过将用户行为嵌入向量转换为一个固定长度的向量来学习用户所有兴趣的表示，所有的表示向量是欧式空间。换言之，将用户不同的兴趣压缩到一个固定长度的向量，限制了表达能力。为了更好地表达用户不同兴趣，就要扩展向量长度。这会增多学习参数，并且增加过拟合的风险。也加重了计算和存储的压力，对于工业线上系统来说很困难。
　　另一方面，没有必要把用户全部兴趣压缩到同一个向量里，因为只有部分兴趣会影响用户下一个动作（点击或不点击）。&lt;/p&gt;
&lt;p&gt;　　训练的问题：
　　基于SGD的优化方法只更新出现在每个小批量中的稀疏特征的参数。然而，加上传统的ℓ2正则化，计算变得不可接受，这需要为每个小批量计算整个参数的L2范数(在阿里的场景，大小按比例增加到数十亿)。本文提出了一种新的小批量正则化方法，在L2范数的计算中，每个小批量正则化中只出现非零特征参数，使得计算是可接受的。另外，设计了一个数据自适应激活函数，推广到常用的PReLU，它通过自适应地调整输入的校正点，也就是输入的分布，并被证明有助于训练具有稀疏特征的工业网络。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;贡献点&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;指出了使用固定长度向量来表达用户不同兴趣的局限性，并设计了一种新的深度兴趣网络(DIN)，它引入了一个局部激活单元来自适应地从给定广告的历史行为中学习用户兴趣的表示。DIN可以大大提高模型的表达能力，更好地捕捉用户兴趣的多样性特征。&lt;/li&gt;
&lt;li&gt;开发了两种新的技术来帮助训练工业深度网络:I)一种小批量感知正则化器，这种正则化器在具有大量参数的深度网络上节省了大量的正则化计算，并且有助于避免过拟合；ii)一种数据自适应激活函数，这种函数通过考虑输入的分布来推广PReLU，并且表现出良好的性能。&lt;/li&gt;
&lt;li&gt;在公共数据集和AI-ibaba数据集上进行了大量实验。结果验证了所提出的DIN和训练技术的有效性。所提出的方法已经在全球最大的广告平台之一阿里巴巴的商业展示广告系统中得到了应用，为业务的发展做出了重大贡献。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;代码：https://github.com/zhougr1993/DeepInterestNetwork&lt;/p&gt;
&lt;h1 id=&#34;背景-background&#34;&gt;背景 BACKGROUND
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cDIN-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;图1 - 阿里广告系统&#34;
	
	
&gt;
预测每个给定广告的点击率，然后选择排名最高的广告。&lt;/p&gt;
&lt;h1 id=&#34;深度兴趣网络-deep-interest-network&#34;&gt;深度兴趣网络 DEEP INTEREST NETWORK
&lt;/h1&gt;&lt;h2 id=&#34;特征表示-feature-representation&#34;&gt;特征表示 Feature Representation
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cDIN-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;表1 - 特征处理&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cDIN-%e7%89%b9%e5%be%81%e8%a1%a8%e7%a4%ba.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;特征表示&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;　　表中描述了我们系统中使用的全部特征集，它由四类组成，其中用户行为特征是典型的多热点编码向量，包含丰富的用户兴趣信息。注意，在我们的设置中，没有组合特性。我们利用深度神经网络捕获特征的交互作用。&lt;/p&gt;
&lt;h2 id=&#34;基线模型-base-modelembeddingmlp&#34;&gt;基线模型 Base Model(Embedding&amp;amp;MLP)
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cDIN%e6%9e%b6%e6%9e%84.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;基础架构 vs DIN架构&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;嵌入层（Embedding layer)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;池化层和连接层（Pooling layer and Concat layer）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　得到定长向量：$e_i = pooling(e_{i_1}, e_{i_2}, &amp;hellip;, e_{i_k})$&lt;/p&gt;
&lt;p&gt;　　最常用的是sum pooling和average pooling。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MLP&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loss&lt;/strong&gt;&lt;/p&gt;
$$L = - \frac{1}{N}\sum_{(x,y)∈S}(ylogp(x) + (1 - y)log(1 - p(x)))$$&lt;p&gt;　　S是尺寸为N的训练集，x是输入，y是标签。p(x)是经过softmax层后的输出，代表样本x被点击的概率。&lt;/p&gt;
&lt;h2 id=&#34;din架构-the-structure-of-deep-interest-network&#34;&gt;DIN架构 The structure of Deep Interest Network
&lt;/h2&gt;&lt;p&gt;　　基线模型对一个用户使用定长向量表示，无论候选广告是什么。&lt;/p&gt;
&lt;p&gt;　　为了表示用户兴趣多样化，一种简单的方法是扩展嵌入维度，但这会增加学习参数规模。有过拟合的风险，并且增加了计算和存储的负担。&lt;/p&gt;
&lt;p&gt;　　DIN模拟了关于给定广告的用户局部激活兴趣。&lt;/p&gt;
&lt;p&gt;　　DIN引入了一个用于用户行为特征的局部激活单元，使用了加权求和池化（weighted sum pooling）来自适应计算当给定一个候选广告A时，用户的表示$V_U$。&lt;/p&gt;
$$v_U = f(v_A, e_1, e_2, ..., e_H) = \sum_{j=1}^{H}a(e_j, v_A)e_j = \sum_{j = 1}^{H}w_je_j$$&lt;p&gt;
　　其中，${e_1, e_2, &amp;hellip;, e_H}$是用户U的行为嵌入向量（长度为H），$v_U(A)$是广告A的嵌入向量。
　　在这种方式下，$v_U(A)$在不同的广告下，a(·)是一个带有激活权重输入的前向反馈网络。除了这两部分输入嵌入向量，a(·)将它们的外积喂入后续网络。
a(·)softmax输出后的标准化被舍弃。&lt;/p&gt;
&lt;h1 id=&#34;训练方法-training-techniques&#34;&gt;训练方法 TRAINING TECHNIQUES
&lt;/h1&gt;&lt;h2 id=&#34;小批量感知正则化-mini-batch-aware-regularization&#34;&gt;小批量感知正则化 Mini-batch Aware Regularization
&lt;/h2&gt;&lt;p&gt;　　工业训练网络面临过拟合的问题。模型训练在第一轮训练后（不加正则化）性能迅速下降。传统的正则策略在面对稀疏输入和成千上万的参数时并不适用（比如l2和l1正则化)。
　　为此，提出小批量感知正则化，即只在每次小批量中对稀疏特征的参数计算$L_2-norm$。&lt;/p&gt;
$$L_2(W)=||W||_{2}^{2}$$$$= \sum_{j = 1}^{K}||w_j||_{2}^{2}$$$$= \sum_{(x,y)∈S}\sum_{j = 1}^{K}\frac{I(x_j≠0)}{n_j}||w_j||_2^2$$&lt;p&gt;　　$I(x_j≠0)$表示x有特征j，$n_j$表示特征id j出现的数量。上述公式可以被转换为下面的小批量感知形式：&lt;/p&gt;
$$L_2(W) =  \sum_{j = 1}^{K}\sum_{m = 1}^{B}\sum_{(x,y)∈B_m}\frac{I(x_j≠0)}{n_j}||w_j||_2^2$$&lt;p&gt;　　其中，B表示小批量的数量，$B_m$表示第m次小批量。定义$α_{mj} = max_{(x,y)∈B_m}I(x_j ≠ 0)$为小批量$B_m$中至少有一次有特征id j。
　　上述近似为&lt;/p&gt;
$$L_2(W) ≈ \sum_{j = 1}^{K}\sum_{m = 1}^{B}\frac{α_{mj}}{n_j}||w_j||_2^2$$&lt;p&gt;
　　
通过这种方式，推导出了一种$l_2$正则化的近似小批量感知形式。
　　对于第m次小批量，关于特征j的嵌入权重的梯度为&lt;/p&gt;
$$w_j\leftarrow w_j - \eta[\frac{1}{|B_m|}\sum_{(x,y)∈B_m}\frac{\partial L(p(x), y)}{\partial w_j} + \lambda \frac{α_{mj}}{n_j}w_j]$$&lt;p&gt;
　　
　　在这里只有出现在第m次小批量的特征参数才会参与正则计算。&lt;/p&gt;
&lt;h2 id=&#34;数据自适应激活函数-data-adaptive-activation-function&#34;&gt;数据自适应激活函数 Data Adaptive Activation Function
&lt;/h2&gt;$$f(s) = p(s)·s + (1-p(s))·αs, p(s) = \frac{1}{1 + e^{-\frac{s-E[s]}{\sqrt{Var[s] + \epsilon}}}}$$&lt;p&gt;
　　E[s]和Var[s]代表每次小批量输入的均值和方差。$\epsilon$是一个常量，此处设为$10^{-8}$。
　　Dice的主要思想是根据输入数据分布自适应调整转折点，值设置为输入的平均值。另外，Dice在两个函数间切换很顺滑。当E(s) = 0且Var[s] = 0时，Dice退化到PReLU。&lt;/p&gt;
&lt;h1 id=&#34;实验-experiments&#34;&gt;实验 EXPERIMENTS
&lt;/h1&gt;&lt;h2 id=&#34;数据集和实验步骤-datasets-and-experimental-setup&#34;&gt;数据集和实验步骤 Datasets and Experimental Setup
&lt;/h2&gt;&lt;p&gt;　　数据集三个：Amazon Dataset， MovieLens Dataset和Alibaba Dataset。
　　Amazon Dataset：http://jmcauley.ucsd.edu/data/amazon/
　　MovieLens Dataset：https://grouplens.org/datasets/movielens/20m/
　　数据集情况如图。
&lt;img src=&#34;https://hubojing.github.io/images/DIN-data.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;数据&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;基线实验&#34;&gt;基线实验
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;LR&lt;/li&gt;
&lt;li&gt;BaseModel&lt;/li&gt;
&lt;li&gt;Wide&amp;amp;Deep&lt;/li&gt;
&lt;li&gt;PNN&lt;/li&gt;
&lt;li&gt;DeepFM&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;策略&#34;&gt;策略
&lt;/h2&gt;$$AUC = \frac{\sum_{i = 1}^{n}impression_i \times AUC_i}{\sum_{i = 1}^{n}impression_i}$$$$RelaImpr = (\frac{AUC(measured model) - 0.5}{AUC(base model) - 0.5} - 1) \times 100\%$$&lt;p&gt;
　　RelaImpr用来衡量模型间的相对提升。&lt;/p&gt;
&lt;h2 id=&#34;亚马逊数据集和movielens数据集模型对比结果-result-from-model-comparison-on-amazon-dataset-and-movielens-dataset&#34;&gt;亚马逊数据集和MovieLens数据集模型对比结果 Result from model comparison on Amazon Dataset and MovieLens Dataset
&lt;/h2&gt;&lt;p&gt;　　如图所示。
&lt;img src=&#34;https://hubojing.github.io/images/DIN-F4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;图4&#34;
	
	
&gt;
&lt;img src=&#34;https://hubojing.github.io/images/DIN-T3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;表3&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;正则化性能-performance-of-regularization&#34;&gt;正则化性能 Performance of regularization
&lt;/h2&gt;&lt;p&gt;　　对比试验：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dropout&lt;/li&gt;
&lt;li&gt;Filter&lt;/li&gt;
&lt;li&gt;Regularization in DiFacto&lt;/li&gt;
&lt;li&gt;MBA
&lt;img src=&#34;https://hubojing.github.io/images/DIN-T4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;表4&#34;
	
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;阿里巴巴数据集模型对比结果-result-from-model-comparison-on-alibaba-dataset&#34;&gt;阿里巴巴数据集模型对比结果 Result from model comparison on Alibaba Dataset
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/DIN-T5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;表5&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;din可视化-visualization-of-din&#34;&gt;DIN可视化 Visualization of DIN
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/DIN-F5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;图5&#34;
	
	
&gt;
&lt;img src=&#34;https://hubojing.github.io/images/DIN-F6.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;图6&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;总结-conclusions&#34;&gt;总结 CONCLUSIONS
&lt;/h1&gt;&lt;p&gt;　　传统CTR模型适用定长向量代表用户兴趣是有缺陷的。为了提高用户兴趣多样性，提出DIN模型来激活相关的用户行为，并且针对不同的广告有一个自适应用户兴趣表示向量。另外，提出两种技术帮助训练工业深度网络，并提升了DIN性能。DIN已被部署到阿里巴巴的在线广告展示系统。&lt;/p&gt;</description>
        </item>
        <item>
        <title>【Paper】Entire Space Multi-Task Model-An Effective Approach for Estimating Post-Click Conversion Rate</title>
        <link>https://hubojing.github.io/hpxssgui/</link>
        <pubDate>Tue, 27 Apr 2021 10:23:10 +0000</pubDate>
        
        <guid>https://hubojing.github.io/hpxssgui/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\ESMM-f2.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;多任务学习之ESMM&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;2018年 阿里巴巴&lt;/p&gt;
&lt;h1 id=&#34;摘要-abstract&#34;&gt;摘要 ABSTRACT
&lt;/h1&gt;&lt;p&gt;传统的CVR建模应用流行的深度学习方法，并实现最先进的性能。遇到的问题：传统的CVR模型用点击曝光的样本进行训练，同时用所有曝光的样本对整个空间进行推断。这导致样本选择偏差（sample selection bias）问题。另外还有数据稀疏的问题。本文提出ESMM(Entire Space Multi-task Model)，通过用户行为序列模式对CVR建模，比如，曝光(impression)&amp;ndash;&amp;gt;点击(click)&amp;ndash;&amp;gt;转换(conversion)。该模型直接在整个空间建模CVR，并使用了一种特征表示转移学习策略。数据集采用淘宝推荐系统，显示ESMM效果显著。本文还发布了第一个包含点击和转化标签用于CVR建模的时序样本数据集。&lt;/p&gt;
&lt;p&gt;关键词：CVR(post-click conversion rate), 多任务学习(multi-task learning), 样本选择偏差(sample selection bias), 数据稀疏(data sparsity), 全空间建模(entire-space modeling)&lt;/p&gt;
&lt;h1 id=&#34;介绍-introduction&#34;&gt;介绍 INTRODUCTION
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cESMM-f1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ESMM&#34;
	
	
&gt;
1）传统的CVR模型在由impression组成的数据集上训练，同时利用所有impression的样本在整个空间上进行推断。该问题（SSB）会影响训练模型的泛化性能。
2）数据稀疏问题。在实践中，为训练CVR模型而收集的数据通常比CTR任务少得多。训练数据的稀疏性使得CVR模型拟合相当困难。&lt;/p&gt;
&lt;p&gt;以前的研究试图解决这些问题。在[5]中，建立了不同特征的分层估计量，并结合逻辑回归模型来解决直接序列问题。然而，它依赖于先验知识来构建层次结构，这在拥有数千万用户和项目的推荐系统中很难应用。过采样方法[11]复制了罕见的类别样本，这有助于减轻数据的稀疏性，但对采样率敏感。全部缺失为阴性(AMAN)应用随机抽样策略选择未点击的impression作为负样本[6]。通过引入未观察到的例子，它可以在一定程度上消除SSB问题，但会导致始终被低估的预测。无偏方法[10]通过剔除抽样从观测值中拟合真实的潜在分布，解决了CTR建模中的SSB问题。然而，当用拒绝概率划分来加权样本时，可能会遇到数值不稳定性。总之，无论是SSB还是DS问题都没有在CVR建模的场景中得到了很好的解决，上述方法都没有利用序列动作信息。&lt;/p&gt;
&lt;p&gt;pCVR = p(conversion|click, impression)&lt;/p&gt;
&lt;p&gt;ESMM可以同时解决SSB和DS问题。它引入了CTR和CTCVR的两个辅助任务。ESMM没有直接用曝光的样本来训练CVR模型，而是把pCVR作为一个中间变量，乘以pCTR等于pCTCVR。PCTCVR和pCTR都是在整个空间上用所有曝光的样本来估计的，因此导出的pCVR也适用于整个空间。这表明SSB问题已经消除。此外，CVR网络特征表示的参数与CTR网络共享。后者是用更丰富的样本训练的。这种参数迁移学习有助于显著缓解DS问题。&lt;/p&gt;
&lt;p&gt;对于这项工作，我们从淘宝的推荐系统中收集流量日志。整个数据集由89亿个样本组成，并带有点击和转换的序列标签。ESMM的表现始终优于其它模型，这证明了所提出方法的有效性。&lt;/p&gt;
&lt;p&gt;数据集开源：https://tianchi.aliyun.com/datalab/dataSet.html?dataId=408&lt;/p&gt;
&lt;h1 id=&#34;提出的方法-the-proposed-approach&#34;&gt;提出的方法 THE PROPOSED APPROACH
&lt;/h1&gt;&lt;h2 id=&#34;注释-notation&#34;&gt;注释 Notation
&lt;/h2&gt;&lt;p&gt;$S = {(x_i, y_i -&amp;gt; z_i)}|^N_{i=1}$，x代表已观察曝光的特征向量，它通常是一个有多域(field)的高维稀疏向量，比如用户域，物品域等。y和z是二分标签，y = 1或者z = 1代表各自被点击或转化事件发生。y-&amp;gt;z代表点击和转化标签的序列依赖，即转化事件发生时总会有前序点击。
pCVR = p(z = 1|y = 1, x)
pCTR = p(y = 1|x)
pCTCVR = p(y = 1, z = 1|x)
p(y = 1, z = 1|x) = p(y = 1|x) × p(z = 1|y = 1, x)
&amp;mdash;&amp;ndash;pCTCVR&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;pCTR&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;pCVR&amp;mdash;&amp;mdash;&amp;ndash;&lt;/p&gt;
&lt;h2 id=&#34;cvr建模和挑战-cvr-modeling-and-challenges&#34;&gt;CVR建模和挑战 CVR Modeling and Challenges
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cESMM-f2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;ESMM架构&#34;
	
	
&gt;
图2左边的DNN CVR建模作为基线模型，传统的CVR模型直接建模p(z = 1|y = 1, x)，使用点击的曝光样本训练模型。比如，$S_c = {(x_j, z_j)|y_j = 1}|^M_{j=1}$，M是所有曝光样本数。$S_c$是S的子集。在$S_c$中，被点击但没有被转化的样本作为负样本，被转化也被点击的样本作为正样本。
&lt;strong&gt;Sample selection bias(SSB)&lt;/strong&gt;
通过引入一个辅助特征向量$x_c$，传统CVR做了一个近似：$p(z = 1|y = 1, x) ≈ q(z = 1|x_c)$。
推理阶段，p(z = 1|y = 1, x)在整个X空间将近似为q(z = 1|x)。
传统的CVR训练数据是曝光和点击的数据，然而预测时又要在整个样本空间。点击事件只是整个曝光样本空间的一个子集，在子集中提取的特征在完整集中使用是有偏的，且数据分布也不一致，违背了机器学习算法有效训练的前提（iid），减弱模型的泛化能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data sparsity (DS)&lt;/strong&gt;
一般CVR比关联的CTR任务少1-3个数量级，CTR任务是在全印象的S的数据集上训练的。表1显示了我们的实验数据集的统计数据，其中CVR任务的样本数量仅为CTR任务的4%。
值得一提的是，CVR建模还存在其他挑战，例如延迟反馈。本文不涉及。&lt;/p&gt;
&lt;h2 id=&#34;多任务全空间模型-entire-space-multi-task-model&#34;&gt;多任务全空间模型 Entire Space Multi-Task Model
&lt;/h2&gt;&lt;p&gt;在整个空间建模。&lt;br&gt;
$p(z = 1|y = 1, x) = \frac{p(y = 1, z = 1|x)}{p(y = 1|x)}$&lt;/p&gt;
&lt;p&gt;这里p(y = 1，z = 1|x)和p(y = 1|x)是在具有所有曝光的S的数据集上建模的。&lt;/p&gt;
&lt;p&gt;损失函数：$L(θ_{cvr}, θ_{ctr}) = \sum_{i=1}^N{l(y_i,f(x_i; θ_{ctr}))} + \sum_{i=1}^N{l(y_i &amp;amp; z_i,f(x_i; θ_{ctr}) × f(x_i;θ_{cvr}))}$
l(·)是交叉熵损失函数。&lt;/p&gt;
&lt;p&gt;特征表征转移。&lt;br&gt;
嵌入层将大规模稀疏输入映射到低维表示向量中。它贡献了深层网络的大部分参数，而深层网络的学习需要大量的训练样本。在ESMM，CVR网络的嵌入式词典与CTR的嵌入式词典是共享的。它遵循特征表征迁移学习范式。CTR任务的全曝光训练样本相对比CVR任务丰富得多。这种参数共享机制使ESMM的CVR网络能够借鉴未点击的曝光，为缓解数据稀疏问题提供了很大的帮助。
请注意，ESMM的子网络可以用一些最近开发的模型来代替，这可能会获得更好的性能。由于篇幅有限，我们省略了它，而把重点放在解决CVR建模在实际实践中遇到的挑战上。&lt;/p&gt;</description>
        </item>
        <item>
        <title>【Paper】Wide &amp; Deep Learning for Recommender Systems</title>
        <link>https://hubojing.github.io/ux6wmeer/</link>
        <pubDate>Tue, 02 Mar 2021 09:20:00 +0000</pubDate>
        
        <guid>https://hubojing.github.io/ux6wmeer/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\Paper-wide&amp;deep-models.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;推荐系统 + 深度学习 2&lt;/strong&gt;
　　&lt;strong&gt;谷歌著名的Wide &amp;amp; Deep模型&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　题目：Wide &amp;amp; Deep Learning for Recommender Systems
　　作者：Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,
　　Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, Hemal Shah, Google Inc.
　　会议信息：DLRS ’16 September 15-15, 2016, Boston, MA, USA&lt;/p&gt;
&lt;p&gt;　　谷歌引用数量：1324（截至2021年3月2日）&lt;/p&gt;
&lt;h1 id=&#34;引言-introduction&#34;&gt;引言 INTRODUCTION
&lt;/h1&gt;&lt;p&gt;　　推荐系统可视为搜索排序系统，输入是用户和上下文信息的查询，输出是物品列表。类似于一般的搜索排序问题，推荐系统中的一大挑战是同时实现记忆（memorization）和泛化（generalization）。
　　Memorization可以宽泛地定义为学习物品或特征的共现频率并探索历史数据的相关关系。
　　Generalization是基于相关性的传递性并探索过去从未出现过的新的特征组合。
　　基于memorization的推荐系统通常更局限于和直接与用户曾有过行为的物品相关。
　　基于generalization的推荐系统试图增强推荐物品的多样性。&lt;/p&gt;
&lt;p&gt;　　例子：如果用户安装了netflix，特征&amp;quot;user_installed_app=netflix&amp;quot;的值为1。
　　Memorization：通过使用稀疏特征的跨物品转换实现，例如AND(user_installed_app=netflix, impression_app=pandora&amp;quot;)，如果用户安装了netflix，然后显示pandora, AND的值为1。
　　Generalization：可以通过使用粒度更小的特性来添加，例如AND(user_installed_category=video，impression_category=music)，但是通常需要手动的特征工程。
　　叉积变换（cross-product transformations）的一个限制是它们不能推广到没有出现在训练数据中的查询项特征对。基于嵌入的模型，例如FM或者DNN跨域解决这个问题。但是当底层的查询项矩阵是稀疏且高阶的（例如用户具有特定的偏好或小范围的吸引力）时，很难学习查询和项的有效低维表示。在这种情况下，大多数查询项对之间应该没有交互，但密集嵌入将导致所有查询项对的预测非零，因此导致过拟合而产生不相干的推荐。具有叉积特征转换的线性模型可以用更少的参数记住这些“例外规则”。&lt;/p&gt;
&lt;p&gt;　　在本文中提出了Wide&amp;amp;Deep模型，通过联合训练一个线性模型组件和一个神经网络组件，实现在一个模型中记忆和泛化。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-wide&amp;amp;deep-models.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Wide&amp;Deep模型&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;贡献点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;带有嵌入和带有特征转换的线性模型的前馈神经网络联合训练的Wide&amp;amp;Deep学习框架，用于具有稀疏输入的通用推荐系统。&lt;/li&gt;
&lt;li&gt;在谷歌Play上实施和评估，谷歌Play是一个拥有超过10亿活跃用户和超过百万应用的移动应用商店。&lt;/li&gt;
&lt;li&gt;在TensorFlow中有开源代码。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;推荐系统概述-recommender-system-overview&#34;&gt;推荐系统概述 RECOMMENDER SYSTEM OVERVIEW
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/images/Paper-wide&amp;amp;deep-models-overview.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;概述&#34;
	
	
&gt;
　　推荐系统一般分为召回（Retrieval）层，排序（Ranking）层。本文在排序层使用Wide &amp;amp; Deep学习框架。&lt;/p&gt;
&lt;h1 id=&#34;宽--深度学习框架-wide--deep-learning&#34;&gt;宽 &amp;amp; 深度学习框架 WIDE &amp;amp; DEEP LEARNING
&lt;/h1&gt;&lt;h2 id=&#34;宽度组件-the-wide-component&#34;&gt;宽度组件 The Wide Component
&lt;/h2&gt;$$\phi_k(x) = \prod_{i=1}^d{x_i}^{c_{ki}}, c_{ki}∈{0,1}$$&lt;p&gt;
　　其中，$c_{ki}$是一个布尔变量，如果第i个特征是第k个变换$\phi_k$的一部分，则为1，否则为0。
　　对于二进制特征，一个叉积变换“AND(gender=female, language=en)，只有当(“gender=female” and “language=en”)时才为1。
　　这捕获了二元特征之间的相互作用，并为广义线性模型增加了非线性。&lt;/p&gt;
&lt;h2 id=&#34;深度组件-the-deep-component&#34;&gt;深度组件 The Deep Component
&lt;/h2&gt;$$\alpha^{l+1} = f(W^{(l)}a^{(l)}) + b^{(l)})$$&lt;h2 id=&#34;模型联合训练-joint-training-of-wide--deep-model&#34;&gt;模型联合训练 Joint Training of Wide &amp;amp; Deep Model
&lt;/h2&gt;$$P(Y=1|x) = \sigma(w^T_{wide}[x,\phi(x)]+w^T_{deep}a^{(l_f)}+b)$$&lt;p&gt;
　　其中Y是二分类标签，$\sigma(·)$是sigmoid函数，$\phi(x)$是原始特征x的叉积变换，b是偏置项。$w_{wide}$是所有宽度模型权重的向量，$w_{deep}$是应用在最终激活$a^{(l_f)}$的权重。&lt;/p&gt;
&lt;h1 id=&#34;系统实现-system-implementation&#34;&gt;系统实现 SYSTEM IMPLEMENTATION
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-wide&amp;amp;deep-models-%e7%b3%bb%e7%bb%9f%e5%ae%9e%e7%8e%b0.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;系统实现&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;数据产生-data-generation&#34;&gt;数据产生 Data Generation
&lt;/h2&gt;&lt;p&gt;　　通过将一个特征值x映射到其累积分布函数P(X≤x)，将连续实值特征归一化为[0,1]，并分成$n_q$分位数。对于第i个分位数的值，规范化值为$\frac{i-1}{n_q-1}$。分位数边界i−1在数据生成时计算。&lt;/p&gt;
&lt;h2 id=&#34;模型训练-model-training&#34;&gt;模型训练 Model Training
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-wide&amp;amp;deep-models-%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;模型训练&#34;
	
	
&gt;
　　在训练过程中，输入层接收训练数据和词汇，并生成稀疏和密集特征以及标签。宽度组件包括用户安装应用和印象应用的叉积。对于模型的深层部分，每个分类特征学习一个32维的嵌入向量。将所有的嵌入与密集特征连接在一起，得到一个大约1200维的密集向量。然后将连接的矢量送入3个ReLU层，最后送入logistic输出单元。
　　Wide &amp;amp; Deep模型训练了超过5000亿个例子。每当一组新的训练数据到达时，模型就需要重新训练。然而，每次重新训练在计算上都是昂贵的，并且延迟了服务时间。为了解决这一挑战，本文实现了一个暖启动系统，该系统使用先前模型的嵌入和线性模型权值来初始化一个新的模型。
在将模型加载到模型服务器之前，需要对模型进行一次演练，以确保在服务实时流量时不会出现问题。本文根据经验来验证模型的质量，作为一个完整的检查。&lt;/p&gt;
&lt;h2 id=&#34;模型服务-model-serving&#34;&gt;模型服务 Model Serving
&lt;/h2&gt;&lt;p&gt;　　一旦模型经过训练和验证，就把它加载到模型服务器中。对于每个请求，服务器都会从应用程序检索系统和用户特性中接收一组应用程序候选项来为每个应用程序评分。然后，应用程序从最高分到最低分进行排名，并按照这个顺序向用户展示这些应用程序。分数是通过运行一个采用Wide &amp;amp; Deep模型的正向推理来计算的。
　　为了为每个请求提供10毫秒量级的服务，使用多线程并行来优化性能，通过并行运行较小的批处理，来代替在单个批处理推理步骤中对所有候选应用程序进行评分。&lt;/p&gt;
&lt;h1 id=&#34;实验-experiment-results&#34;&gt;实验 EXPERIMENT RESULTS
&lt;/h1&gt;&lt;h2 id=&#34;app-acquisitions&#34;&gt;App Acquisitions
&lt;/h2&gt;&lt;p&gt;　　本文在A/B测试框架下进行了为期3周的在线实时实验。对于对照组，随机选择1%的用户，并向他们展示由上一个版本的排名模型生成的推荐，该模型是一个高度优化的广泛性logistic回归模型，具有丰富的叉积特征转换。在实验组中，1%的用户使用了由相同的一组特征进行训练的Wide &amp;amp; Deep模型生成的推荐。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-wide&amp;amp;deep-models-t1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;性能对比&#34;
	
	
&gt;
　　Wide &amp;amp; Deep模式使app store主登陆页面的应用获取率比对照组提高了+3.9%。结果还与另1%组仅使用具有相同特征和神经网络结构的模型的深度部分进行了比较，Wide &amp;amp; deep模式比deep-only模型有+1%的增益。
　　除了在线实验，还展示了AUC。Wide &amp;amp; Deep的线下AUC略高，但对线上流量的影响更显著。一个可能的原因是离线数据集中的印象和标签是固定的，而在线系统可以通过混合归纳和记忆生成新的探索性推荐，并从新的用户反应中学习。&lt;/p&gt;
&lt;h2 id=&#34;服务性能-serving-performance&#34;&gt;服务性能 Serving Performance
&lt;/h2&gt;&lt;p&gt;　　面对我们的商业移动应用商店所面临的高流量，高吞吐量和低延迟的服务具有挑战性。在高峰流量时，我们的推荐服务器每秒可以获得超过1000万个应用。使用单个线程，在一次批处理中为所有候选人打分需要31毫秒。我们实现了多线程，并将每个批处理分成更小的部分，这显著地将客户端延迟减少到14毫秒（包括服务开销），如表所示。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-wide&amp;amp;deep-models-t2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;服务性能&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;相关工作-related-work&#34;&gt;相关工作 RELATED WORK
&lt;/h1&gt;&lt;p&gt;　　结合带叉积转换的广义线性模型与深层神经网络嵌入的灵感来自以前的工作，比如FM，通过在两个低维嵌入向量之间使用点积分解两个变量间的相互作用，将线性模型了进行推广。在本文中，通过神经网络代替点积来学习嵌入之间高度非线性的相互作用，从而扩展了模型容量。
　　在语言模型中，通过学习输入和输出之间的直接权值，提出了使用n元特征的递归神经网络(RNNs)和最大熵模型联合训练，以显著降低RNN的复杂性(例如，隐藏层大小)。在计算机视觉中，深度残差学习已被用于降低训练更深层次模型的难度，并通过跳过一个或多个层次的捷径连接提高准确性。
　　神经网络与图形模型的联合训练还被应用于基于图像的人体姿态估计。在这项工作中，探讨了前馈神经网络和线性模型的联合训练，在稀疏特征和输出单元之间直接连接，用于输入数据稀疏的通用推荐和排序问题。
　　在推荐系统文献中，将内容信息的深度学习与评分矩阵的协同过滤(CF)相结合来探索协同深度学习。以前的工作也曾致力于手机应用推荐系统，如AppJoy在用户的应用使用记录上使用CF。不同于之前工作中基于cf或基于内容的方法，我们在app推荐系统中，基于用户和印象数据使用Wide &amp;amp; Deep模型联合训练。&lt;/p&gt;
&lt;h1 id=&#34;总结-conclusion&#34;&gt;总结 CONCLUSION
&lt;/h1&gt;&lt;p&gt;　　宽度线性模型可以通过叉积特征变换有效地记忆稀疏特征交互，而深度神经网络可以通过低维嵌入来泛化之前未见过的特征交互。在线实验结果表明，与Wide-only和Deep-only模型相比，Wide &amp;amp; Deep模型有显著提高。&lt;/p&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/python/estimator/canned/dnn_linear_combined.py&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/tensorflow/tensorflow/blob/r1.11/tensorflow/python/estimator/canned/dnn_linear_combined.py&lt;/a&gt;&lt;/p&gt;</description>
        </item>
        <item>
        <title>【paper】AutoRec - Autoencoders Meet Collaborative Filtering</title>
        <link>https://hubojing.github.io/dapymrcc/</link>
        <pubDate>Thu, 04 Feb 2021 10:19:03 +0000</pubDate>
        
        <guid>https://hubojing.github.io/dapymrcc/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\Paper-AutoRec-Itembased.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;推荐系统 + 深度学习 1&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;WWW&#39;15&lt;br&gt;
作者：Suvash  Sedhain, Aditya Krishna Menon, Scott Patrick Sanner, Lexing Xie&lt;/p&gt;
&lt;p&gt;谷歌学术引用次数580（截至2021年2月4日）&lt;/p&gt;
&lt;p&gt;关键词：Recommender Systems; Collaborative Filtering; Autoencoders&lt;/p&gt;
&lt;h1 id=&#34;introduction-引言&#34;&gt;INTRODUCTION 引言
&lt;/h1&gt;&lt;p&gt;本文提出一种新的基于自动编码器范例的CF模型，思路来自于针对视觉和语音任务的深度神经网络模型。 &lt;br&gt;
和CF相比，具有表示和计算的优越性。&lt;/p&gt;
&lt;h1 id=&#34;the-autorec-model-模型&#34;&gt;THE AUTOREC MODEL 模型
&lt;/h1&gt;$$min_{\theta}\sum_{r∈S}||r - h(r;\theta)||^2_2$$$$h(r;\theta) = f(W · g(Vr + μ) + b)$$&lt;p&gt;
f、g是激活函数。$\theta = {W, V, μ, b}$&lt;br&gt;
$W∈\mathbb{R}^{d×k}$, $V∈\mathbb{R}^{k×d}$, $μ∈\mathbb{R}^k$, $b∈\mathbb{R}^d$
该目标对应于具有单个k维隐藏层的自连接神经网络。使用反向传播来学习参数θ。&lt;/p&gt;
&lt;p&gt;基于物品的AutoRec模型I-AutoRec&lt;br&gt;
${r^{(i)}}^n_{i=1}$
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-AutoRec-Itembased.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;基于物品的AutoRec&#34;
	
	
&gt;
两点改变：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个$r^{(i)}$通过反向传播更新和输入有关的权重得到，这在矩阵分解和RBM策略中常用。&lt;/li&gt;
&lt;li&gt;设计了学习参数正则化防止过拟合。&lt;/li&gt;
&lt;/ol&gt;
$$\hat{R}_{ui} = (h(r^{(i)};\hat{\theta}))_u$$$$min_{\theta}||r^{(i)}-h(r^{(i)};\theta)||^2_o + \frac{\lambda}{2}·(||W||^2_F + ||V||^2_F)$$&lt;p&gt;
$||||^2_o$代表只考虑可观测评分的贡献。&lt;/p&gt;
&lt;p&gt;基于用户的AutoRec模型U-AutoRec&lt;br&gt;
${r^{(u)}}^m_{u=1}$&lt;/p&gt;
&lt;p&gt;和CF策略的区别：&lt;br&gt;
对比基于RBM的CF模型（RBM-CF）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;RBM-CF是基于限制玻尔兹曼机的生成概率模型，AutoRec是一个基于自动编码器的判别模型。&lt;/li&gt;
&lt;li&gt;RBM-CF通过最大化似然log函数估计参数，AutoRec直接最小化RMSE。&lt;/li&gt;
&lt;li&gt;训练RBM-CF需要使用对比散度，训练AutoRec需要相对更快的基于梯度的反向传播。&lt;/li&gt;
&lt;li&gt;RBM-CF只使用于离散评分，并对每个评分估计一个分散的参数集。对r个可能的评分，它使用了基于RBM的nkr或者mkr个参数用于用户（物品）。AutoRec与r无关，因此需要较少的参数。 较少的参数使AutoRec的内存占用量更少，更不容易过度拟合。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对比矩阵分解（MF）&lt;br&gt;
MF学习线性潜在表示，AutoRec可以通过激活函数学习非线性潜在表示。&lt;/p&gt;
&lt;h1 id=&#34;experimental-evaluation-实验评估&#34;&gt;EXPERIMENTAL EVALUATION 实验评估
&lt;/h1&gt;&lt;p&gt;基线：RBM-CF, BiasedMF, LLORMA.&lt;br&gt;
数据集：Movielens 1M, 10M 和Nerflix数据集&lt;br&gt;
没有训练数据的测试集默认评分为3。&lt;br&gt;
训练集：测试集=9：1&lt;br&gt;
将训练集10%作为验证集。&lt;br&gt;
重复划分步骤5次并记录平均RMSE。&lt;br&gt;
每次实验95%在RMSE偶然的间隔在±0.003之间。&lt;br&gt;
正则化参数λ∈{0.001, 0.01, 0.1, 1, 100, 1000}&lt;br&gt;
潜在维度k∈{10, 20, 40, 80, 100, 200, 300, 400, 500}&lt;/p&gt;
&lt;p&gt;三种实验&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;和RBM对比&lt;/li&gt;
&lt;li&gt;激活函数选取对比&lt;/li&gt;
&lt;li&gt;隐藏单元k的数量
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-AutoRec-k.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;k&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;基线性能对比
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-AutoRec-baselines.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;基线&#34;
	
	
&gt;&lt;/li&gt;
&lt;li&gt;深度扩展对Auto的帮助&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;代码&#34;&gt;代码
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/mesuvash/NNRec&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/mesuvash/NNRec&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结
&lt;/h1&gt;&lt;p&gt;AutoRec是最简单的深度学习推荐系统。&lt;br&gt;
它是一种单隐层神经网络推荐模型，将自动编码器与协同过滤相结合。&lt;/p&gt;</description>
        </item>
        <item>
        <title>【Paper】Deep Neural Networks for YouTube Recommendations</title>
        <link>https://hubojing.github.io/fqywpuls/</link>
        <pubDate>Tue, 15 Dec 2020 14:24:54 +0000</pubDate>
        
        <guid>https://hubojing.github.io/fqywpuls/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\Paper-YouTube-整体架构.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;YouTube经典推荐论文。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　RecSys&#39;16
　　谷歌学术引用次数为1201（截至2020年12月15日）&lt;/p&gt;
&lt;p&gt;　　作者：Paul Covington, Jay Adams, Emre Sargin
　　Google
　　Mountain View, CA&lt;/p&gt;
&lt;p&gt;　　关键词：recommender system; deep learning; scalability
　　&lt;a class=&#34;link&#34; href=&#34;https://dl.acm.org/doi/pdf/10.1145/2959100.2959190&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;introduction-引言&#34;&gt;Introduction 引言
&lt;/h1&gt;&lt;p&gt;YouTube推荐系统的三大挑战：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scale 大规模&lt;/li&gt;
&lt;li&gt;Freshness 新鲜度&lt;/li&gt;
&lt;li&gt;Noise 噪声-数据往往是隐式反馈&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;system-overview-系统概述&#34;&gt;System Overview 系统概述
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-YouTube-%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;系统架构&#34;
	
	
&gt;
　　系统由两部分组成：候选生成部分和排序部分。
　　候选生成部分输入是用户历史活动事件，使用协同过滤从大数据集中输出小子集。
　　排序部分根据目标函数对每个视频精排打分，最高分视频推荐给用户。&lt;/p&gt;
&lt;p&gt;　　优点：从大数据集中选出的小数据集依然具有个性化特征，并且候选生成部分可以添加别的数据源。&lt;/p&gt;
&lt;p&gt;　　评价指标：精确率、召回率、排序损失等
　　最后通过A/B测试在线实验（A/B测试结果不总是和离线实验结果相一致）。&lt;/p&gt;
&lt;h1 id=&#34;candidate-generation-候选生成&#34;&gt;Candidate Generation 候选生成
&lt;/h1&gt;&lt;p&gt;　　这种方法可以看作矩阵分解的非线性推广，它早期的神经网络迭代只嵌入用户过去观看记录来模拟这种因子分解行为。&lt;/p&gt;
&lt;h2 id=&#34;recommendation-as-classification-作为分类推荐&#34;&gt;Recommendation as Classification 作为分类推荐
&lt;/h2&gt;$$P(w_t = i|U,C) = \frac{e^{v_iu}}{\sum_{j∈V}e^{v_ju}}$$&lt;p&gt;
　　其中$u∈\mathbb{R}^N$代表了用户高维嵌入（embedding），上下文数据对和$V_j∈\mathbb{R}^N$代表了每个候选视频的嵌入（embedding）。
　　在这样的设定中，一个嵌入就从稀疏实体转为了稠密向量（$\mathbb{R}^N$）。&lt;/p&gt;
&lt;p&gt;　　深度神经网络的任务是学习用户嵌入u，作为用户历史记录和上下文的函数，这有助于使用softmax分类器从海量视频中进行识别。&lt;/p&gt;
&lt;h3 id=&#34;effcient-extreme-multiclass-高效极端多分类&#34;&gt;Effcient Extreme Multiclass 高效极端多分类
&lt;/h3&gt;&lt;p&gt;　　为了有效地训练这样一个拥有数百万分类的模型，需要依赖于一种技术，从背景分布(“候选抽样”)中抽取负类，然后通过重要性加权对该抽样进行修正。对于每一个实例，真标签和抽样的负样本的交叉熵损失都最小。
　　在严格的服务延迟为几十毫秒的情况下为百万个物品打分需要一个近似亚线性的方案。以前的YouTube系统依赖于hashing，分类采用相似方法。
　　由于服务时不需要softmax输出层校准可能性（？有些不解），评分问题简化为在点积空间的最近邻搜索，在这个空间中，通用库可以使用。A/B结果对最近邻搜索算法的选择不是特别敏感。&lt;/p&gt;
&lt;h2 id=&#34;model-architecture-模型架构&#34;&gt;Model Architecture 模型架构
&lt;/h2&gt;&lt;p&gt;　　学习每个视频的高维嵌入到固定词汇中，并将这些嵌入输入到前馈神经网络中。用户的观看历史记录由稀疏视频id的可变长度序列表示，该序列通过嵌入映射到稠密向量表示。该网络需要固定规模的密集输入，并简单地平均在不同策略中表现最好的嵌入。通过梯度下降反向传播更新，嵌入与所有其他模型参数联合学习。特征被连接成一个宽的第一层，然后是几层全连接的线性单元(ReLU)。如下图所示。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-YouTube-%e5%80%99%e9%80%89%e7%94%9f%e6%88%90%e6%9e%b6%e6%9e%84.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;候选生成架构&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;heterogeneous-signals-混合信号&#34;&gt;Heterogeneous Signals 混合信号
&lt;/h2&gt;&lt;p&gt;　　使用深度神经网络作为矩阵分解的推广的一个关键优点是任意连续和分类特征可以很容易地添加到模型中。&lt;/p&gt;
&lt;h3 id=&#34;example-age-feature-示例年龄特征&#34;&gt;“Example Age” Feature “示例年龄”特征
&lt;/h3&gt;&lt;p&gt;　　用户往往喜欢新鲜的内容。除了简单地推荐用户想看的新视频的一级效应，还有一个重要的二级现象，即引导和传播病毒式内容。视频受欢迎程度是会变化的，但推荐系统反映的是几周内的平均观看可能性。为了纠正这一点，在训练期间将训练示例的年龄作为一个特征输入。在服务时间，这个特征被设置为零(或者稍微负一点)，以反映模型正在训练窗口的最后进行预测。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-YouTube-with_example_age.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;With Example Age&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;label-and-context-selection-标签和上下文选择&#34;&gt;Label and Context Selection 标签和上下文选择
&lt;/h2&gt;&lt;p&gt;　　替代学习问题的选择对A/B测试的性能有很大的影响，但很难用离线实验来衡量。
　　训练示例是从所有YouTube视频中生成的而不是仅仅依靠推荐。否则新内容的出现将会非常困难，而且推荐器会有过度偏向。如果用户是通过推荐以外的方式发现视频，希望能够通过协同过滤快速传播这个发现给其他人。改进实时指标的另一个关键见解是，为每个用户生成固定数量的训练样例，有效平等地在损失函数中权衡我们的用户。这避免了一小部分高活跃用户主导损失。
　　必须非常小心地对分类器隐瞒信息，以防止模型利用站点的结构和过度拟合代理问题。
　　预测用户下一个观看的性能要比预测随机留出的观看好得多。许多协同过滤系统隐式地选择标签和上下文，方法是取出一个随机的物品，并从用户历史记录中的其他物品中预测它。这泄露了未来信息并忽视了非对称消费模式。相反，本文“回滚”用户的历史记录，通过选择一个随机的观看记录，并且只输入用户留出的有标签的观看记录之前采取的动作。
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-YouTube-predict_future_watch.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Predicting future watch&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;experiments-with-features-and-depth-特征和深度实验&#34;&gt;Experiments with Features and Depth 特征和深度实验
&lt;/h2&gt;&lt;p&gt;　　添加特征和深度可以显著改善保持数据的精度，如图6所示。在这些实验中，一个包含100万个视频和100万个搜索令牌的词汇表中嵌入了256个浮点数，每个浮点数的最大包尺寸为50个最近的观看和50个最近的搜索。softmax层在相同的1M视频类上输出多项分布，维数为256(可以认为是单独的输出视频嵌入)。网络结构遵循一个常见的“塔”模式，其中网络的底部是最宽的，每个后续隐藏层的单位数量减半。&lt;/p&gt;
&lt;h1 id=&#34;ranking-排序&#34;&gt;Ranking 排序
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-YouTube-%e6%8e%92%e5%ba%8f%e6%9e%b6%e6%9e%84.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;排序架构&#34;
	
	
&gt;
　　使用与候选生成结构相似的深度神经网络，使用逻辑回归为每个视频印象分配一个独立的分数。如图所示。然后，视频列表将根据这个分数进行排序并返回给用户。最终排名目标是根据实时A/B测试结果不断调整，但通常是每个印象的预期观看时间的简单函数。通过点击率排名通常会促进欺骗性视频，用户没有完成(“点击诱饵”)，而观看时间能够更好地捕捉用户粘性。&lt;/p&gt;
&lt;h2 id=&#34;feature-representation-特征表示&#34;&gt;Feature Representation 特征表示
&lt;/h2&gt;&lt;p&gt;　　用的类别或特征在基数上差别很大——有些是二进制的（例如用户是否登录），而其他有数百万个可能的值（例如用户的最后一次搜索查询）。根据功能是仅贡献单个值(&amp;ldquo;univalent&amp;rdquo;)还是一组值(&amp;ldquo;multivalent&amp;rdquo;)，进一步划分功能。　　
univalent例子：被评分的视频ID，multivalent例子：用户最近观看的N个视频ID的bag。还根据特性是描述物品的属性（&amp;ldquo;impression&amp;rdquo;）还是描述用户/上下文的属性（&amp;ldquo;query&amp;rdquo;）对特性进行分类。查询特征为每个请求计算一次，而印象特征为每个物品项计算一次。&lt;/p&gt;
&lt;h3 id=&#34;feature-engineering-特征工程&#34;&gt;Feature Engineering 特征工程
&lt;/h3&gt;&lt;p&gt;　　描述过去视频输入频率的特性对于在推荐中引入“churn”(连续的请求不返回相同的列表)也是至关重要的。如果一个用户最近被推荐了一个视频，但没有看过它，那么模型自然会在下一次加载页面时降低这种印象。&lt;/p&gt;
&lt;h3 id=&#34;embedding-categorical-features-嵌入分类特征&#34;&gt;Embedding Categorical Features 嵌入分类特征
&lt;/h3&gt;&lt;p&gt;　　类似于候选生成，使用嵌入将稀疏分类特征映射到适合于神经网络的稠密表示。
　　同一ID空间中的分类特性也共享底层的嵌入。共享嵌入对于提高泛化性能、加快训练速度和减少内存需求具有重要意义。&lt;/p&gt;
&lt;h3 id=&#34;normalizing-continuous-features-归一化连续特征&#34;&gt;Normalizing Continuous Features 归一化连续特征
&lt;/h3&gt;&lt;p&gt;　　神经网络对其输入的尺度和分布非常敏感，而其他方法，如决策树的集合，对单个特征的尺度是不变的。
　　对于连续特征x，其分布为f，使用公式$\tilde{x} = \int_{-\infty}^xdf$进行归一化操作到[0,1)。除了该方法，也使用了$\tilde{x}^2$和$\sqrt{\tilde{x}}$。&lt;/p&gt;
&lt;h2 id=&#34;modeling-expected-watch-time-预期观看时间建模&#34;&gt;Modeling Expected Watch Time 预期观看时间建模
&lt;/h2&gt;&lt;p&gt;　　预期观看时间使用加权逻辑回归方法。
　　模型在交叉熵损失下用逻辑回归进行训练。积极的（点击）印象是由视频上观察的观看时间加权的。负面（未点击的）印象全部获得单位权重。
　　逻辑回归学到的概率为$\frac{\sum{T_i}}{N-k}$，N是训练集数量，k是正例数量，$T_i$是第i个印象的观看时间。
　　最终本文使用指数函数$e^x$作为最后激活函数来产生预估概率。&lt;/p&gt;
&lt;h2 id=&#34;experiments-with-hidden-layers隐藏层实验&#34;&gt;Experiments with Hidden Layers隐藏层实验
&lt;/h2&gt;&lt;p&gt;　　这些结果表明，增加隐藏层的宽度可以改善结果，同时也可以增加它们的深度。但是，需要权衡的是推荐所需的服务器CPU时间。&lt;/p&gt;
&lt;h1 id=&#34;conclusions-总结&#34;&gt;Conclusions 总结
&lt;/h1&gt;&lt;p&gt;　　将YouTube推荐问题划分为两个部分：候选生成部分和排序部分。
　　通过捕捉不对称的协同观看行为和防止未来信息泄漏，对未来观看进行分类，可以很好地执行实时指标。从分类器中截取不同信号对于取得良好的结果也是至关重要的——否则模型会过度拟合代理问题而不能很好地转移到主页。
　　使用训练样例的年龄作为输入特征，消除了对过去的固有偏见，并允许模型表示流行视频的时间依赖性行为。这提高了离线保持精度结果，并在A/B测试中显著增加了观看最近上传的视频的时间。
　　排序是一个比较经典的机器学习问题，然而本文深度学习方法在观看时间预测方面优于以往的线性和基于树的方法。推荐系统尤其受益于描述用户关于物品的历史行为的特定特征。深度神经网络需要分类特征和连续特征的特殊表示，分别用嵌入和分位数规范化进行变换。层的深度显示有效地模拟了非线性交互之间的数百个特征。
　　逻辑回归通过加权训练样例修正了正例，统一了负例，使之能学习预期观看时间的概率。与直接预测点击率相比，该方法在观看时间加权排序评价指标上表现得更好。&lt;/p&gt;</description>
        </item>
        <item>
        <title>【Paper】Factorization Machines</title>
        <link>https://hubojing.github.io/ucapbpue/</link>
        <pubDate>Wed, 09 Dec 2020 11:18:31 +0000</pubDate>
        
        <guid>https://hubojing.github.io/ucapbpue/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\Paper-FM-feature_x.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;FM算法原文。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　2010 IEEE International Conference on Data Mining
　　Steffen Rendle
　　Department of Reasoning for Intelligence
　　The Institute of Scientific and Industrial Research Osaka University, Japan
谷歌学术被引用次数1396（截至2020年12月14日）
　　论文关键词：factorization machine; sparse data; tensor factorization; support vector machine
　　&lt;a class=&#34;link&#34; href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=5694074&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;introduction-引言&#34;&gt;Introduction 引言
&lt;/h1&gt;&lt;p&gt;　　FM优点：
　1. FM能在很稀疏的数据上进行参数估计，但SVM不行。
　2. FM是线性复杂度，不需要类似于SVM中的支持向量。
　3. FM是通用预测方法，适用于任何特征向量。其它的因子分解方法都受限于特定的输入。（对比biased MF, SVD++, PITF和FPMC）&lt;/p&gt;
&lt;h1 id=&#34;prediction-under-sparsity-稀疏情况下的预测&#34;&gt;Prediction under sparsity 稀疏情况下的预测
&lt;/h1&gt;&lt;p&gt;&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-FM-feature_x.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;feature x&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;factorization-machinesfm-因子分解机&#34;&gt;Factorization machines(FM) 因子分解机
&lt;/h1&gt;&lt;h2 id=&#34;factorization-machine-model-因子分解机模型&#34;&gt;Factorization machine model 因子分解机模型
&lt;/h2&gt;$$\hat{y}(x):=w_0 + \sum_{i=1}^nw_ix_i + \sum_{i=1}^n\sum_{j=i+1}^n&lt;v_i,v_j&gt;x_ix_j$$$$&lt;v_i,v_j&gt;:=\sum_{f=1}^kv_{i,f}·v_{j,f}$$&lt;p&gt;
　　V中的$v_i$描述k个因素中的第i个变量。$Ks∈N_0^+$是定义因子分解的维度的超参数。
　　2-way FM捕捉所有变量的单个和成对交互：
　　$w_0$是全局偏置，$w_i$模拟了第i个变量的程度。
　　$\hat{w}_{i,j}:=&amp;lt;v_i, v_j&amp;gt;$模拟了第i和第j个变量间的交互。这个在高阶交互时（d &amp;gt; 2）高质量估计的关键。
　　时间复杂度O($kn^2$)，因为所有的交互对都要被计算。但可以变形使之化为O(kn)。&lt;/p&gt;
&lt;h2 id=&#34;factorization-machines-as-predictors-fm作为预测器&#34;&gt;Factorization machines as predictors FM作为预测器
&lt;/h2&gt;&lt;p&gt;　　可用于回归、二分类和排序问题。&lt;/p&gt;
&lt;h2 id=&#34;learning-factorization-machines-fm学习策略&#34;&gt;Learning factorization machines FM学习策略
&lt;/h2&gt;&lt;p&gt;　　使用随机梯度下降（SGD）来学习。&lt;/p&gt;
&lt;h2 id=&#34;d-way-factorization-machine-多维fm&#34;&gt;d-way factorization machine 多维FM
&lt;/h2&gt;&lt;p&gt;　　同时2-way FM可以拓展为d-way。&lt;/p&gt;
&lt;h2 id=&#34;summary-总结&#34;&gt;Summary 总结
&lt;/h2&gt;&lt;p&gt;　　FM优点：
　　1. 在高稀疏下可估计特征交互，尤其是不可观测的交互。
　　2. 预测和学习的时间复杂度是线性的。使SGD优化可行，并允许多种损失函数优化。&lt;/p&gt;
&lt;h1 id=&#34;fms-vs-svms-因子分解机对比支持向量机&#34;&gt;FMs vs. SVMs 因子分解机对比支持向量机
&lt;/h1&gt;&lt;h2 id=&#34;svm-model-支持向量机模型&#34;&gt;SVM model 支持向量机模型
&lt;/h2&gt;$$\hat{y}(x) = &lt;\Phi(x), w&gt;$$$$K:R^n × R^n → R, K(x, z) = &lt;\Phi(x), \Phi(z)&gt;$$&lt;ol&gt;
&lt;li&gt;
$$\hat{y}(x) = w_0 + \sum^n_{i=1}w_ix_i, w_0∈R, w∈R^n$$&lt;p&gt;
　　这等价于FM中d = 1的情况。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
$$\hat{y}(x) = w_0 + \sqrt{2}\sum^n_{i=1}w_ix_i + \sum^n_{i = 1}w_{i,i}^{(2)}x_i^2 + \sqrt{2}\sum^n_{i=1}\sum^n_{j=i+1}w_{i,j}^{(2)}x_ix_j$$&lt;p&gt;
　　其中$w_0∈R, w∈R^n, w^(2)∈R^{n×n}$。
　　d = 2时，FM和SVM的区别在于SVM中$w_{i,j}$是完全独立的，而FM中参数是因子分解的，所以$&amp;lt;v_i, v_j&amp;gt;$依赖于彼此。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;parameter-estimation-under-sparsity-在稀疏情况下的参数估计&#34;&gt;Parameter Estimation Under Sparsity 在稀疏情况下的参数估计
&lt;/h2&gt;&lt;p&gt;　　举例：使用协同过滤（上图中蓝色和红色部分数据）。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;线性SVM
$$\hat{y}(x) = w_0 + w_u + w_i$$
　　只有j = u 或 j = i时$x_j$ = 1，即只有用户和物品偏好被选中时才有用。由于模型简单，在稀疏情况也能进不错的参数估计，但预测质量低。&lt;/li&gt;
&lt;li&gt;多项式SVM
$$\hat{y}(x) = w_0 + \sqrt{2}(w_u + w_i) + w_{u,u}^{(2)} +  w_{i,i}^{(2)} + \sqrt{2}w_{u,i}^{(2)}$$
　　$w_u$和$w_{u,u}^{(2)}$是一样的。该等式除了一个额外的$w_{u,i}$，等价于线性SVM。在训练集中，对于每一个$w_{u,i}$最多只有一条记录，在测试集中通常没有。因此，2-way的SVM效果也不比线性SVM好。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;summary-总结-1&#34;&gt;Summary 总结
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;SVM需要直接观测交互数据，但稀疏数据集经常没有。FM参数可以在系数情况下进行不错的参数估计。&lt;/li&gt;
&lt;li&gt;FM可以一开始就直接学习，但非线性SVM需要成对学习。&lt;/li&gt;
&lt;li&gt;FM是独立于训练集的，SVM的预测是基于部分训练数据的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;fms-vs-other-factorization-models-其它因子分解方法对比&#34;&gt;FMs VS. Other Factorization Models 其它因子分解方法对比
&lt;/h1&gt;&lt;p&gt;　　改写FM公式形式，分别与Matrix and Tensor Factorization矩阵和张量分解、SVD++、PITF for Tag Recommendation、Factorized Personalized Markov Chains(FPMC)方法对比，FM改写后性能与这些方法实现效果类似。&lt;/p&gt;
&lt;h2 id=&#34;summary-总结-2&#34;&gt;Summary 总结
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;标准因子分解模型（比如PARAFAC或者MF）不像FM一样是通用预测模型。&lt;/li&gt;
&lt;li&gt;修改特征提取部分，FM可以模拟在特定任务下的成功模型（比如MF,PARAFAC,SVD++,PITF,FPMC)。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;conclusion-and-future-work-总结和展望&#34;&gt;Conclusion and Future Work 总结和展望
&lt;/h1&gt;&lt;p&gt;　　与SVM对比，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在数据稀疏情况下，FM可以进行参数估计。&lt;/li&gt;
&lt;li&gt;模型时间复杂度是线性的，并且只依赖于模型参数。&lt;/li&gt;
&lt;li&gt;从最开始就能直接优化。&lt;/li&gt;
&lt;/ol&gt;</description>
        </item>
        <item>
        <title>【Paper】Matrix Factorization Techniques for Recommender Systems</title>
        <link>https://hubojing.github.io/dvbvavgt/</link>
        <pubDate>Mon, 07 Dec 2020 15:12:57 +0000</pubDate>
        
        <guid>https://hubojing.github.io/dvbvavgt/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\Paper-MF-LFM.png&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;矩阵分解算法原文。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　2009年发表于IEEE旗下的Computer期刊。
　　谷歌学术引用数为7954（截至2020年12月7日）。&lt;br&gt;
　　作者：Yehuda Koren, Yahoo Research
　　Robert Bell and Chris Volinsky, AT&amp;amp;T Labs—Research&lt;br&gt;
　　DOI: 10.1109/MC.2009.263&lt;br&gt;
　　&lt;a class=&#34;link&#34; href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=5197422&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;recommender-system-stratrgies-推荐系统策略&#34;&gt;Recommender System Stratrgies 推荐系统策略
&lt;/h1&gt;&lt;p&gt;　　两种策略：content filtering approach和collaborative filtering&lt;br&gt;
　　前者需要收集外部信息，但这不容易得到。后者聚焦于用户过去的行为，相比前者精确度更高，但它有冷启动问题。相反，在冷启动问题方面，前者更优越。&lt;/p&gt;
&lt;p&gt;　　协同过滤又分为neighborhood methods和latent factor models。&lt;br&gt;
　　基于领域的策略又可分为基于用户和基于物品。&lt;br&gt;
　　基于物品的策略基于同一个用户对相邻物品的评分对用户偏好进行评估。同一个用户给一件物品的相邻物品会打相似的评分。&lt;br&gt;
　　基于用户的方法鉴定相似的用户，他们可以互相补充对方的评分信息。&lt;/p&gt;
&lt;p&gt;　　LFM隐语义模型&lt;br&gt;
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-MF-LFM.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;LFM&#34;
	
	
&gt;&lt;br&gt;
　　意思是把特征刻画分为k个维度。如图，将刻画特征设为性别和题材类别（serious/escapist），形成一个坐标空间，每个用户和物品都在这个空间中，如果在坐标系中距离越近则说明越相似。&lt;/p&gt;
&lt;h1 id=&#34;matrix-factorization-methods-矩阵分解策略&#34;&gt;Matrix Factorization Methods 矩阵分解策略
&lt;/h1&gt;&lt;p&gt;　　一些最成功的隐语义模型是基于矩阵分解实现的。&lt;br&gt;
　　矩阵分解通过从评分矩阵推断出的因子向量来刻画物品和用户。&lt;br&gt;
　　优势：当显式反馈无法得到时，可以添加其它信息（比如使用隐式反馈推断用户偏好）。&lt;/p&gt;
&lt;h1 id=&#34;a-basic-matrix-factorization-model-基本矩阵分解模型&#34;&gt;A Basic Matrix Factorization Model 基本矩阵分解模型
&lt;/h1&gt;$$\hat{r}_{ui} = {q_i}^T{p_u}$$$$min_{q\*,p\*}\sum_{(u,i)∈k}({r_ui} - {p_u}^Tq_i)^2 + \lambda(||p_u||^2 + ||q_i||^2)$$&lt;p&gt;
　　其中，k是(u,i)对的集合。${r_{ui}}$是未知的（训练集）。&lt;/p&gt;
&lt;h1 id=&#34;learning-algorithms-学习算法&#34;&gt;Learning Algorithms 学习算法
&lt;/h1&gt;&lt;p&gt;　　使上述式子最小化的两种方法是随机梯度下降和交替最小二乘法。&lt;/p&gt;
&lt;h2 id=&#34;stochastic-gradient-descent-随机梯度下降&#34;&gt;Stochastic gradient descent 随机梯度下降
&lt;/h2&gt;$$\begin{equation}{e_{ui}}\overset{def}{=} {r_{ui}} - {q_i}^T{p_u}\end{equation}$$$${q_i} \leftarrow q_i + \gamma·({e_ui}·{p_u} - \lambda · {q_i})$$$${p_u} \leftarrow p_u + \gamma·({e_ui}·{q_i} - \lambda · {p_u})$$&lt;p&gt;　　该方法运行速度较快。不过在有些场景下，使用ALS优化更好。&lt;/p&gt;
&lt;h2 id=&#34;alternating-least-squares-交替最小二乘法&#34;&gt;Alternating least squares 交替最小二乘法
&lt;/h2&gt;&lt;p&gt;　　一般随机梯度下降比ALS简单且快。但ALS适用于两个场景，一是系统可以并行化。ALS可独立计算${q_i}$和${p_u}$。二是隐式数据情况下使用。&lt;/p&gt;
&lt;h1 id=&#34;adding-biases&#34;&gt;Adding Biases
&lt;/h1&gt;$${b_{ui}} = μ + {b_i} + {b_u}$$$$\hat{r}_{ui} = μ + {b_i} + {b_u} + {q_i}^T{p_u}$$$$min_{p\*,q\*,b\*}\sum_{(u,i)∈k}({r_ui} - μ - {b_u}- {b_i}-{p_u}^Tq_i)^2 + \lambda(||p_u||^2 + ||q_i||^2 + b_u^2 + b_i^2)$$&lt;h1 id=&#34;additional-input-sources-额外输入资源&#34;&gt;Additional Input Sources 额外输入资源
&lt;/h1&gt;$$\hat{r}_{ui} = μ + {b_i} + {b_u} + {q_i}^T[{p_u} + |N(u)|^{-0.5} \sum_{i∈N(u)}{x_i} + \sum_{a∈A(u)}{y_a}]$$&lt;p&gt;
　　N(u)指用户u有过隐式反馈的若干个item集合。x是和item i相关的因素。$\sum_{i∈N(u)}{x_i}$表示一个用户对N(u)中的若干item的偏好刻画向量。系数代表规范化。&lt;br&gt;
　　用户属性用A(u)表示，每一个用户的每一个属性对应的因素向量用$y_a$表示。$\sum_{a∈A(u)}{y_a}表示每个用户的属性集。&lt;/p&gt;
&lt;h1 id=&#34;temporal-dynamics-时空动态&#34;&gt;Temporal dynamics 时空动态
&lt;/h1&gt;$$\hat{r}_{ui}(t) = μ + b_i(t) + b_u(t) + q_i^Tp_u(t)$$&lt;p&gt;
　　$b_i(t)$表示物品随时间变化的流行程度，$b_u(t)$表示用户评分随时间变化的严格程度，$p_u(t)$表示用户偏好随时间变化的改变程度。物品是静态的，所以$q_i$也是静态的。&lt;/p&gt;
&lt;h1 id=&#34;inputs-with-varying-confidence-levels-各种信任级别的输入&#34;&gt;Inputs with varying confidence levels 各种信任级别的输入
&lt;/h1&gt;$$min_{p\*,q\*,b\*}\sum_{(u,i)∈k}c_{ui}({r_ui} - μ - {b_u}- {b_i}-{p_u}^Tq_i)^2 + \lambda(||p_u||^2 + ||q_i||^2 + b_u^2 + b_i^2)$$&lt;p&gt;
　　$c_{ui}$为评分的信任程度。&lt;/p&gt;
&lt;h1 id=&#34;netflix-prize-competition--netflix大奖竞赛&#34;&gt;Netflix prize competition  Netflix大奖竞赛
&lt;/h1&gt;&lt;p&gt;　　使用矩阵分解的方法取得了第一名的成绩。
&lt;img src=&#34;https://hubojing.github.io/images/Paper-MF-accuracy.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;精确度&#34;
	
	
&gt;
　　加的因素越多，精确度越高。&lt;/p&gt;
&lt;h1 id=&#34;阅后总结&#34;&gt;阅后总结
&lt;/h1&gt;&lt;p&gt;　　本文主要介绍了矩阵分解的具体算法。&lt;/p&gt;</description>
        </item>
        <item>
        <title>【Paper】Amazon.com Recommendations Item-to-Item Collaborative Filtering</title>
        <link>https://hubojing.github.io/h5bkenqv/</link>
        <pubDate>Wed, 02 Dec 2020 14:40:23 +0000</pubDate>
        
        <guid>https://hubojing.github.io/h5bkenqv/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\假装有图片.jpg&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;ItemCF原文。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文背景&#34;&gt;论文背景
&lt;/h1&gt;&lt;p&gt;　　22 January 2003&lt;br&gt;
　　谷歌学术被引用次数：6769（截至2020年12月2日）&lt;br&gt;
　　期刊：IEEE Internet Computing&lt;br&gt;
　　DOI: 10.1109/MIC.2003.1167344&lt;br&gt;
　　作者：Greg Linden,Brent Smith,and Jeremy York • Amazon.com&lt;br&gt;
　　&lt;a class=&#34;link&#34; href=&#34;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=1167344&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;引言&#34;&gt;引言
&lt;/h1&gt;&lt;p&gt;　　电子商务推荐算法面临的挑战：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一家大型零售商可能拥有大量数据、数千万客户和数百万不同的物品&lt;/li&gt;
&lt;li&gt;要求在不超过半秒钟的时间内实时返回结果集，同时能产生高质量的推荐&lt;/li&gt;
&lt;li&gt;新客户通常只有非常有限的信息，仅有少量购买信息和产品评分&lt;/li&gt;
&lt;li&gt;基于成千上万次的购买和评分，老用户可能拥有大量信息&lt;/li&gt;
&lt;li&gt;客户数据是不稳定的：每次交互都提供有价值的客户数据，算法必须对新信息立即做出响应&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;recommendation-algorithms-推荐算法&#34;&gt;Recommendation Algorithms 推荐算法
&lt;/h1&gt;&lt;p&gt;　　三种常规方法：&lt;br&gt;
　　传统协同过滤、聚类模型和基于搜索的策略&lt;br&gt;
　　traditional collaborative filtering, cluster models, and search-based methods&lt;/p&gt;
&lt;h2 id=&#34;traditional-collaborative-filtering-传统协同过滤&#34;&gt;Traditional Collaborative Filtering 传统协同过滤
&lt;/h2&gt;&lt;p&gt;　　传统协同过滤，这里指基于用户的协同过滤方法。&lt;br&gt;
　　相似度计算：&lt;br&gt;
&lt;img src=&#34;https://hubojing.github.io/%5cimages%5cPaper-Amazon-similarity.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;similarity&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;　　使用该方法时间复杂度最差为O(MN)，由于用户向量稀疏，时间复杂度更接近于O(M + N)。（大部分用户只涉及很少的物品，每个用户是O(M)，但一小部分用户买了很多物品，需要O(N)时间。）&lt;br&gt;
　　M为用户数，N为物品数&lt;/p&gt;
&lt;p&gt;　　解决方法是降低数据规模。&lt;br&gt;
　　通过随机采样用户或者忽视只有少数购买记录的用户，来减少M。&lt;br&gt;
　　通过忽视非常流行或不流行的物品，来减少N。&lt;br&gt;
　　还可以通过产品类别或或客观分类来分割物品成为小向量来减少物品数量。&lt;br&gt;
　　维度减少，比如聚类或主成分分析可以减少M或N的大量因素。&lt;/p&gt;
&lt;p&gt;　　但是上述方法会降低推荐质量。&lt;/p&gt;
&lt;h2 id=&#34;cluster-models-聚类模型&#34;&gt;Cluster Models 聚类模型
&lt;/h2&gt;&lt;p&gt;　　该算法的目标是将用户分配到包含最相似用户的簇。然后，它使用该簇中用户的购买和评级信息来推荐。&lt;br&gt;
　　一旦该算法生成了簇，它就计算用户与每个簇的向量的相似性，然后选择具有最大相似性的簇，并相应地对用户进行分类。一些算法将用户分为多个簇，并描述每个关系的强度。&lt;br&gt;
　　优点：比上述协同过滤具有更好的在线可扩展性和性能，复杂且昂贵的聚类计算是离线运行的。&lt;br&gt;
　　缺点：推荐效果差。通过使用大量细粒度的聚类来提高质量是可能的，但是线上用户细分聚类变得几乎和使用协同过滤寻找相似客户一样昂贵。&lt;/p&gt;
&lt;h2 id=&#34;search-based-methods-基于搜索的策略&#34;&gt;Search-Based Methods 基于搜索的策略
&lt;/h2&gt;&lt;p&gt;　　基于搜索或基于内容的方法将推荐问题视为对相关项目的搜索。对于给定用户购买和评级信息的物品，该算法构建搜索查询来查找由相同作者、艺术家或导演或具有相似关键字或主题的其他流行项目。例如，如果一位顾客购买了《教父》系列影碟，系统可能会推荐其他犯罪题材的电影、其他由影星马龙·白兰度主演的电影或其他由弗朗西斯·福特·科波拉执导的电影。&lt;/p&gt;
&lt;p&gt;　　优点：用户购买和评分记录少时，性能不错。&lt;br&gt;
　　缺点：推荐质量低，推荐的物品太一般（general)或太狭窄（narrow）。&lt;/p&gt;
&lt;h1 id=&#34;item-to-item-collaborative-filtering-基于物品的协同过滤&#34;&gt;Item-to-Item Collaborative Filtering 基于物品的协同过滤
&lt;/h1&gt;&lt;h2 id=&#34;how-it-works-如何工作&#34;&gt;How It Works 如何工作
&lt;/h2&gt;&lt;p&gt;　Item-to-item collaborative filtering matches each of the user’s purchased and rated items to similar items, then combines those similar items into a recommendation list.&lt;/p&gt;
&lt;p&gt;　　基于物品的协同过滤将用户购买的和评分的每个物品与相似的物品进行匹配，然后将这些相似的物品组合成推荐列表。&lt;/p&gt;
&lt;p&gt;　　为了确定给定物品的最相似匹配，该算法通过查找用户倾向于一起购买的物品来构建相似物品表。可通过遍历所有物品并为每一对计算相似性来构建物品矩阵。然而，许多产品对没有共同的用户，因此这种方法在处理时间和内存使用方面效率低下。以下迭代算法通过计算单个物品和所有相关物品之间的相似性提供了更好的措施：&lt;br&gt;
　　伪代码&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;For each item in product catalog, I1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    For each customer C who purchased I1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        For each item I2 purchased by customer C
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            Record that a customer purchased I1 and I2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    For each item I2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        Compute the similarity between I1 and I2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;　　计算两个物品之间的相似性有多种方法，一种常见的方法是使用前面描述的余弦度量，其中每个向量对应于一个物品而不是一个客户，并且向量的多维度对应于已经购买该物品的用户。相似物品表的这种离线计算非常耗时，最糟糕的情况是O($N^2M$)。然而，在实践中，它更接近于零，因为大多数客户只有很少的购买记录。对购买畅销物品的用户进行采样会进一步减少运行时间，而质量几乎没有下降。&lt;br&gt;
　　给定相似物品表，该算法找到与每个用户的购买和评分相似的物品，汇总这些物品，然后推荐最受欢迎或相关的物品。这种计算非常快速，仅取决于用户购买或评分的物品数量。&lt;/p&gt;
&lt;h2 id=&#34;scalability-a-comparison-可扩展性&#34;&gt;Scalability: A Comparison 可扩展性
&lt;/h2&gt;&lt;p&gt;　　Amazon.com有超过2900万的顾客和数百万的商品目录。对于非常大的数据集，可扩展的推荐算法必须离线执行最昂贵的计算。&lt;br&gt;
　　现有算法的缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传统的协同过滤很少或没有离线计算，其在线计算随着用户和物品目录的数量而变化。该算法在大数据集上是不切实际的，除非它使用降维、采样或分区——所有这些都会降低推荐质量。&lt;/li&gt;
&lt;li&gt;聚类模型可以离线执行大部分计算，但是推荐质量相对较差。为了改善这一点，可以增加细分簇的数量，但这使得在线用户细分分类变得昂贵。&lt;/li&gt;
&lt;li&gt;基于搜索的模型离线构建关键字、类别和作者索引，但无法提供有趣的、有针对性的主题推荐。对于有大量购买和评分的用户来说，它们的可扩展性也很小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;　　可扩展性和性能的关键是它离线创建昂贵的相似物品表。该算法的在线组件——为用户的购买和评分物品查找相似的物品——独立于物品目录大小或客户总数，它只取决于用户购买或评分物品。因此，即使对于非常大的数据集，该算法也是快速的。因为该算法推荐高度相关的相似物品，所以推荐质量很好。与传统的协作过滤不同，该算法在有限的用户数据下也表现良好，仅基于两三个物品就能产生高质量的推荐。&lt;/p&gt;
&lt;h1 id=&#34;conclusion-总结&#34;&gt;Conclusion 总结
&lt;/h1&gt;&lt;p&gt;　　主要是介绍了基于物品的协同过滤思想。&lt;br&gt;
　　耗时昂贵的操作放在线下离线进行，使线上达到实时要求。&lt;/p&gt;</description>
        </item>
        <item>
        <title>【Paper】Using Collaborative Filtering to Weave an Information Tapestry</title>
        <link>https://hubojing.github.io/jaxyksgz/</link>
        <pubDate>Wed, 15 Jul 2020 16:44:25 +0000</pubDate>
        
        <guid>https://hubojing.github.io/jaxyksgz/</guid>
        <description>&lt;div align=&#34;left&#34;&gt;
&lt;img src=&#34;\images\假装有图片.jpg&#34; width=&#34;300&#34; height=&#34;180&#34; style=&#34;float:right;&#34;/&gt;
&lt;p&gt;　　&lt;strong&gt;“协同过滤”词汇来源。&lt;/strong&gt;&lt;/p&gt;
 &lt;/div&gt;
&lt;h1 id=&#34;论文情况&#34;&gt;论文情况
&lt;/h1&gt;&lt;p&gt;　　COMMUN ACM, 1992.
　　David Goldberg, David Nichols, Brian M.Oki, and Douglas Terry
　　10页&lt;/p&gt;
&lt;p&gt;　　题目直译：使用协同过滤去构造一个信息tapestry&lt;/p&gt;
&lt;p&gt;　　截至2020年11月15日，该论文在谷歌学术上被引用次数为5239次。&lt;/p&gt;
&lt;h1 id=&#34;论文内容&#34;&gt;论文内容
&lt;/h1&gt;&lt;p&gt;　　文章提出了协同过滤（Collaborative filtering）这个词，最早是用于邮件系统Tapestry。&lt;br&gt;
　　文章对协同过滤的定义是：Collaborative filtering simply means that people collaborate to help one another perform filtering by recording their reactions to documents they read.&lt;/p&gt;
&lt;p&gt;　　协同过滤的亮点在于，它不仅仅是一个过滤邮件的机制，还是过去发送邮件的存储库。Tapestry将对这个存储库的临时查询与对传入数据的过滤统一起来。文章提到不仅可以处理邮件，也可以处理类似流数据，比如新闻。&lt;/p&gt;
&lt;p&gt;　　不过该文重点还是在邮件系统本身上，用户可以对邮件进行注解，这些注解可以用来进行协同过滤。本文设计了两种类型的阅读器。一种eager readers可以获取全部文件，另一种casual readers会进行注解，并且阅读基于此的文件。文章用了大量篇幅介绍了邮件系统本身的各个部件和查询语言（TQL），和推荐系统相关的不太多，因此本文属于浏览，未细致阅读。但毕竟是协同过滤鼻祖，所以记录一下。&lt;/p&gt;</description>
        </item>
        
    </channel>
</rss>
